I0216 01:28:31.288056 32696 caffe.cpp:185] Using GPUs 0, 1, 2, 3
I0216 01:28:31.320672 32696 caffe.cpp:190] GPU 0: Graphics Device
I0216 01:28:31.325343 32696 caffe.cpp:190] GPU 1: Graphics Device
I0216 01:28:31.329246 32696 caffe.cpp:190] GPU 2: Graphics Device
I0216 01:28:31.332868 32696 caffe.cpp:190] GPU 3: Graphics Device
I0216 01:28:32.084681 32696 solver.cpp:51] Initializing solver from parameters: 
train_net: "/home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/train.prototxt"
test_net: "/home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/test.prototxt"
test_iter: 7481
test_interval: 10000
base_lr: 0.001
display: 10
max_iter: 60000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 40000
snapshot: 40000
snapshot_prefix: "/home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/VGG_KITTI_SSD_600x150"
solver_mode: GPU
device_id: 0
debug_info: false
snapshot_after_train: true
test_initialization: false
average_loss: 10
iter_size: 1
type: "SGD"
eval_type: "detection"
ap_version: "11point"
I0216 01:28:32.084841 32696 solver.cpp:84] Creating training net from train_net file: /home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/train.prototxt
I0216 01:28:32.086674 32696 net.cpp:49] Initializing net from parameters: 
name: "VGG_KITTI_SSD_600x150_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 150
      width: 600
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
  }
  data_param {
    source: "/home/perception/KITTI_SSD/examples/KITTI/KITTI_train_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "/home/perception/KITTI_SSD//data/KITTI/labelmap_KITTI.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv8_2"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    aspect_ratio: 2
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 114
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 114
    max_size: 168
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 168
    max_size: 222
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 222
    max_size: 276
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "pool6_mbox_loc"
  type: "Convolution"
  bottom: "pool6"
  top: "pool6_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool6_mbox_loc_perm"
  type: "Permute"
  bottom: "pool6_mbox_loc"
  top: "pool6_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "pool6_mbox_loc_flat"
  type: "Flatten"
  bottom: "pool6_mbox_loc_perm"
  top: "pool6_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "pool6_mbox_conf"
  type: "Convolution"
  bottom: "pool6"
  top: "pool6_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool6_mbox_conf_perm"
  type: "Permute"
  bottom: "pool6_mbox_conf"
  top: "pool6_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "pool6_mbox_conf_flat"
  type: "Flatten"
  bottom: "pool6_mbox_conf_perm"
  top: "pool6_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "pool6_mbox_priorbox"
  type: "PriorBox"
  bottom: "pool6"
  bottom: "data"
  top: "pool6_mbox_priorbox"
  prior_box_param {
    min_size: 276
    max_size: 330
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "pool6_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "pool6_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "pool6_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 4
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    do_neg_mining: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
  }
}
I0216 01:28:32.087218 32696 layer_factory.hpp:77] Creating layer data
I0216 01:28:32.087694 32696 net.cpp:91] Creating Layer data
I0216 01:28:32.087723 32696 net.cpp:399] data -> data
I0216 01:28:32.087772 32696 net.cpp:399] data -> label
I0216 01:28:32.089468 32704 db_lmdb.cpp:13] Jerry: openning source lmdb: /home/perception/KITTI_SSD/examples/KITTI/KITTI_train_lmdb
I0216 01:28:32.089591 32704 db_lmdb.cpp:39] Opened lmdb /home/perception/KITTI_SSD/examples/KITTI/KITTI_train_lmdb
I0216 01:28:32.138834 32696 annotated_data_layer.cpp:52] output data size: 8,3,150,600
I0216 01:28:32.164933 32696 net.cpp:141] Setting up data
I0216 01:28:32.164969 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.164975 32696 net.cpp:148] Top shape: 1 1 1 8 (8)
I0216 01:28:32.164978 32696 net.cpp:156] Memory required for data: 8640032
I0216 01:28:32.164993 32696 layer_factory.hpp:77] Creating layer data_data_0_split
I0216 01:28:32.165010 32696 net.cpp:91] Creating Layer data_data_0_split
I0216 01:28:32.165020 32696 net.cpp:425] data_data_0_split <- data
I0216 01:28:32.165035 32696 net.cpp:399] data_data_0_split -> data_data_0_split_0
I0216 01:28:32.165055 32696 net.cpp:399] data_data_0_split -> data_data_0_split_1
I0216 01:28:32.165065 32696 net.cpp:399] data_data_0_split -> data_data_0_split_2
I0216 01:28:32.165074 32696 net.cpp:399] data_data_0_split -> data_data_0_split_3
I0216 01:28:32.165081 32696 net.cpp:399] data_data_0_split -> data_data_0_split_4
I0216 01:28:32.165091 32696 net.cpp:399] data_data_0_split -> data_data_0_split_5
I0216 01:28:32.165098 32696 net.cpp:399] data_data_0_split -> data_data_0_split_6
I0216 01:28:32.165212 32696 net.cpp:141] Setting up data_data_0_split
I0216 01:28:32.165220 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.165225 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.165230 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.165251 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.165254 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.165257 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.165261 32696 net.cpp:148] Top shape: 8 3 150 600 (2160000)
I0216 01:28:32.165264 32696 net.cpp:156] Memory required for data: 69120032
I0216 01:28:32.165268 32696 layer_factory.hpp:77] Creating layer conv1_1
I0216 01:28:32.165292 32696 net.cpp:91] Creating Layer conv1_1
I0216 01:28:32.165297 32696 net.cpp:425] conv1_1 <- data_data_0_split_0
I0216 01:28:32.165305 32696 net.cpp:399] conv1_1 -> conv1_1
I0216 01:28:32.168102 32696 net.cpp:141] Setting up conv1_1
I0216 01:28:32.168128 32696 net.cpp:148] Top shape: 8 64 150 600 (46080000)
I0216 01:28:32.168130 32696 net.cpp:156] Memory required for data: 253440032
I0216 01:28:32.168154 32696 layer_factory.hpp:77] Creating layer relu1_1
I0216 01:28:32.168166 32696 net.cpp:91] Creating Layer relu1_1
I0216 01:28:32.168171 32696 net.cpp:425] relu1_1 <- conv1_1
I0216 01:28:32.168179 32696 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0216 01:28:32.168192 32696 net.cpp:141] Setting up relu1_1
I0216 01:28:32.168197 32696 net.cpp:148] Top shape: 8 64 150 600 (46080000)
I0216 01:28:32.168200 32696 net.cpp:156] Memory required for data: 437760032
I0216 01:28:32.168203 32696 layer_factory.hpp:77] Creating layer conv1_2
I0216 01:28:32.168218 32696 net.cpp:91] Creating Layer conv1_2
I0216 01:28:32.168222 32696 net.cpp:425] conv1_2 <- conv1_1
I0216 01:28:32.168228 32696 net.cpp:399] conv1_2 -> conv1_2
I0216 01:28:32.169862 32696 net.cpp:141] Setting up conv1_2
I0216 01:28:32.169878 32696 net.cpp:148] Top shape: 8 64 150 600 (46080000)
I0216 01:28:32.169883 32696 net.cpp:156] Memory required for data: 622080032
I0216 01:28:32.169891 32696 layer_factory.hpp:77] Creating layer relu1_2
I0216 01:28:32.169898 32696 net.cpp:91] Creating Layer relu1_2
I0216 01:28:32.169903 32696 net.cpp:425] relu1_2 <- conv1_2
I0216 01:28:32.169909 32696 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0216 01:28:32.169914 32696 net.cpp:141] Setting up relu1_2
I0216 01:28:32.169920 32696 net.cpp:148] Top shape: 8 64 150 600 (46080000)
I0216 01:28:32.169924 32696 net.cpp:156] Memory required for data: 806400032
I0216 01:28:32.169925 32696 layer_factory.hpp:77] Creating layer pool1
I0216 01:28:32.169931 32696 net.cpp:91] Creating Layer pool1
I0216 01:28:32.169934 32696 net.cpp:425] pool1 <- conv1_2
I0216 01:28:32.169942 32696 net.cpp:399] pool1 -> pool1
I0216 01:28:32.169997 32696 net.cpp:141] Setting up pool1
I0216 01:28:32.170004 32696 net.cpp:148] Top shape: 8 64 75 300 (11520000)
I0216 01:28:32.170007 32696 net.cpp:156] Memory required for data: 852480032
I0216 01:28:32.170011 32696 layer_factory.hpp:77] Creating layer conv2_1
I0216 01:28:32.170022 32696 net.cpp:91] Creating Layer conv2_1
I0216 01:28:32.170027 32696 net.cpp:425] conv2_1 <- pool1
I0216 01:28:32.170032 32696 net.cpp:399] conv2_1 -> conv2_1
I0216 01:28:32.170711 32696 net.cpp:141] Setting up conv2_1
I0216 01:28:32.170720 32696 net.cpp:148] Top shape: 8 128 75 300 (23040000)
I0216 01:28:32.170723 32696 net.cpp:156] Memory required for data: 944640032
I0216 01:28:32.170732 32696 layer_factory.hpp:77] Creating layer relu2_1
I0216 01:28:32.170742 32696 net.cpp:91] Creating Layer relu2_1
I0216 01:28:32.170747 32696 net.cpp:425] relu2_1 <- conv2_1
I0216 01:28:32.170752 32696 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0216 01:28:32.170763 32696 net.cpp:141] Setting up relu2_1
I0216 01:28:32.170768 32696 net.cpp:148] Top shape: 8 128 75 300 (23040000)
I0216 01:28:32.170770 32696 net.cpp:156] Memory required for data: 1036800032
I0216 01:28:32.170773 32696 layer_factory.hpp:77] Creating layer conv2_2
I0216 01:28:32.170786 32696 net.cpp:91] Creating Layer conv2_2
I0216 01:28:32.170790 32696 net.cpp:425] conv2_2 <- conv2_1
I0216 01:28:32.170797 32696 net.cpp:399] conv2_2 -> conv2_2
I0216 01:28:32.171903 32696 net.cpp:141] Setting up conv2_2
I0216 01:28:32.171911 32696 net.cpp:148] Top shape: 8 128 75 300 (23040000)
I0216 01:28:32.171931 32696 net.cpp:156] Memory required for data: 1128960032
I0216 01:28:32.171938 32696 layer_factory.hpp:77] Creating layer relu2_2
I0216 01:28:32.171943 32696 net.cpp:91] Creating Layer relu2_2
I0216 01:28:32.171947 32696 net.cpp:425] relu2_2 <- conv2_2
I0216 01:28:32.171954 32696 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0216 01:28:32.171960 32696 net.cpp:141] Setting up relu2_2
I0216 01:28:32.171964 32696 net.cpp:148] Top shape: 8 128 75 300 (23040000)
I0216 01:28:32.171968 32696 net.cpp:156] Memory required for data: 1221120032
I0216 01:28:32.171972 32696 layer_factory.hpp:77] Creating layer pool2
I0216 01:28:32.171977 32696 net.cpp:91] Creating Layer pool2
I0216 01:28:32.171980 32696 net.cpp:425] pool2 <- conv2_2
I0216 01:28:32.171986 32696 net.cpp:399] pool2 -> pool2
I0216 01:28:32.172024 32696 net.cpp:141] Setting up pool2
I0216 01:28:32.172029 32696 net.cpp:148] Top shape: 8 128 38 150 (5836800)
I0216 01:28:32.172032 32696 net.cpp:156] Memory required for data: 1244467232
I0216 01:28:32.172035 32696 layer_factory.hpp:77] Creating layer conv3_1
I0216 01:28:32.172045 32696 net.cpp:91] Creating Layer conv3_1
I0216 01:28:32.172049 32696 net.cpp:425] conv3_1 <- pool2
I0216 01:28:32.172056 32696 net.cpp:399] conv3_1 -> conv3_1
I0216 01:28:32.176766 32696 net.cpp:141] Setting up conv3_1
I0216 01:28:32.176791 32696 net.cpp:148] Top shape: 8 256 38 150 (11673600)
I0216 01:28:32.176795 32696 net.cpp:156] Memory required for data: 1291161632
I0216 01:28:32.176810 32696 layer_factory.hpp:77] Creating layer relu3_1
I0216 01:28:32.176818 32696 net.cpp:91] Creating Layer relu3_1
I0216 01:28:32.176823 32696 net.cpp:425] relu3_1 <- conv3_1
I0216 01:28:32.176831 32696 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0216 01:28:32.176841 32696 net.cpp:141] Setting up relu3_1
I0216 01:28:32.176847 32696 net.cpp:148] Top shape: 8 256 38 150 (11673600)
I0216 01:28:32.176851 32696 net.cpp:156] Memory required for data: 1337856032
I0216 01:28:32.176853 32696 layer_factory.hpp:77] Creating layer conv3_2
I0216 01:28:32.176867 32696 net.cpp:91] Creating Layer conv3_2
I0216 01:28:32.176872 32696 net.cpp:425] conv3_2 <- conv3_1
I0216 01:28:32.176878 32696 net.cpp:399] conv3_2 -> conv3_2
I0216 01:28:32.182773 32696 net.cpp:141] Setting up conv3_2
I0216 01:28:32.182796 32696 net.cpp:148] Top shape: 8 256 38 150 (11673600)
I0216 01:28:32.182814 32696 net.cpp:156] Memory required for data: 1384550432
I0216 01:28:32.182826 32696 layer_factory.hpp:77] Creating layer relu3_2
I0216 01:28:32.182835 32696 net.cpp:91] Creating Layer relu3_2
I0216 01:28:32.182857 32696 net.cpp:425] relu3_2 <- conv3_2
I0216 01:28:32.182862 32696 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0216 01:28:32.182869 32696 net.cpp:141] Setting up relu3_2
I0216 01:28:32.182874 32696 net.cpp:148] Top shape: 8 256 38 150 (11673600)
I0216 01:28:32.182876 32696 net.cpp:156] Memory required for data: 1431244832
I0216 01:28:32.182896 32696 layer_factory.hpp:77] Creating layer conv3_3
I0216 01:28:32.182914 32696 net.cpp:91] Creating Layer conv3_3
I0216 01:28:32.182919 32696 net.cpp:425] conv3_3 <- conv3_2
I0216 01:28:32.182940 32696 net.cpp:399] conv3_3 -> conv3_3
I0216 01:28:32.191109 32696 net.cpp:141] Setting up conv3_3
I0216 01:28:32.191123 32696 net.cpp:148] Top shape: 8 256 38 150 (11673600)
I0216 01:28:32.191135 32696 net.cpp:156] Memory required for data: 1477939232
I0216 01:28:32.191141 32696 layer_factory.hpp:77] Creating layer relu3_3
I0216 01:28:32.191148 32696 net.cpp:91] Creating Layer relu3_3
I0216 01:28:32.191151 32696 net.cpp:425] relu3_3 <- conv3_3
I0216 01:28:32.191174 32696 net.cpp:386] relu3_3 -> conv3_3 (in-place)
I0216 01:28:32.191180 32696 net.cpp:141] Setting up relu3_3
I0216 01:28:32.191184 32696 net.cpp:148] Top shape: 8 256 38 150 (11673600)
I0216 01:28:32.191189 32696 net.cpp:156] Memory required for data: 1524633632
I0216 01:28:32.191190 32696 layer_factory.hpp:77] Creating layer pool3
I0216 01:28:32.191197 32696 net.cpp:91] Creating Layer pool3
I0216 01:28:32.191215 32696 net.cpp:425] pool3 <- conv3_3
I0216 01:28:32.191221 32696 net.cpp:399] pool3 -> pool3
I0216 01:28:32.191337 32696 net.cpp:141] Setting up pool3
I0216 01:28:32.191345 32696 net.cpp:148] Top shape: 8 256 19 75 (2918400)
I0216 01:28:32.191347 32696 net.cpp:156] Memory required for data: 1536307232
I0216 01:28:32.191351 32696 layer_factory.hpp:77] Creating layer conv4_1
I0216 01:28:32.191372 32696 net.cpp:91] Creating Layer conv4_1
I0216 01:28:32.191381 32696 net.cpp:425] conv4_1 <- pool3
I0216 01:28:32.191388 32696 net.cpp:399] conv4_1 -> conv4_1
I0216 01:28:32.209302 32696 net.cpp:141] Setting up conv4_1
I0216 01:28:32.209336 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.209339 32696 net.cpp:156] Memory required for data: 1559654432
I0216 01:28:32.209347 32696 layer_factory.hpp:77] Creating layer relu4_1
I0216 01:28:32.209372 32696 net.cpp:91] Creating Layer relu4_1
I0216 01:28:32.209377 32696 net.cpp:425] relu4_1 <- conv4_1
I0216 01:28:32.209383 32696 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0216 01:28:32.209410 32696 net.cpp:141] Setting up relu4_1
I0216 01:28:32.209415 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.209417 32696 net.cpp:156] Memory required for data: 1583001632
I0216 01:28:32.209420 32696 layer_factory.hpp:77] Creating layer conv4_2
I0216 01:28:32.209447 32696 net.cpp:91] Creating Layer conv4_2
I0216 01:28:32.209451 32696 net.cpp:425] conv4_2 <- conv4_1
I0216 01:28:32.209457 32696 net.cpp:399] conv4_2 -> conv4_2
I0216 01:28:32.236075 32696 net.cpp:141] Setting up conv4_2
I0216 01:28:32.236115 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.236122 32696 net.cpp:156] Memory required for data: 1606348832
I0216 01:28:32.236151 32696 layer_factory.hpp:77] Creating layer relu4_2
I0216 01:28:32.236173 32696 net.cpp:91] Creating Layer relu4_2
I0216 01:28:32.236183 32696 net.cpp:425] relu4_2 <- conv4_2
I0216 01:28:32.236198 32696 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0216 01:28:32.236214 32696 net.cpp:141] Setting up relu4_2
I0216 01:28:32.236224 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.236229 32696 net.cpp:156] Memory required for data: 1629696032
I0216 01:28:32.236237 32696 layer_factory.hpp:77] Creating layer conv4_3
I0216 01:28:32.236255 32696 net.cpp:91] Creating Layer conv4_3
I0216 01:28:32.236261 32696 net.cpp:425] conv4_3 <- conv4_2
I0216 01:28:32.236274 32696 net.cpp:399] conv4_3 -> conv4_3
I0216 01:28:32.238798 32705 blocking_queue.cpp:50] Waiting for data
I0216 01:28:32.260742 32696 net.cpp:141] Setting up conv4_3
I0216 01:28:32.260792 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.260812 32696 net.cpp:156] Memory required for data: 1653043232
I0216 01:28:32.260824 32696 layer_factory.hpp:77] Creating layer relu4_3
I0216 01:28:32.260854 32696 net.cpp:91] Creating Layer relu4_3
I0216 01:28:32.260859 32696 net.cpp:425] relu4_3 <- conv4_3
I0216 01:28:32.260866 32696 net.cpp:386] relu4_3 -> conv4_3 (in-place)
I0216 01:28:32.260897 32696 net.cpp:141] Setting up relu4_3
I0216 01:28:32.260901 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.260905 32696 net.cpp:156] Memory required for data: 1676390432
I0216 01:28:32.260907 32696 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0216 01:28:32.260952 32696 net.cpp:91] Creating Layer conv4_3_relu4_3_0_split
I0216 01:28:32.260956 32696 net.cpp:425] conv4_3_relu4_3_0_split <- conv4_3
I0216 01:28:32.260977 32696 net.cpp:399] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0216 01:28:32.260987 32696 net.cpp:399] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0216 01:28:32.261059 32696 net.cpp:141] Setting up conv4_3_relu4_3_0_split
I0216 01:28:32.261066 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.261070 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.261072 32696 net.cpp:156] Memory required for data: 1723084832
I0216 01:28:32.261076 32696 layer_factory.hpp:77] Creating layer pool4
I0216 01:28:32.261103 32696 net.cpp:91] Creating Layer pool4
I0216 01:28:32.261108 32696 net.cpp:425] pool4 <- conv4_3_relu4_3_0_split_0
I0216 01:28:32.261152 32696 net.cpp:399] pool4 -> pool4
I0216 01:28:32.261227 32696 net.cpp:141] Setting up pool4
I0216 01:28:32.261234 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.261236 32696 net.cpp:156] Memory required for data: 1729310752
I0216 01:28:32.261239 32696 layer_factory.hpp:77] Creating layer conv5_1
I0216 01:28:32.261277 32696 net.cpp:91] Creating Layer conv5_1
I0216 01:28:32.261296 32696 net.cpp:425] conv5_1 <- pool4
I0216 01:28:32.261306 32696 net.cpp:399] conv5_1 -> conv5_1
I0216 01:28:32.290174 32696 net.cpp:141] Setting up conv5_1
I0216 01:28:32.290241 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.290243 32696 net.cpp:156] Memory required for data: 1735536672
I0216 01:28:32.290251 32696 layer_factory.hpp:77] Creating layer relu5_1
I0216 01:28:32.290277 32696 net.cpp:91] Creating Layer relu5_1
I0216 01:28:32.290282 32696 net.cpp:425] relu5_1 <- conv5_1
I0216 01:28:32.290287 32696 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0216 01:28:32.290328 32696 net.cpp:141] Setting up relu5_1
I0216 01:28:32.290331 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.290343 32696 net.cpp:156] Memory required for data: 1741762592
I0216 01:28:32.290376 32696 layer_factory.hpp:77] Creating layer conv5_2
I0216 01:28:32.290418 32696 net.cpp:91] Creating Layer conv5_2
I0216 01:28:32.290441 32696 net.cpp:425] conv5_2 <- conv5_1
I0216 01:28:32.290447 32696 net.cpp:399] conv5_2 -> conv5_2
I0216 01:28:32.309154 32696 net.cpp:141] Setting up conv5_2
I0216 01:28:32.309201 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.309203 32696 net.cpp:156] Memory required for data: 1747988512
I0216 01:28:32.309214 32696 layer_factory.hpp:77] Creating layer relu5_2
I0216 01:28:32.309224 32696 net.cpp:91] Creating Layer relu5_2
I0216 01:28:32.309228 32696 net.cpp:425] relu5_2 <- conv5_2
I0216 01:28:32.309253 32696 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0216 01:28:32.309264 32696 net.cpp:141] Setting up relu5_2
I0216 01:28:32.309268 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.309269 32696 net.cpp:156] Memory required for data: 1754214432
I0216 01:28:32.309273 32696 layer_factory.hpp:77] Creating layer conv5_3
I0216 01:28:32.309283 32696 net.cpp:91] Creating Layer conv5_3
I0216 01:28:32.309286 32696 net.cpp:425] conv5_3 <- conv5_2
I0216 01:28:32.309306 32696 net.cpp:399] conv5_3 -> conv5_3
I0216 01:28:32.334053 32696 net.cpp:141] Setting up conv5_3
I0216 01:28:32.334102 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.334105 32696 net.cpp:156] Memory required for data: 1760440352
I0216 01:28:32.334133 32696 layer_factory.hpp:77] Creating layer relu5_3
I0216 01:28:32.334170 32696 net.cpp:91] Creating Layer relu5_3
I0216 01:28:32.334175 32696 net.cpp:425] relu5_3 <- conv5_3
I0216 01:28:32.334182 32696 net.cpp:386] relu5_3 -> conv5_3 (in-place)
I0216 01:28:32.334213 32696 net.cpp:141] Setting up relu5_3
I0216 01:28:32.334218 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.334219 32696 net.cpp:156] Memory required for data: 1766666272
I0216 01:28:32.334221 32696 layer_factory.hpp:77] Creating layer pool5
I0216 01:28:32.334226 32696 net.cpp:91] Creating Layer pool5
I0216 01:28:32.334230 32696 net.cpp:425] pool5 <- conv5_3
I0216 01:28:32.334254 32696 net.cpp:399] pool5 -> pool5
I0216 01:28:32.334416 32696 net.cpp:141] Setting up pool5
I0216 01:28:32.334424 32696 net.cpp:148] Top shape: 8 512 10 38 (1556480)
I0216 01:28:32.334425 32696 net.cpp:156] Memory required for data: 1772892192
I0216 01:28:32.334429 32696 layer_factory.hpp:77] Creating layer fc6
I0216 01:28:32.334460 32696 net.cpp:91] Creating Layer fc6
I0216 01:28:32.334465 32696 net.cpp:425] fc6 <- pool5
I0216 01:28:32.334470 32696 net.cpp:399] fc6 -> fc6
I0216 01:28:32.392763 32696 net.cpp:141] Setting up fc6
I0216 01:28:32.392802 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.392807 32696 net.cpp:156] Memory required for data: 1785344032
I0216 01:28:32.392820 32696 layer_factory.hpp:77] Creating layer relu6
I0216 01:28:32.392845 32696 net.cpp:91] Creating Layer relu6
I0216 01:28:32.392884 32696 net.cpp:425] relu6 <- fc6
I0216 01:28:32.392894 32696 net.cpp:386] relu6 -> fc6 (in-place)
I0216 01:28:32.392907 32696 net.cpp:141] Setting up relu6
I0216 01:28:32.392915 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.392918 32696 net.cpp:156] Memory required for data: 1797795872
I0216 01:28:32.392922 32696 layer_factory.hpp:77] Creating layer fc7
I0216 01:28:32.392940 32696 net.cpp:91] Creating Layer fc7
I0216 01:28:32.392945 32696 net.cpp:425] fc7 <- fc6
I0216 01:28:32.392953 32696 net.cpp:399] fc7 -> fc7
I0216 01:28:32.405438 32696 net.cpp:141] Setting up fc7
I0216 01:28:32.405455 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.405460 32696 net.cpp:156] Memory required for data: 1810247712
I0216 01:28:32.405469 32696 layer_factory.hpp:77] Creating layer relu7
I0216 01:28:32.405479 32696 net.cpp:91] Creating Layer relu7
I0216 01:28:32.405483 32696 net.cpp:425] relu7 <- fc7
I0216 01:28:32.405491 32696 net.cpp:386] relu7 -> fc7 (in-place)
I0216 01:28:32.405500 32696 net.cpp:141] Setting up relu7
I0216 01:28:32.405506 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.405509 32696 net.cpp:156] Memory required for data: 1822699552
I0216 01:28:32.405514 32696 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0216 01:28:32.405522 32696 net.cpp:91] Creating Layer fc7_relu7_0_split
I0216 01:28:32.405527 32696 net.cpp:425] fc7_relu7_0_split <- fc7
I0216 01:28:32.405534 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0216 01:28:32.405544 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0216 01:28:32.405565 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0216 01:28:32.405573 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0216 01:28:32.405655 32696 net.cpp:141] Setting up fc7_relu7_0_split
I0216 01:28:32.405673 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.405678 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.405683 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.405688 32696 net.cpp:148] Top shape: 8 1024 10 38 (3112960)
I0216 01:28:32.405692 32696 net.cpp:156] Memory required for data: 1872506912
I0216 01:28:32.405696 32696 layer_factory.hpp:77] Creating layer conv6_1
I0216 01:28:32.405709 32696 net.cpp:91] Creating Layer conv6_1
I0216 01:28:32.405714 32696 net.cpp:425] conv6_1 <- fc7_relu7_0_split_0
I0216 01:28:32.405730 32696 net.cpp:399] conv6_1 -> conv6_1
I0216 01:28:32.410094 32696 net.cpp:141] Setting up conv6_1
I0216 01:28:32.410110 32696 net.cpp:148] Top shape: 8 256 10 38 (778240)
I0216 01:28:32.410115 32696 net.cpp:156] Memory required for data: 1875619872
I0216 01:28:32.410123 32696 layer_factory.hpp:77] Creating layer conv6_1_relu
I0216 01:28:32.410131 32696 net.cpp:91] Creating Layer conv6_1_relu
I0216 01:28:32.410135 32696 net.cpp:425] conv6_1_relu <- conv6_1
I0216 01:28:32.410145 32696 net.cpp:386] conv6_1_relu -> conv6_1 (in-place)
I0216 01:28:32.410153 32696 net.cpp:141] Setting up conv6_1_relu
I0216 01:28:32.410159 32696 net.cpp:148] Top shape: 8 256 10 38 (778240)
I0216 01:28:32.410162 32696 net.cpp:156] Memory required for data: 1878732832
I0216 01:28:32.410166 32696 layer_factory.hpp:77] Creating layer conv6_2
I0216 01:28:32.410181 32696 net.cpp:91] Creating Layer conv6_2
I0216 01:28:32.410184 32696 net.cpp:425] conv6_2 <- conv6_1
I0216 01:28:32.410192 32696 net.cpp:399] conv6_2 -> conv6_2
I0216 01:28:32.423004 32696 net.cpp:141] Setting up conv6_2
I0216 01:28:32.423020 32696 net.cpp:148] Top shape: 8 512 5 19 (389120)
I0216 01:28:32.423023 32696 net.cpp:156] Memory required for data: 1880289312
I0216 01:28:32.423043 32696 layer_factory.hpp:77] Creating layer conv6_2_relu
I0216 01:28:32.423050 32696 net.cpp:91] Creating Layer conv6_2_relu
I0216 01:28:32.423055 32696 net.cpp:425] conv6_2_relu <- conv6_2
I0216 01:28:32.423061 32696 net.cpp:386] conv6_2_relu -> conv6_2 (in-place)
I0216 01:28:32.423069 32696 net.cpp:141] Setting up conv6_2_relu
I0216 01:28:32.423074 32696 net.cpp:148] Top shape: 8 512 5 19 (389120)
I0216 01:28:32.423097 32696 net.cpp:156] Memory required for data: 1881845792
I0216 01:28:32.423101 32696 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0216 01:28:32.423110 32696 net.cpp:91] Creating Layer conv6_2_conv6_2_relu_0_split
I0216 01:28:32.423115 32696 net.cpp:425] conv6_2_conv6_2_relu_0_split <- conv6_2
I0216 01:28:32.423123 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0216 01:28:32.423146 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0216 01:28:32.423153 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0216 01:28:32.423161 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0216 01:28:32.423265 32696 net.cpp:141] Setting up conv6_2_conv6_2_relu_0_split
I0216 01:28:32.423277 32696 net.cpp:148] Top shape: 8 512 5 19 (389120)
I0216 01:28:32.423281 32696 net.cpp:148] Top shape: 8 512 5 19 (389120)
I0216 01:28:32.423286 32696 net.cpp:148] Top shape: 8 512 5 19 (389120)
I0216 01:28:32.423291 32696 net.cpp:148] Top shape: 8 512 5 19 (389120)
I0216 01:28:32.423295 32696 net.cpp:156] Memory required for data: 1888071712
I0216 01:28:32.423297 32696 layer_factory.hpp:77] Creating layer conv7_1
I0216 01:28:32.423310 32696 net.cpp:91] Creating Layer conv7_1
I0216 01:28:32.423315 32696 net.cpp:425] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0216 01:28:32.423322 32696 net.cpp:399] conv7_1 -> conv7_1
I0216 01:28:32.424160 32696 net.cpp:141] Setting up conv7_1
I0216 01:28:32.424168 32696 net.cpp:148] Top shape: 8 128 5 19 (97280)
I0216 01:28:32.424172 32696 net.cpp:156] Memory required for data: 1888460832
I0216 01:28:32.424180 32696 layer_factory.hpp:77] Creating layer conv7_1_relu
I0216 01:28:32.424185 32696 net.cpp:91] Creating Layer conv7_1_relu
I0216 01:28:32.424188 32696 net.cpp:425] conv7_1_relu <- conv7_1
I0216 01:28:32.424197 32696 net.cpp:386] conv7_1_relu -> conv7_1 (in-place)
I0216 01:28:32.424202 32696 net.cpp:141] Setting up conv7_1_relu
I0216 01:28:32.424207 32696 net.cpp:148] Top shape: 8 128 5 19 (97280)
I0216 01:28:32.424211 32696 net.cpp:156] Memory required for data: 1888849952
I0216 01:28:32.424214 32696 layer_factory.hpp:77] Creating layer conv7_2
I0216 01:28:32.424223 32696 net.cpp:91] Creating Layer conv7_2
I0216 01:28:32.424227 32696 net.cpp:425] conv7_2 <- conv7_1
I0216 01:28:32.424233 32696 net.cpp:399] conv7_2 -> conv7_2
I0216 01:28:32.428388 32696 net.cpp:141] Setting up conv7_2
I0216 01:28:32.428403 32696 net.cpp:148] Top shape: 8 256 3 10 (61440)
I0216 01:28:32.428406 32696 net.cpp:156] Memory required for data: 1889095712
I0216 01:28:32.428413 32696 layer_factory.hpp:77] Creating layer conv7_2_relu
I0216 01:28:32.428421 32696 net.cpp:91] Creating Layer conv7_2_relu
I0216 01:28:32.428426 32696 net.cpp:425] conv7_2_relu <- conv7_2
I0216 01:28:32.428432 32696 net.cpp:386] conv7_2_relu -> conv7_2 (in-place)
I0216 01:28:32.428441 32696 net.cpp:141] Setting up conv7_2_relu
I0216 01:28:32.428447 32696 net.cpp:148] Top shape: 8 256 3 10 (61440)
I0216 01:28:32.428449 32696 net.cpp:156] Memory required for data: 1889341472
I0216 01:28:32.428452 32696 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0216 01:28:32.428459 32696 net.cpp:91] Creating Layer conv7_2_conv7_2_relu_0_split
I0216 01:28:32.428464 32696 net.cpp:425] conv7_2_conv7_2_relu_0_split <- conv7_2
I0216 01:28:32.428472 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0216 01:28:32.428479 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0216 01:28:32.428488 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0216 01:28:32.428496 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0216 01:28:32.428570 32696 net.cpp:141] Setting up conv7_2_conv7_2_relu_0_split
I0216 01:28:32.428578 32696 net.cpp:148] Top shape: 8 256 3 10 (61440)
I0216 01:28:32.428584 32696 net.cpp:148] Top shape: 8 256 3 10 (61440)
I0216 01:28:32.428602 32696 net.cpp:148] Top shape: 8 256 3 10 (61440)
I0216 01:28:32.428606 32696 net.cpp:148] Top shape: 8 256 3 10 (61440)
I0216 01:28:32.428609 32696 net.cpp:156] Memory required for data: 1890324512
I0216 01:28:32.428613 32696 layer_factory.hpp:77] Creating layer conv8_1
I0216 01:28:32.428627 32696 net.cpp:91] Creating Layer conv8_1
I0216 01:28:32.428630 32696 net.cpp:425] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0216 01:28:32.428639 32696 net.cpp:399] conv8_1 -> conv8_1
I0216 01:28:32.429183 32696 net.cpp:141] Setting up conv8_1
I0216 01:28:32.429193 32696 net.cpp:148] Top shape: 8 128 3 10 (30720)
I0216 01:28:32.429196 32696 net.cpp:156] Memory required for data: 1890447392
I0216 01:28:32.429203 32696 layer_factory.hpp:77] Creating layer conv8_1_relu
I0216 01:28:32.429211 32696 net.cpp:91] Creating Layer conv8_1_relu
I0216 01:28:32.429215 32696 net.cpp:425] conv8_1_relu <- conv8_1
I0216 01:28:32.429220 32696 net.cpp:386] conv8_1_relu -> conv8_1 (in-place)
I0216 01:28:32.429226 32696 net.cpp:141] Setting up conv8_1_relu
I0216 01:28:32.429231 32696 net.cpp:148] Top shape: 8 128 3 10 (30720)
I0216 01:28:32.429235 32696 net.cpp:156] Memory required for data: 1890570272
I0216 01:28:32.429239 32696 layer_factory.hpp:77] Creating layer conv8_2
I0216 01:28:32.429249 32696 net.cpp:91] Creating Layer conv8_2
I0216 01:28:32.429252 32696 net.cpp:425] conv8_2 <- conv8_1
I0216 01:28:32.429260 32696 net.cpp:399] conv8_2 -> conv8_2
I0216 01:28:32.433531 32696 net.cpp:141] Setting up conv8_2
I0216 01:28:32.433547 32696 net.cpp:148] Top shape: 8 256 2 5 (20480)
I0216 01:28:32.433550 32696 net.cpp:156] Memory required for data: 1890652192
I0216 01:28:32.433558 32696 layer_factory.hpp:77] Creating layer conv8_2_relu
I0216 01:28:32.433568 32696 net.cpp:91] Creating Layer conv8_2_relu
I0216 01:28:32.433573 32696 net.cpp:425] conv8_2_relu <- conv8_2
I0216 01:28:32.433578 32696 net.cpp:386] conv8_2_relu -> conv8_2 (in-place)
I0216 01:28:32.433586 32696 net.cpp:141] Setting up conv8_2_relu
I0216 01:28:32.433591 32696 net.cpp:148] Top shape: 8 256 2 5 (20480)
I0216 01:28:32.433594 32696 net.cpp:156] Memory required for data: 1890734112
I0216 01:28:32.433598 32696 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0216 01:28:32.433606 32696 net.cpp:91] Creating Layer conv8_2_conv8_2_relu_0_split
I0216 01:28:32.433610 32696 net.cpp:425] conv8_2_conv8_2_relu_0_split <- conv8_2
I0216 01:28:32.433615 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0216 01:28:32.433624 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0216 01:28:32.433635 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0216 01:28:32.433643 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0216 01:28:32.433738 32696 net.cpp:141] Setting up conv8_2_conv8_2_relu_0_split
I0216 01:28:32.433746 32696 net.cpp:148] Top shape: 8 256 2 5 (20480)
I0216 01:28:32.433751 32696 net.cpp:148] Top shape: 8 256 2 5 (20480)
I0216 01:28:32.433756 32696 net.cpp:148] Top shape: 8 256 2 5 (20480)
I0216 01:28:32.433760 32696 net.cpp:148] Top shape: 8 256 2 5 (20480)
I0216 01:28:32.433763 32696 net.cpp:156] Memory required for data: 1891061792
I0216 01:28:32.433768 32696 layer_factory.hpp:77] Creating layer pool6
I0216 01:28:32.433779 32696 net.cpp:91] Creating Layer pool6
I0216 01:28:32.433784 32696 net.cpp:425] pool6 <- conv8_2_conv8_2_relu_0_split_0
I0216 01:28:32.433789 32696 net.cpp:399] pool6 -> pool6
I0216 01:28:32.433833 32696 net.cpp:141] Setting up pool6
I0216 01:28:32.433840 32696 net.cpp:148] Top shape: 8 256 1 1 (2048)
I0216 01:28:32.433843 32696 net.cpp:156] Memory required for data: 1891069984
I0216 01:28:32.433846 32696 layer_factory.hpp:77] Creating layer pool6_pool6_0_split
I0216 01:28:32.433854 32696 net.cpp:91] Creating Layer pool6_pool6_0_split
I0216 01:28:32.433857 32696 net.cpp:425] pool6_pool6_0_split <- pool6
I0216 01:28:32.433864 32696 net.cpp:399] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0216 01:28:32.433887 32696 net.cpp:399] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0216 01:28:32.433897 32696 net.cpp:399] pool6_pool6_0_split -> pool6_pool6_0_split_2
I0216 01:28:32.433951 32696 net.cpp:141] Setting up pool6_pool6_0_split
I0216 01:28:32.433959 32696 net.cpp:148] Top shape: 8 256 1 1 (2048)
I0216 01:28:32.433964 32696 net.cpp:148] Top shape: 8 256 1 1 (2048)
I0216 01:28:32.433969 32696 net.cpp:148] Top shape: 8 256 1 1 (2048)
I0216 01:28:32.433971 32696 net.cpp:156] Memory required for data: 1891094560
I0216 01:28:32.433974 32696 layer_factory.hpp:77] Creating layer conv4_3_norm
I0216 01:28:32.433985 32696 net.cpp:91] Creating Layer conv4_3_norm
I0216 01:28:32.433991 32696 net.cpp:425] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0216 01:28:32.433997 32696 net.cpp:399] conv4_3_norm -> conv4_3_norm
I0216 01:28:32.434171 32696 net.cpp:141] Setting up conv4_3_norm
I0216 01:28:32.434182 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.434190 32696 net.cpp:156] Memory required for data: 1914441760
I0216 01:28:32.434197 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0216 01:28:32.434211 32696 net.cpp:91] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0216 01:28:32.434226 32696 net.cpp:425] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0216 01:28:32.434237 32696 net.cpp:399] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0216 01:28:32.434249 32696 net.cpp:399] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0216 01:28:32.434260 32696 net.cpp:399] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0216 01:28:32.434355 32696 net.cpp:141] Setting up conv4_3_norm_conv4_3_norm_0_split
I0216 01:28:32.434376 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.434383 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.434391 32696 net.cpp:148] Top shape: 8 512 19 75 (5836800)
I0216 01:28:32.434396 32696 net.cpp:156] Memory required for data: 1984483360
I0216 01:28:32.434401 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0216 01:28:32.434414 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_loc
I0216 01:28:32.434418 32696 net.cpp:425] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0216 01:28:32.434427 32696 net.cpp:399] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0216 01:28:32.435220 32696 net.cpp:141] Setting up conv4_3_norm_mbox_loc
I0216 01:28:32.435236 32696 net.cpp:148] Top shape: 8 12 19 75 (136800)
I0216 01:28:32.435240 32696 net.cpp:156] Memory required for data: 1985030560
I0216 01:28:32.435246 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0216 01:28:32.435257 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_loc_perm
I0216 01:28:32.435261 32696 net.cpp:425] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0216 01:28:32.435267 32696 net.cpp:399] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0216 01:28:32.435384 32696 net.cpp:141] Setting up conv4_3_norm_mbox_loc_perm
I0216 01:28:32.435394 32696 net.cpp:148] Top shape: 8 19 75 12 (136800)
I0216 01:28:32.435396 32696 net.cpp:156] Memory required for data: 1985577760
I0216 01:28:32.435400 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0216 01:28:32.435408 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_loc_flat
I0216 01:28:32.435413 32696 net.cpp:425] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0216 01:28:32.435421 32696 net.cpp:399] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0216 01:28:32.435451 32696 net.cpp:141] Setting up conv4_3_norm_mbox_loc_flat
I0216 01:28:32.435458 32696 net.cpp:148] Top shape: 8 17100 (136800)
I0216 01:28:32.435462 32696 net.cpp:156] Memory required for data: 1986124960
I0216 01:28:32.435466 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0216 01:28:32.435482 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_conf
I0216 01:28:32.435485 32696 net.cpp:425] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0216 01:28:32.435500 32696 net.cpp:399] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0216 01:28:32.436255 32696 net.cpp:141] Setting up conv4_3_norm_mbox_conf
I0216 01:28:32.436265 32696 net.cpp:148] Top shape: 8 12 19 75 (136800)
I0216 01:28:32.436269 32696 net.cpp:156] Memory required for data: 1986672160
I0216 01:28:32.436275 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0216 01:28:32.436283 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_conf_perm
I0216 01:28:32.436287 32696 net.cpp:425] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0216 01:28:32.436295 32696 net.cpp:399] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0216 01:28:32.436436 32696 net.cpp:141] Setting up conv4_3_norm_mbox_conf_perm
I0216 01:28:32.436449 32696 net.cpp:148] Top shape: 8 19 75 12 (136800)
I0216 01:28:32.436451 32696 net.cpp:156] Memory required for data: 1987219360
I0216 01:28:32.436455 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0216 01:28:32.436462 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_conf_flat
I0216 01:28:32.436466 32696 net.cpp:425] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0216 01:28:32.436475 32696 net.cpp:399] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0216 01:28:32.436499 32696 net.cpp:141] Setting up conv4_3_norm_mbox_conf_flat
I0216 01:28:32.436507 32696 net.cpp:148] Top shape: 8 17100 (136800)
I0216 01:28:32.436511 32696 net.cpp:156] Memory required for data: 1987766560
I0216 01:28:32.436513 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0216 01:28:32.436538 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_priorbox
I0216 01:28:32.436544 32696 net.cpp:425] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0216 01:28:32.436549 32696 net.cpp:425] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0216 01:28:32.436556 32696 net.cpp:399] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0216 01:28:32.436601 32696 net.cpp:141] Setting up conv4_3_norm_mbox_priorbox
I0216 01:28:32.436610 32696 net.cpp:148] Top shape: 1 2 17100 (34200)
I0216 01:28:32.436614 32696 net.cpp:156] Memory required for data: 1987903360
I0216 01:28:32.436616 32696 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0216 01:28:32.436630 32696 net.cpp:91] Creating Layer fc7_mbox_loc
I0216 01:28:32.436635 32696 net.cpp:425] fc7_mbox_loc <- fc7_relu7_0_split_1
I0216 01:28:32.436642 32696 net.cpp:399] fc7_mbox_loc -> fc7_mbox_loc
I0216 01:28:32.438493 32696 net.cpp:141] Setting up fc7_mbox_loc
I0216 01:28:32.438503 32696 net.cpp:148] Top shape: 8 24 10 38 (72960)
I0216 01:28:32.438506 32696 net.cpp:156] Memory required for data: 1988195200
I0216 01:28:32.438513 32696 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0216 01:28:32.438526 32696 net.cpp:91] Creating Layer fc7_mbox_loc_perm
I0216 01:28:32.438531 32696 net.cpp:425] fc7_mbox_loc_perm <- fc7_mbox_loc
I0216 01:28:32.438537 32696 net.cpp:399] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0216 01:28:32.438652 32696 net.cpp:141] Setting up fc7_mbox_loc_perm
I0216 01:28:32.438660 32696 net.cpp:148] Top shape: 8 10 38 24 (72960)
I0216 01:28:32.438663 32696 net.cpp:156] Memory required for data: 1988487040
I0216 01:28:32.438668 32696 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0216 01:28:32.438675 32696 net.cpp:91] Creating Layer fc7_mbox_loc_flat
I0216 01:28:32.438678 32696 net.cpp:425] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0216 01:28:32.438684 32696 net.cpp:399] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0216 01:28:32.438710 32696 net.cpp:141] Setting up fc7_mbox_loc_flat
I0216 01:28:32.438716 32696 net.cpp:148] Top shape: 8 9120 (72960)
I0216 01:28:32.438719 32696 net.cpp:156] Memory required for data: 1988778880
I0216 01:28:32.438722 32696 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0216 01:28:32.438735 32696 net.cpp:91] Creating Layer fc7_mbox_conf
I0216 01:28:32.438738 32696 net.cpp:425] fc7_mbox_conf <- fc7_relu7_0_split_2
I0216 01:28:32.438746 32696 net.cpp:399] fc7_mbox_conf -> fc7_mbox_conf
I0216 01:28:32.440600 32696 net.cpp:141] Setting up fc7_mbox_conf
I0216 01:28:32.440623 32696 net.cpp:148] Top shape: 8 24 10 38 (72960)
I0216 01:28:32.440626 32696 net.cpp:156] Memory required for data: 1989070720
I0216 01:28:32.440632 32696 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0216 01:28:32.440639 32696 net.cpp:91] Creating Layer fc7_mbox_conf_perm
I0216 01:28:32.440644 32696 net.cpp:425] fc7_mbox_conf_perm <- fc7_mbox_conf
I0216 01:28:32.440650 32696 net.cpp:399] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0216 01:28:32.440764 32696 net.cpp:141] Setting up fc7_mbox_conf_perm
I0216 01:28:32.440773 32696 net.cpp:148] Top shape: 8 10 38 24 (72960)
I0216 01:28:32.440776 32696 net.cpp:156] Memory required for data: 1989362560
I0216 01:28:32.440779 32696 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0216 01:28:32.440788 32696 net.cpp:91] Creating Layer fc7_mbox_conf_flat
I0216 01:28:32.440790 32696 net.cpp:425] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0216 01:28:32.440796 32696 net.cpp:399] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0216 01:28:32.440822 32696 net.cpp:141] Setting up fc7_mbox_conf_flat
I0216 01:28:32.440829 32696 net.cpp:148] Top shape: 8 9120 (72960)
I0216 01:28:32.440831 32696 net.cpp:156] Memory required for data: 1989654400
I0216 01:28:32.440835 32696 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0216 01:28:32.440843 32696 net.cpp:91] Creating Layer fc7_mbox_priorbox
I0216 01:28:32.440847 32696 net.cpp:425] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0216 01:28:32.440852 32696 net.cpp:425] fc7_mbox_priorbox <- data_data_0_split_2
I0216 01:28:32.440858 32696 net.cpp:399] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0216 01:28:32.440886 32696 net.cpp:141] Setting up fc7_mbox_priorbox
I0216 01:28:32.440894 32696 net.cpp:148] Top shape: 1 2 9120 (18240)
I0216 01:28:32.440896 32696 net.cpp:156] Memory required for data: 1989727360
I0216 01:28:32.440901 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0216 01:28:32.440914 32696 net.cpp:91] Creating Layer conv6_2_mbox_loc
I0216 01:28:32.440920 32696 net.cpp:425] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0216 01:28:32.440930 32696 net.cpp:399] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0216 01:28:32.442003 32696 net.cpp:141] Setting up conv6_2_mbox_loc
I0216 01:28:32.442013 32696 net.cpp:148] Top shape: 8 24 5 19 (18240)
I0216 01:28:32.442015 32696 net.cpp:156] Memory required for data: 1989800320
I0216 01:28:32.442023 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0216 01:28:32.442031 32696 net.cpp:91] Creating Layer conv6_2_mbox_loc_perm
I0216 01:28:32.442035 32696 net.cpp:425] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0216 01:28:32.442044 32696 net.cpp:399] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0216 01:28:32.442154 32696 net.cpp:141] Setting up conv6_2_mbox_loc_perm
I0216 01:28:32.442164 32696 net.cpp:148] Top shape: 8 5 19 24 (18240)
I0216 01:28:32.442167 32696 net.cpp:156] Memory required for data: 1989873280
I0216 01:28:32.442170 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0216 01:28:32.442176 32696 net.cpp:91] Creating Layer conv6_2_mbox_loc_flat
I0216 01:28:32.442181 32696 net.cpp:425] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0216 01:28:32.442186 32696 net.cpp:399] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0216 01:28:32.442211 32696 net.cpp:141] Setting up conv6_2_mbox_loc_flat
I0216 01:28:32.442219 32696 net.cpp:148] Top shape: 8 2280 (18240)
I0216 01:28:32.442221 32696 net.cpp:156] Memory required for data: 1989946240
I0216 01:28:32.442224 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0216 01:28:32.442235 32696 net.cpp:91] Creating Layer conv6_2_mbox_conf
I0216 01:28:32.442239 32696 net.cpp:425] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0216 01:28:32.442247 32696 net.cpp:399] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0216 01:28:32.443322 32696 net.cpp:141] Setting up conv6_2_mbox_conf
I0216 01:28:32.443331 32696 net.cpp:148] Top shape: 8 24 5 19 (18240)
I0216 01:28:32.443334 32696 net.cpp:156] Memory required for data: 1990019200
I0216 01:28:32.443341 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0216 01:28:32.443359 32696 net.cpp:91] Creating Layer conv6_2_mbox_conf_perm
I0216 01:28:32.443363 32696 net.cpp:425] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0216 01:28:32.443372 32696 net.cpp:399] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0216 01:28:32.443485 32696 net.cpp:141] Setting up conv6_2_mbox_conf_perm
I0216 01:28:32.443492 32696 net.cpp:148] Top shape: 8 5 19 24 (18240)
I0216 01:28:32.443495 32696 net.cpp:156] Memory required for data: 1990092160
I0216 01:28:32.443500 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0216 01:28:32.443506 32696 net.cpp:91] Creating Layer conv6_2_mbox_conf_flat
I0216 01:28:32.443509 32696 net.cpp:425] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0216 01:28:32.443517 32696 net.cpp:399] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0216 01:28:32.443539 32696 net.cpp:141] Setting up conv6_2_mbox_conf_flat
I0216 01:28:32.443547 32696 net.cpp:148] Top shape: 8 2280 (18240)
I0216 01:28:32.443549 32696 net.cpp:156] Memory required for data: 1990165120
I0216 01:28:32.443552 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0216 01:28:32.443562 32696 net.cpp:91] Creating Layer conv6_2_mbox_priorbox
I0216 01:28:32.443565 32696 net.cpp:425] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0216 01:28:32.443570 32696 net.cpp:425] conv6_2_mbox_priorbox <- data_data_0_split_3
I0216 01:28:32.443578 32696 net.cpp:399] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0216 01:28:32.443604 32696 net.cpp:141] Setting up conv6_2_mbox_priorbox
I0216 01:28:32.443612 32696 net.cpp:148] Top shape: 1 2 2280 (4560)
I0216 01:28:32.443614 32696 net.cpp:156] Memory required for data: 1990183360
I0216 01:28:32.443617 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0216 01:28:32.443632 32696 net.cpp:91] Creating Layer conv7_2_mbox_loc
I0216 01:28:32.443639 32696 net.cpp:425] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0216 01:28:32.443645 32696 net.cpp:399] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0216 01:28:32.444371 32696 net.cpp:141] Setting up conv7_2_mbox_loc
I0216 01:28:32.444380 32696 net.cpp:148] Top shape: 8 24 3 10 (5760)
I0216 01:28:32.444385 32696 net.cpp:156] Memory required for data: 1990206400
I0216 01:28:32.444391 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0216 01:28:32.444399 32696 net.cpp:91] Creating Layer conv7_2_mbox_loc_perm
I0216 01:28:32.444402 32696 net.cpp:425] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0216 01:28:32.444409 32696 net.cpp:399] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0216 01:28:32.444519 32696 net.cpp:141] Setting up conv7_2_mbox_loc_perm
I0216 01:28:32.444526 32696 net.cpp:148] Top shape: 8 3 10 24 (5760)
I0216 01:28:32.444528 32696 net.cpp:156] Memory required for data: 1990229440
I0216 01:28:32.444533 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0216 01:28:32.444538 32696 net.cpp:91] Creating Layer conv7_2_mbox_loc_flat
I0216 01:28:32.444542 32696 net.cpp:425] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0216 01:28:32.444550 32696 net.cpp:399] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0216 01:28:32.444577 32696 net.cpp:141] Setting up conv7_2_mbox_loc_flat
I0216 01:28:32.444583 32696 net.cpp:148] Top shape: 8 720 (5760)
I0216 01:28:32.444586 32696 net.cpp:156] Memory required for data: 1990252480
I0216 01:28:32.444589 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0216 01:28:32.444602 32696 net.cpp:91] Creating Layer conv7_2_mbox_conf
I0216 01:28:32.444607 32696 net.cpp:425] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0216 01:28:32.444618 32696 net.cpp:399] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0216 01:28:32.445324 32696 net.cpp:141] Setting up conv7_2_mbox_conf
I0216 01:28:32.445334 32696 net.cpp:148] Top shape: 8 24 3 10 (5760)
I0216 01:28:32.445338 32696 net.cpp:156] Memory required for data: 1990275520
I0216 01:28:32.445343 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0216 01:28:32.445353 32696 net.cpp:91] Creating Layer conv7_2_mbox_conf_perm
I0216 01:28:32.445368 32696 net.cpp:425] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0216 01:28:32.445376 32696 net.cpp:399] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0216 01:28:32.445492 32696 net.cpp:141] Setting up conv7_2_mbox_conf_perm
I0216 01:28:32.445498 32696 net.cpp:148] Top shape: 8 3 10 24 (5760)
I0216 01:28:32.445502 32696 net.cpp:156] Memory required for data: 1990298560
I0216 01:28:32.445505 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0216 01:28:32.445513 32696 net.cpp:91] Creating Layer conv7_2_mbox_conf_flat
I0216 01:28:32.445516 32696 net.cpp:425] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0216 01:28:32.445523 32696 net.cpp:399] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0216 01:28:32.445549 32696 net.cpp:141] Setting up conv7_2_mbox_conf_flat
I0216 01:28:32.445554 32696 net.cpp:148] Top shape: 8 720 (5760)
I0216 01:28:32.445557 32696 net.cpp:156] Memory required for data: 1990321600
I0216 01:28:32.445561 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0216 01:28:32.445569 32696 net.cpp:91] Creating Layer conv7_2_mbox_priorbox
I0216 01:28:32.445574 32696 net.cpp:425] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0216 01:28:32.445577 32696 net.cpp:425] conv7_2_mbox_priorbox <- data_data_0_split_4
I0216 01:28:32.445585 32696 net.cpp:399] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0216 01:28:32.445611 32696 net.cpp:141] Setting up conv7_2_mbox_priorbox
I0216 01:28:32.445617 32696 net.cpp:148] Top shape: 1 2 720 (1440)
I0216 01:28:32.445619 32696 net.cpp:156] Memory required for data: 1990327360
I0216 01:28:32.445623 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0216 01:28:32.445634 32696 net.cpp:91] Creating Layer conv8_2_mbox_loc
I0216 01:28:32.445638 32696 net.cpp:425] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0216 01:28:32.445647 32696 net.cpp:399] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0216 01:28:32.446347 32696 net.cpp:141] Setting up conv8_2_mbox_loc
I0216 01:28:32.446358 32696 net.cpp:148] Top shape: 8 24 2 5 (1920)
I0216 01:28:32.446363 32696 net.cpp:156] Memory required for data: 1990335040
I0216 01:28:32.446373 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0216 01:28:32.446385 32696 net.cpp:91] Creating Layer conv8_2_mbox_loc_perm
I0216 01:28:32.446393 32696 net.cpp:425] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0216 01:28:32.446404 32696 net.cpp:399] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0216 01:28:32.446535 32696 net.cpp:141] Setting up conv8_2_mbox_loc_perm
I0216 01:28:32.446547 32696 net.cpp:148] Top shape: 8 2 5 24 (1920)
I0216 01:28:32.446552 32696 net.cpp:156] Memory required for data: 1990342720
I0216 01:28:32.446557 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0216 01:28:32.446569 32696 net.cpp:91] Creating Layer conv8_2_mbox_loc_flat
I0216 01:28:32.446576 32696 net.cpp:425] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0216 01:28:32.446588 32696 net.cpp:399] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0216 01:28:32.446635 32696 net.cpp:141] Setting up conv8_2_mbox_loc_flat
I0216 01:28:32.446645 32696 net.cpp:148] Top shape: 8 240 (1920)
I0216 01:28:32.446651 32696 net.cpp:156] Memory required for data: 1990350400
I0216 01:28:32.446656 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0216 01:28:32.446677 32696 net.cpp:91] Creating Layer conv8_2_mbox_conf
I0216 01:28:32.446684 32696 net.cpp:425] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0216 01:28:32.446697 32696 net.cpp:399] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0216 01:28:32.447911 32696 net.cpp:141] Setting up conv8_2_mbox_conf
I0216 01:28:32.447947 32696 net.cpp:148] Top shape: 8 24 2 5 (1920)
I0216 01:28:32.447964 32696 net.cpp:156] Memory required for data: 1990358080
I0216 01:28:32.447986 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0216 01:28:32.448007 32696 net.cpp:91] Creating Layer conv8_2_mbox_conf_perm
I0216 01:28:32.448027 32696 net.cpp:425] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0216 01:28:32.448065 32696 net.cpp:399] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0216 01:28:32.448240 32696 net.cpp:141] Setting up conv8_2_mbox_conf_perm
I0216 01:28:32.448266 32696 net.cpp:148] Top shape: 8 2 5 24 (1920)
I0216 01:28:32.448281 32696 net.cpp:156] Memory required for data: 1990365760
I0216 01:28:32.448295 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0216 01:28:32.448317 32696 net.cpp:91] Creating Layer conv8_2_mbox_conf_flat
I0216 01:28:32.448333 32696 net.cpp:425] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0216 01:28:32.448355 32696 net.cpp:399] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0216 01:28:32.448405 32696 net.cpp:141] Setting up conv8_2_mbox_conf_flat
I0216 01:28:32.448431 32696 net.cpp:148] Top shape: 8 240 (1920)
I0216 01:28:32.448446 32696 net.cpp:156] Memory required for data: 1990373440
I0216 01:28:32.448460 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0216 01:28:32.448482 32696 net.cpp:91] Creating Layer conv8_2_mbox_priorbox
I0216 01:28:32.448498 32696 net.cpp:425] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0216 01:28:32.448515 32696 net.cpp:425] conv8_2_mbox_priorbox <- data_data_0_split_5
I0216 01:28:32.448539 32696 net.cpp:399] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0216 01:28:32.448590 32696 net.cpp:141] Setting up conv8_2_mbox_priorbox
I0216 01:28:32.448616 32696 net.cpp:148] Top shape: 1 2 240 (480)
I0216 01:28:32.448631 32696 net.cpp:156] Memory required for data: 1990375360
I0216 01:28:32.448645 32696 layer_factory.hpp:77] Creating layer pool6_mbox_loc
I0216 01:28:32.448673 32696 net.cpp:91] Creating Layer pool6_mbox_loc
I0216 01:28:32.448691 32696 net.cpp:425] pool6_mbox_loc <- pool6_pool6_0_split_0
I0216 01:28:32.448712 32696 net.cpp:399] pool6_mbox_loc -> pool6_mbox_loc
I0216 01:28:32.451709 32696 net.cpp:141] Setting up pool6_mbox_loc
I0216 01:28:32.451727 32696 net.cpp:148] Top shape: 8 24 1 1 (192)
I0216 01:28:32.451730 32696 net.cpp:156] Memory required for data: 1990376128
I0216 01:28:32.451756 32696 layer_factory.hpp:77] Creating layer pool6_mbox_loc_perm
I0216 01:28:32.451768 32696 net.cpp:91] Creating Layer pool6_mbox_loc_perm
I0216 01:28:32.451776 32696 net.cpp:425] pool6_mbox_loc_perm <- pool6_mbox_loc
I0216 01:28:32.451784 32696 net.cpp:399] pool6_mbox_loc_perm -> pool6_mbox_loc_perm
I0216 01:28:32.451902 32696 net.cpp:141] Setting up pool6_mbox_loc_perm
I0216 01:28:32.451910 32696 net.cpp:148] Top shape: 8 1 1 24 (192)
I0216 01:28:32.451913 32696 net.cpp:156] Memory required for data: 1990376896
I0216 01:28:32.451920 32696 layer_factory.hpp:77] Creating layer pool6_mbox_loc_flat
I0216 01:28:32.451932 32696 net.cpp:91] Creating Layer pool6_mbox_loc_flat
I0216 01:28:32.451939 32696 net.cpp:425] pool6_mbox_loc_flat <- pool6_mbox_loc_perm
I0216 01:28:32.451949 32696 net.cpp:399] pool6_mbox_loc_flat -> pool6_mbox_loc_flat
I0216 01:28:32.451980 32696 net.cpp:141] Setting up pool6_mbox_loc_flat
I0216 01:28:32.451987 32696 net.cpp:148] Top shape: 8 24 (192)
I0216 01:28:32.451989 32696 net.cpp:156] Memory required for data: 1990377664
I0216 01:28:32.451993 32696 layer_factory.hpp:77] Creating layer pool6_mbox_conf
I0216 01:28:32.452013 32696 net.cpp:91] Creating Layer pool6_mbox_conf
I0216 01:28:32.452018 32696 net.cpp:425] pool6_mbox_conf <- pool6_pool6_0_split_1
I0216 01:28:32.452025 32696 net.cpp:399] pool6_mbox_conf -> pool6_mbox_conf
I0216 01:28:32.452738 32696 net.cpp:141] Setting up pool6_mbox_conf
I0216 01:28:32.452749 32696 net.cpp:148] Top shape: 8 24 1 1 (192)
I0216 01:28:32.452752 32696 net.cpp:156] Memory required for data: 1990378432
I0216 01:28:32.452759 32696 layer_factory.hpp:77] Creating layer pool6_mbox_conf_perm
I0216 01:28:32.452769 32696 net.cpp:91] Creating Layer pool6_mbox_conf_perm
I0216 01:28:32.452775 32696 net.cpp:425] pool6_mbox_conf_perm <- pool6_mbox_conf
I0216 01:28:32.452786 32696 net.cpp:399] pool6_mbox_conf_perm -> pool6_mbox_conf_perm
I0216 01:28:32.452903 32696 net.cpp:141] Setting up pool6_mbox_conf_perm
I0216 01:28:32.452910 32696 net.cpp:148] Top shape: 8 1 1 24 (192)
I0216 01:28:32.452932 32696 net.cpp:156] Memory required for data: 1990379200
I0216 01:28:32.452936 32696 layer_factory.hpp:77] Creating layer pool6_mbox_conf_flat
I0216 01:28:32.452941 32696 net.cpp:91] Creating Layer pool6_mbox_conf_flat
I0216 01:28:32.452945 32696 net.cpp:425] pool6_mbox_conf_flat <- pool6_mbox_conf_perm
I0216 01:28:32.452956 32696 net.cpp:399] pool6_mbox_conf_flat -> pool6_mbox_conf_flat
I0216 01:28:32.452999 32696 net.cpp:141] Setting up pool6_mbox_conf_flat
I0216 01:28:32.453008 32696 net.cpp:148] Top shape: 8 24 (192)
I0216 01:28:32.453011 32696 net.cpp:156] Memory required for data: 1990379968
I0216 01:28:32.453016 32696 layer_factory.hpp:77] Creating layer pool6_mbox_priorbox
I0216 01:28:32.453025 32696 net.cpp:91] Creating Layer pool6_mbox_priorbox
I0216 01:28:32.453033 32696 net.cpp:425] pool6_mbox_priorbox <- pool6_pool6_0_split_2
I0216 01:28:32.453039 32696 net.cpp:425] pool6_mbox_priorbox <- data_data_0_split_6
I0216 01:28:32.453057 32696 net.cpp:399] pool6_mbox_priorbox -> pool6_mbox_priorbox
I0216 01:28:32.453088 32696 net.cpp:141] Setting up pool6_mbox_priorbox
I0216 01:28:32.453096 32696 net.cpp:148] Top shape: 1 2 24 (48)
I0216 01:28:32.453099 32696 net.cpp:156] Memory required for data: 1990380160
I0216 01:28:32.453106 32696 layer_factory.hpp:77] Creating layer mbox_loc
I0216 01:28:32.453119 32696 net.cpp:91] Creating Layer mbox_loc
I0216 01:28:32.453125 32696 net.cpp:425] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0216 01:28:32.453131 32696 net.cpp:425] mbox_loc <- fc7_mbox_loc_flat
I0216 01:28:32.453140 32696 net.cpp:425] mbox_loc <- conv6_2_mbox_loc_flat
I0216 01:28:32.453147 32696 net.cpp:425] mbox_loc <- conv7_2_mbox_loc_flat
I0216 01:28:32.453155 32696 net.cpp:425] mbox_loc <- conv8_2_mbox_loc_flat
I0216 01:28:32.453160 32696 net.cpp:425] mbox_loc <- pool6_mbox_loc_flat
I0216 01:28:32.453172 32696 net.cpp:399] mbox_loc -> mbox_loc
I0216 01:28:32.453207 32696 net.cpp:141] Setting up mbox_loc
I0216 01:28:32.453217 32696 net.cpp:148] Top shape: 8 29484 (235872)
I0216 01:28:32.453224 32696 net.cpp:156] Memory required for data: 1991323648
I0216 01:28:32.453229 32696 layer_factory.hpp:77] Creating layer mbox_conf
I0216 01:28:32.453239 32696 net.cpp:91] Creating Layer mbox_conf
I0216 01:28:32.453245 32696 net.cpp:425] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0216 01:28:32.453254 32696 net.cpp:425] mbox_conf <- fc7_mbox_conf_flat
I0216 01:28:32.453261 32696 net.cpp:425] mbox_conf <- conv6_2_mbox_conf_flat
I0216 01:28:32.453271 32696 net.cpp:425] mbox_conf <- conv7_2_mbox_conf_flat
I0216 01:28:32.453275 32696 net.cpp:425] mbox_conf <- conv8_2_mbox_conf_flat
I0216 01:28:32.453282 32696 net.cpp:425] mbox_conf <- pool6_mbox_conf_flat
I0216 01:28:32.453294 32696 net.cpp:399] mbox_conf -> mbox_conf
I0216 01:28:32.453325 32696 net.cpp:141] Setting up mbox_conf
I0216 01:28:32.453332 32696 net.cpp:148] Top shape: 8 29484 (235872)
I0216 01:28:32.453336 32696 net.cpp:156] Memory required for data: 1992267136
I0216 01:28:32.453342 32696 layer_factory.hpp:77] Creating layer mbox_priorbox
I0216 01:28:32.453351 32696 net.cpp:91] Creating Layer mbox_priorbox
I0216 01:28:32.453356 32696 net.cpp:425] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0216 01:28:32.453364 32696 net.cpp:425] mbox_priorbox <- fc7_mbox_priorbox
I0216 01:28:32.453373 32696 net.cpp:425] mbox_priorbox <- conv6_2_mbox_priorbox
I0216 01:28:32.453377 32696 net.cpp:425] mbox_priorbox <- conv7_2_mbox_priorbox
I0216 01:28:32.453383 32696 net.cpp:425] mbox_priorbox <- conv8_2_mbox_priorbox
I0216 01:28:32.453390 32696 net.cpp:425] mbox_priorbox <- pool6_mbox_priorbox
I0216 01:28:32.453400 32696 net.cpp:399] mbox_priorbox -> mbox_priorbox
I0216 01:28:32.453431 32696 net.cpp:141] Setting up mbox_priorbox
I0216 01:28:32.453439 32696 net.cpp:148] Top shape: 1 2 29484 (58968)
I0216 01:28:32.453443 32696 net.cpp:156] Memory required for data: 1992503008
I0216 01:28:32.453449 32696 layer_factory.hpp:77] Creating layer mbox_loss
I0216 01:28:32.453464 32696 net.cpp:91] Creating Layer mbox_loss
I0216 01:28:32.453474 32696 net.cpp:425] mbox_loss <- mbox_loc
I0216 01:28:32.453493 32696 net.cpp:425] mbox_loss <- mbox_conf
I0216 01:28:32.453498 32696 net.cpp:425] mbox_loss <- mbox_priorbox
I0216 01:28:32.453502 32696 net.cpp:425] mbox_loss <- label
I0216 01:28:32.453510 32696 net.cpp:399] mbox_loss -> mbox_loss
I0216 01:28:32.453585 32696 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0216 01:28:32.453697 32696 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0216 01:28:32.453712 32696 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0216 01:28:32.453825 32696 net.cpp:141] Setting up mbox_loss
I0216 01:28:32.453832 32696 net.cpp:148] Top shape: (1)
I0216 01:28:32.453837 32696 net.cpp:151]     with loss weight 1
I0216 01:28:32.453876 32696 net.cpp:156] Memory required for data: 1992503012
I0216 01:28:32.453879 32696 net.cpp:217] mbox_loss needs backward computation.
I0216 01:28:32.453893 32696 net.cpp:219] mbox_priorbox does not need backward computation.
I0216 01:28:32.453907 32696 net.cpp:217] mbox_conf needs backward computation.
I0216 01:28:32.453918 32696 net.cpp:217] mbox_loc needs backward computation.
I0216 01:28:32.453928 32696 net.cpp:219] pool6_mbox_priorbox does not need backward computation.
I0216 01:28:32.453936 32696 net.cpp:217] pool6_mbox_conf_flat needs backward computation.
I0216 01:28:32.453944 32696 net.cpp:217] pool6_mbox_conf_perm needs backward computation.
I0216 01:28:32.453948 32696 net.cpp:217] pool6_mbox_conf needs backward computation.
I0216 01:28:32.453953 32696 net.cpp:217] pool6_mbox_loc_flat needs backward computation.
I0216 01:28:32.453961 32696 net.cpp:217] pool6_mbox_loc_perm needs backward computation.
I0216 01:28:32.453969 32696 net.cpp:217] pool6_mbox_loc needs backward computation.
I0216 01:28:32.453976 32696 net.cpp:219] conv8_2_mbox_priorbox does not need backward computation.
I0216 01:28:32.453984 32696 net.cpp:217] conv8_2_mbox_conf_flat needs backward computation.
I0216 01:28:32.453990 32696 net.cpp:217] conv8_2_mbox_conf_perm needs backward computation.
I0216 01:28:32.453996 32696 net.cpp:217] conv8_2_mbox_conf needs backward computation.
I0216 01:28:32.454002 32696 net.cpp:217] conv8_2_mbox_loc_flat needs backward computation.
I0216 01:28:32.454007 32696 net.cpp:217] conv8_2_mbox_loc_perm needs backward computation.
I0216 01:28:32.454015 32696 net.cpp:217] conv8_2_mbox_loc needs backward computation.
I0216 01:28:32.454021 32696 net.cpp:219] conv7_2_mbox_priorbox does not need backward computation.
I0216 01:28:32.454030 32696 net.cpp:217] conv7_2_mbox_conf_flat needs backward computation.
I0216 01:28:32.454037 32696 net.cpp:217] conv7_2_mbox_conf_perm needs backward computation.
I0216 01:28:32.454042 32696 net.cpp:217] conv7_2_mbox_conf needs backward computation.
I0216 01:28:32.454049 32696 net.cpp:217] conv7_2_mbox_loc_flat needs backward computation.
I0216 01:28:32.454057 32696 net.cpp:217] conv7_2_mbox_loc_perm needs backward computation.
I0216 01:28:32.454064 32696 net.cpp:217] conv7_2_mbox_loc needs backward computation.
I0216 01:28:32.454069 32696 net.cpp:219] conv6_2_mbox_priorbox does not need backward computation.
I0216 01:28:32.454077 32696 net.cpp:217] conv6_2_mbox_conf_flat needs backward computation.
I0216 01:28:32.454085 32696 net.cpp:217] conv6_2_mbox_conf_perm needs backward computation.
I0216 01:28:32.454089 32696 net.cpp:217] conv6_2_mbox_conf needs backward computation.
I0216 01:28:32.454097 32696 net.cpp:217] conv6_2_mbox_loc_flat needs backward computation.
I0216 01:28:32.454103 32696 net.cpp:217] conv6_2_mbox_loc_perm needs backward computation.
I0216 01:28:32.454109 32696 net.cpp:217] conv6_2_mbox_loc needs backward computation.
I0216 01:28:32.454118 32696 net.cpp:219] fc7_mbox_priorbox does not need backward computation.
I0216 01:28:32.454125 32696 net.cpp:217] fc7_mbox_conf_flat needs backward computation.
I0216 01:28:32.454134 32696 net.cpp:217] fc7_mbox_conf_perm needs backward computation.
I0216 01:28:32.454139 32696 net.cpp:217] fc7_mbox_conf needs backward computation.
I0216 01:28:32.454145 32696 net.cpp:217] fc7_mbox_loc_flat needs backward computation.
I0216 01:28:32.454164 32696 net.cpp:217] fc7_mbox_loc_perm needs backward computation.
I0216 01:28:32.454170 32696 net.cpp:217] fc7_mbox_loc needs backward computation.
I0216 01:28:32.454177 32696 net.cpp:219] conv4_3_norm_mbox_priorbox does not need backward computation.
I0216 01:28:32.454186 32696 net.cpp:217] conv4_3_norm_mbox_conf_flat needs backward computation.
I0216 01:28:32.454192 32696 net.cpp:217] conv4_3_norm_mbox_conf_perm needs backward computation.
I0216 01:28:32.454201 32696 net.cpp:217] conv4_3_norm_mbox_conf needs backward computation.
I0216 01:28:32.454205 32696 net.cpp:217] conv4_3_norm_mbox_loc_flat needs backward computation.
I0216 01:28:32.454211 32696 net.cpp:217] conv4_3_norm_mbox_loc_perm needs backward computation.
I0216 01:28:32.454216 32696 net.cpp:217] conv4_3_norm_mbox_loc needs backward computation.
I0216 01:28:32.454221 32696 net.cpp:217] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0216 01:28:32.454224 32696 net.cpp:217] conv4_3_norm needs backward computation.
I0216 01:28:32.454228 32696 net.cpp:217] pool6_pool6_0_split needs backward computation.
I0216 01:28:32.454232 32696 net.cpp:217] pool6 needs backward computation.
I0216 01:28:32.454239 32696 net.cpp:217] conv8_2_conv8_2_relu_0_split needs backward computation.
I0216 01:28:32.454243 32696 net.cpp:217] conv8_2_relu needs backward computation.
I0216 01:28:32.454246 32696 net.cpp:217] conv8_2 needs backward computation.
I0216 01:28:32.454251 32696 net.cpp:217] conv8_1_relu needs backward computation.
I0216 01:28:32.454254 32696 net.cpp:217] conv8_1 needs backward computation.
I0216 01:28:32.454258 32696 net.cpp:217] conv7_2_conv7_2_relu_0_split needs backward computation.
I0216 01:28:32.454262 32696 net.cpp:217] conv7_2_relu needs backward computation.
I0216 01:28:32.454265 32696 net.cpp:217] conv7_2 needs backward computation.
I0216 01:28:32.454270 32696 net.cpp:217] conv7_1_relu needs backward computation.
I0216 01:28:32.454273 32696 net.cpp:217] conv7_1 needs backward computation.
I0216 01:28:32.454277 32696 net.cpp:217] conv6_2_conv6_2_relu_0_split needs backward computation.
I0216 01:28:32.454282 32696 net.cpp:217] conv6_2_relu needs backward computation.
I0216 01:28:32.454285 32696 net.cpp:217] conv6_2 needs backward computation.
I0216 01:28:32.454289 32696 net.cpp:217] conv6_1_relu needs backward computation.
I0216 01:28:32.454293 32696 net.cpp:217] conv6_1 needs backward computation.
I0216 01:28:32.454296 32696 net.cpp:217] fc7_relu7_0_split needs backward computation.
I0216 01:28:32.454301 32696 net.cpp:217] relu7 needs backward computation.
I0216 01:28:32.454304 32696 net.cpp:217] fc7 needs backward computation.
I0216 01:28:32.454308 32696 net.cpp:217] relu6 needs backward computation.
I0216 01:28:32.454311 32696 net.cpp:217] fc6 needs backward computation.
I0216 01:28:32.454315 32696 net.cpp:217] pool5 needs backward computation.
I0216 01:28:32.454319 32696 net.cpp:217] relu5_3 needs backward computation.
I0216 01:28:32.454324 32696 net.cpp:217] conv5_3 needs backward computation.
I0216 01:28:32.454326 32696 net.cpp:217] relu5_2 needs backward computation.
I0216 01:28:32.454330 32696 net.cpp:217] conv5_2 needs backward computation.
I0216 01:28:32.454334 32696 net.cpp:217] relu5_1 needs backward computation.
I0216 01:28:32.454337 32696 net.cpp:217] conv5_1 needs backward computation.
I0216 01:28:32.454340 32696 net.cpp:217] pool4 needs backward computation.
I0216 01:28:32.454345 32696 net.cpp:217] conv4_3_relu4_3_0_split needs backward computation.
I0216 01:28:32.454349 32696 net.cpp:217] relu4_3 needs backward computation.
I0216 01:28:32.454352 32696 net.cpp:217] conv4_3 needs backward computation.
I0216 01:28:32.454356 32696 net.cpp:217] relu4_2 needs backward computation.
I0216 01:28:32.454360 32696 net.cpp:217] conv4_2 needs backward computation.
I0216 01:28:32.454363 32696 net.cpp:217] relu4_1 needs backward computation.
I0216 01:28:32.454367 32696 net.cpp:217] conv4_1 needs backward computation.
I0216 01:28:32.454370 32696 net.cpp:217] pool3 needs backward computation.
I0216 01:28:32.454381 32696 net.cpp:217] relu3_3 needs backward computation.
I0216 01:28:32.454385 32696 net.cpp:217] conv3_3 needs backward computation.
I0216 01:28:32.454388 32696 net.cpp:217] relu3_2 needs backward computation.
I0216 01:28:32.454391 32696 net.cpp:217] conv3_2 needs backward computation.
I0216 01:28:32.454396 32696 net.cpp:217] relu3_1 needs backward computation.
I0216 01:28:32.454399 32696 net.cpp:217] conv3_1 needs backward computation.
I0216 01:28:32.454402 32696 net.cpp:219] pool2 does not need backward computation.
I0216 01:28:32.454407 32696 net.cpp:219] relu2_2 does not need backward computation.
I0216 01:28:32.454411 32696 net.cpp:219] conv2_2 does not need backward computation.
I0216 01:28:32.454416 32696 net.cpp:219] relu2_1 does not need backward computation.
I0216 01:28:32.454419 32696 net.cpp:219] conv2_1 does not need backward computation.
I0216 01:28:32.454422 32696 net.cpp:219] pool1 does not need backward computation.
I0216 01:28:32.454427 32696 net.cpp:219] relu1_2 does not need backward computation.
I0216 01:28:32.454430 32696 net.cpp:219] conv1_2 does not need backward computation.
I0216 01:28:32.454433 32696 net.cpp:219] relu1_1 does not need backward computation.
I0216 01:28:32.454437 32696 net.cpp:219] conv1_1 does not need backward computation.
I0216 01:28:32.454443 32696 net.cpp:219] data_data_0_split does not need backward computation.
I0216 01:28:32.454448 32696 net.cpp:219] data does not need backward computation.
I0216 01:28:32.454450 32696 net.cpp:261] This network produces output mbox_loss
I0216 01:28:32.454572 32696 net.cpp:274] Network initialization done.
I0216 01:28:32.455904 32696 solver.cpp:184] Creating test net (#0) specified by test_net file: /home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/test.prototxt
I0216 01:28:32.456841 32696 net.cpp:49] Initializing net from parameters: 
name: "VGG_KITTI_SSD_600x150_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 150
      width: 600
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "/home/perception/KITTI_SSD/examples/KITTI/KITTI_test_lmdb"
    batch_size: 1
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "/home/perception/KITTI_SSD//data/KITTI/labelmap_KITTI.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "pool6"
  type: "Pooling"
  bottom: "conv8_2"
  top: "pool6"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    aspect_ratio: 2
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 114
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 114
    max_size: 168
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 168
    max_size: 222
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 222
    max_size: 276
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "pool6_mbox_loc"
  type: "Convolution"
  bottom: "pool6"
  top: "pool6_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool6_mbox_loc_perm"
  type: "Permute"
  bottom: "pool6_mbox_loc"
  top: "pool6_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "pool6_mbox_loc_flat"
  type: "Flatten"
  bottom: "pool6_mbox_loc_perm"
  top: "pool6_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "pool6_mbox_conf"
  type: "Convolution"
  bottom: "pool6"
  top: "pool6_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool6_mbox_conf_perm"
  type: "Permute"
  bottom: "pool6_mbox_conf"
  top: "pool6_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "pool6_mbox_conf_flat"
  type: "Flatten"
  bottom: "pool6_mbox_conf_perm"
  top: "pool6_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "pool6_mbox_priorbox"
  type: "PriorBox"
  bottom: "pool6"
  bottom: "data"
  top: "pool6_mbox_priorbox"
  prior_box_param {
    min_size: 276
    max_size: 330
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: true
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "pool6_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "pool6_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "pool6_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 4
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "/home/perception/data/KITTI/results/KITTI/SSD_600x150/Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "/home/perception/KITTI_SSD//data/KITTI/labelmap_KITTI.prototxt"
      name_size_file: "/home/perception/KITTI_SSD//data/KITTI/test_name_size.txt"
      num_test_image: 7481
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 4
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "/home/perception/KITTI_SSD//data/KITTI/test_name_size.txt"
  }
}
I0216 01:28:32.457350 32696 layer_factory.hpp:77] Creating layer data
I0216 01:28:32.457432 32696 net.cpp:91] Creating Layer data
I0216 01:28:32.457442 32696 net.cpp:399] data -> data
I0216 01:28:32.457459 32696 net.cpp:399] data -> label
I0216 01:28:32.466781 32707 db_lmdb.cpp:13] Jerry: openning source lmdb: /home/perception/KITTI_SSD/examples/KITTI/KITTI_test_lmdb
I0216 01:28:32.467026 32707 db_lmdb.cpp:39] Opened lmdb /home/perception/KITTI_SSD/examples/KITTI/KITTI_test_lmdb
I0216 01:28:32.485888 32696 annotated_data_layer.cpp:52] output data size: 1,3,150,600
I0216 01:28:32.495342 32696 net.cpp:141] Setting up data
I0216 01:28:32.495355 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495360 32696 net.cpp:148] Top shape: 1 1 1 8 (8)
I0216 01:28:32.495363 32696 net.cpp:156] Memory required for data: 1080032
I0216 01:28:32.495368 32696 layer_factory.hpp:77] Creating layer data_data_0_split
I0216 01:28:32.495381 32696 net.cpp:91] Creating Layer data_data_0_split
I0216 01:28:32.495385 32696 net.cpp:425] data_data_0_split <- data
I0216 01:28:32.495393 32696 net.cpp:399] data_data_0_split -> data_data_0_split_0
I0216 01:28:32.495403 32696 net.cpp:399] data_data_0_split -> data_data_0_split_1
I0216 01:28:32.495409 32696 net.cpp:399] data_data_0_split -> data_data_0_split_2
I0216 01:28:32.495415 32696 net.cpp:399] data_data_0_split -> data_data_0_split_3
I0216 01:28:32.495422 32696 net.cpp:399] data_data_0_split -> data_data_0_split_4
I0216 01:28:32.495427 32696 net.cpp:399] data_data_0_split -> data_data_0_split_5
I0216 01:28:32.495432 32696 net.cpp:399] data_data_0_split -> data_data_0_split_6
I0216 01:28:32.495597 32696 net.cpp:141] Setting up data_data_0_split
I0216 01:28:32.495604 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495609 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495612 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495615 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495620 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495640 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495643 32696 net.cpp:148] Top shape: 1 3 150 600 (270000)
I0216 01:28:32.495645 32696 net.cpp:156] Memory required for data: 8640032
I0216 01:28:32.495649 32696 layer_factory.hpp:77] Creating layer conv1_1
I0216 01:28:32.495662 32696 net.cpp:91] Creating Layer conv1_1
I0216 01:28:32.495666 32696 net.cpp:425] conv1_1 <- data_data_0_split_0
I0216 01:28:32.495671 32696 net.cpp:399] conv1_1 -> conv1_1
I0216 01:28:32.496004 32696 net.cpp:141] Setting up conv1_1
I0216 01:28:32.496011 32696 net.cpp:148] Top shape: 1 64 150 600 (5760000)
I0216 01:28:32.496012 32696 net.cpp:156] Memory required for data: 31680032
I0216 01:28:32.496022 32696 layer_factory.hpp:77] Creating layer relu1_1
I0216 01:28:32.496029 32696 net.cpp:91] Creating Layer relu1_1
I0216 01:28:32.496031 32696 net.cpp:425] relu1_1 <- conv1_1
I0216 01:28:32.496037 32696 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0216 01:28:32.496042 32696 net.cpp:141] Setting up relu1_1
I0216 01:28:32.496045 32696 net.cpp:148] Top shape: 1 64 150 600 (5760000)
I0216 01:28:32.496047 32696 net.cpp:156] Memory required for data: 54720032
I0216 01:28:32.496050 32696 layer_factory.hpp:77] Creating layer conv1_2
I0216 01:28:32.496058 32696 net.cpp:91] Creating Layer conv1_2
I0216 01:28:32.496062 32696 net.cpp:425] conv1_2 <- conv1_1
I0216 01:28:32.496067 32696 net.cpp:399] conv1_2 -> conv1_2
I0216 01:28:32.496590 32696 net.cpp:141] Setting up conv1_2
I0216 01:28:32.496597 32696 net.cpp:148] Top shape: 1 64 150 600 (5760000)
I0216 01:28:32.496599 32696 net.cpp:156] Memory required for data: 77760032
I0216 01:28:32.496606 32696 layer_factory.hpp:77] Creating layer relu1_2
I0216 01:28:32.496610 32696 net.cpp:91] Creating Layer relu1_2
I0216 01:28:32.496613 32696 net.cpp:425] relu1_2 <- conv1_2
I0216 01:28:32.496618 32696 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0216 01:28:32.496623 32696 net.cpp:141] Setting up relu1_2
I0216 01:28:32.496626 32696 net.cpp:148] Top shape: 1 64 150 600 (5760000)
I0216 01:28:32.496629 32696 net.cpp:156] Memory required for data: 100800032
I0216 01:28:32.496632 32696 layer_factory.hpp:77] Creating layer pool1
I0216 01:28:32.496639 32696 net.cpp:91] Creating Layer pool1
I0216 01:28:32.496640 32696 net.cpp:425] pool1 <- conv1_2
I0216 01:28:32.496645 32696 net.cpp:399] pool1 -> pool1
I0216 01:28:32.496683 32696 net.cpp:141] Setting up pool1
I0216 01:28:32.496688 32696 net.cpp:148] Top shape: 1 64 75 300 (1440000)
I0216 01:28:32.496690 32696 net.cpp:156] Memory required for data: 106560032
I0216 01:28:32.496692 32696 layer_factory.hpp:77] Creating layer conv2_1
I0216 01:28:32.496701 32696 net.cpp:91] Creating Layer conv2_1
I0216 01:28:32.496703 32696 net.cpp:425] conv2_1 <- pool1
I0216 01:28:32.496707 32696 net.cpp:399] conv2_1 -> conv2_1
I0216 01:28:32.497387 32696 net.cpp:141] Setting up conv2_1
I0216 01:28:32.497393 32696 net.cpp:148] Top shape: 1 128 75 300 (2880000)
I0216 01:28:32.497396 32696 net.cpp:156] Memory required for data: 118080032
I0216 01:28:32.497403 32696 layer_factory.hpp:77] Creating layer relu2_1
I0216 01:28:32.497409 32696 net.cpp:91] Creating Layer relu2_1
I0216 01:28:32.497412 32696 net.cpp:425] relu2_1 <- conv2_1
I0216 01:28:32.497416 32696 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0216 01:28:32.497421 32696 net.cpp:141] Setting up relu2_1
I0216 01:28:32.497424 32696 net.cpp:148] Top shape: 1 128 75 300 (2880000)
I0216 01:28:32.497427 32696 net.cpp:156] Memory required for data: 129600032
I0216 01:28:32.497431 32696 layer_factory.hpp:77] Creating layer conv2_2
I0216 01:28:32.497437 32696 net.cpp:91] Creating Layer conv2_2
I0216 01:28:32.497439 32696 net.cpp:425] conv2_2 <- conv2_1
I0216 01:28:32.497445 32696 net.cpp:399] conv2_2 -> conv2_2
I0216 01:28:32.498574 32696 net.cpp:141] Setting up conv2_2
I0216 01:28:32.498579 32696 net.cpp:148] Top shape: 1 128 75 300 (2880000)
I0216 01:28:32.498582 32696 net.cpp:156] Memory required for data: 141120032
I0216 01:28:32.498589 32696 layer_factory.hpp:77] Creating layer relu2_2
I0216 01:28:32.498602 32696 net.cpp:91] Creating Layer relu2_2
I0216 01:28:32.498605 32696 net.cpp:425] relu2_2 <- conv2_2
I0216 01:28:32.498610 32696 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0216 01:28:32.498615 32696 net.cpp:141] Setting up relu2_2
I0216 01:28:32.498628 32696 net.cpp:148] Top shape: 1 128 75 300 (2880000)
I0216 01:28:32.498631 32696 net.cpp:156] Memory required for data: 152640032
I0216 01:28:32.498634 32696 layer_factory.hpp:77] Creating layer pool2
I0216 01:28:32.498639 32696 net.cpp:91] Creating Layer pool2
I0216 01:28:32.498642 32696 net.cpp:425] pool2 <- conv2_2
I0216 01:28:32.498646 32696 net.cpp:399] pool2 -> pool2
I0216 01:28:32.498682 32696 net.cpp:141] Setting up pool2
I0216 01:28:32.498687 32696 net.cpp:148] Top shape: 1 128 38 150 (729600)
I0216 01:28:32.498689 32696 net.cpp:156] Memory required for data: 155558432
I0216 01:28:32.498692 32696 layer_factory.hpp:77] Creating layer conv3_1
I0216 01:28:32.498699 32696 net.cpp:91] Creating Layer conv3_1
I0216 01:28:32.498703 32696 net.cpp:425] conv3_1 <- pool2
I0216 01:28:32.498708 32696 net.cpp:399] conv3_1 -> conv3_1
I0216 01:28:32.501974 32696 net.cpp:141] Setting up conv3_1
I0216 01:28:32.501988 32696 net.cpp:148] Top shape: 1 256 38 150 (1459200)
I0216 01:28:32.501992 32696 net.cpp:156] Memory required for data: 161395232
I0216 01:28:32.502002 32696 layer_factory.hpp:77] Creating layer relu3_1
I0216 01:28:32.502010 32696 net.cpp:91] Creating Layer relu3_1
I0216 01:28:32.502015 32696 net.cpp:425] relu3_1 <- conv3_1
I0216 01:28:32.502024 32696 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0216 01:28:32.502033 32696 net.cpp:141] Setting up relu3_1
I0216 01:28:32.502040 32696 net.cpp:148] Top shape: 1 256 38 150 (1459200)
I0216 01:28:32.502044 32696 net.cpp:156] Memory required for data: 167232032
I0216 01:28:32.502048 32696 layer_factory.hpp:77] Creating layer conv3_2
I0216 01:28:32.502058 32696 net.cpp:91] Creating Layer conv3_2
I0216 01:28:32.502063 32696 net.cpp:425] conv3_2 <- conv3_1
I0216 01:28:32.502073 32696 net.cpp:399] conv3_2 -> conv3_2
I0216 01:28:32.507221 32696 net.cpp:141] Setting up conv3_2
I0216 01:28:32.507237 32696 net.cpp:148] Top shape: 1 256 38 150 (1459200)
I0216 01:28:32.507242 32696 net.cpp:156] Memory required for data: 173068832
I0216 01:28:32.507252 32696 layer_factory.hpp:77] Creating layer relu3_2
I0216 01:28:32.507262 32696 net.cpp:91] Creating Layer relu3_2
I0216 01:28:32.507267 32696 net.cpp:425] relu3_2 <- conv3_2
I0216 01:28:32.507277 32696 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0216 01:28:32.507285 32696 net.cpp:141] Setting up relu3_2
I0216 01:28:32.507293 32696 net.cpp:148] Top shape: 1 256 38 150 (1459200)
I0216 01:28:32.507297 32696 net.cpp:156] Memory required for data: 178905632
I0216 01:28:32.507302 32696 layer_factory.hpp:77] Creating layer conv3_3
I0216 01:28:32.507316 32696 net.cpp:91] Creating Layer conv3_3
I0216 01:28:32.507330 32696 net.cpp:425] conv3_3 <- conv3_2
I0216 01:28:32.507339 32696 net.cpp:399] conv3_3 -> conv3_3
I0216 01:28:32.514569 32696 net.cpp:141] Setting up conv3_3
I0216 01:28:32.514585 32696 net.cpp:148] Top shape: 1 256 38 150 (1459200)
I0216 01:28:32.514591 32696 net.cpp:156] Memory required for data: 184742432
I0216 01:28:32.514600 32696 layer_factory.hpp:77] Creating layer relu3_3
I0216 01:28:32.514611 32696 net.cpp:91] Creating Layer relu3_3
I0216 01:28:32.514631 32696 net.cpp:425] relu3_3 <- conv3_3
I0216 01:28:32.514641 32696 net.cpp:386] relu3_3 -> conv3_3 (in-place)
I0216 01:28:32.514657 32696 net.cpp:141] Setting up relu3_3
I0216 01:28:32.514664 32696 net.cpp:148] Top shape: 1 256 38 150 (1459200)
I0216 01:28:32.514668 32696 net.cpp:156] Memory required for data: 190579232
I0216 01:28:32.514674 32696 layer_factory.hpp:77] Creating layer pool3
I0216 01:28:32.514683 32696 net.cpp:91] Creating Layer pool3
I0216 01:28:32.514688 32696 net.cpp:425] pool3 <- conv3_3
I0216 01:28:32.514696 32696 net.cpp:399] pool3 -> pool3
I0216 01:28:32.514744 32696 net.cpp:141] Setting up pool3
I0216 01:28:32.514770 32696 net.cpp:148] Top shape: 1 256 19 75 (364800)
I0216 01:28:32.514773 32696 net.cpp:156] Memory required for data: 192038432
I0216 01:28:32.514799 32696 layer_factory.hpp:77] Creating layer conv4_1
I0216 01:28:32.514816 32696 net.cpp:91] Creating Layer conv4_1
I0216 01:28:32.514822 32696 net.cpp:425] conv4_1 <- pool3
I0216 01:28:32.514832 32696 net.cpp:399] conv4_1 -> conv4_1
I0216 01:28:32.524835 32696 net.cpp:141] Setting up conv4_1
I0216 01:28:32.524853 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.524857 32696 net.cpp:156] Memory required for data: 194956832
I0216 01:28:32.524868 32696 layer_factory.hpp:77] Creating layer relu4_1
I0216 01:28:32.524878 32696 net.cpp:91] Creating Layer relu4_1
I0216 01:28:32.524883 32696 net.cpp:425] relu4_1 <- conv4_1
I0216 01:28:32.524891 32696 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0216 01:28:32.524900 32696 net.cpp:141] Setting up relu4_1
I0216 01:28:32.524907 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.524930 32696 net.cpp:156] Memory required for data: 197875232
I0216 01:28:32.524935 32696 layer_factory.hpp:77] Creating layer conv4_2
I0216 01:28:32.524948 32696 net.cpp:91] Creating Layer conv4_2
I0216 01:28:32.524953 32696 net.cpp:425] conv4_2 <- conv4_1
I0216 01:28:32.524963 32696 net.cpp:399] conv4_2 -> conv4_2
I0216 01:28:32.544020 32696 net.cpp:141] Setting up conv4_2
I0216 01:28:32.544049 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.544052 32696 net.cpp:156] Memory required for data: 200793632
I0216 01:28:32.544075 32696 layer_factory.hpp:77] Creating layer relu4_2
I0216 01:28:32.544090 32696 net.cpp:91] Creating Layer relu4_2
I0216 01:28:32.544096 32696 net.cpp:425] relu4_2 <- conv4_2
I0216 01:28:32.544106 32696 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0216 01:28:32.544121 32696 net.cpp:141] Setting up relu4_2
I0216 01:28:32.544142 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.544147 32696 net.cpp:156] Memory required for data: 203712032
I0216 01:28:32.544150 32696 layer_factory.hpp:77] Creating layer conv4_3
I0216 01:28:32.544167 32696 net.cpp:91] Creating Layer conv4_3
I0216 01:28:32.544179 32696 net.cpp:425] conv4_3 <- conv4_2
I0216 01:28:32.544189 32696 net.cpp:399] conv4_3 -> conv4_3
I0216 01:28:32.563349 32696 net.cpp:141] Setting up conv4_3
I0216 01:28:32.563383 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.563387 32696 net.cpp:156] Memory required for data: 206630432
I0216 01:28:32.563400 32696 layer_factory.hpp:77] Creating layer relu4_3
I0216 01:28:32.563413 32696 net.cpp:91] Creating Layer relu4_3
I0216 01:28:32.563421 32696 net.cpp:425] relu4_3 <- conv4_3
I0216 01:28:32.563431 32696 net.cpp:386] relu4_3 -> conv4_3 (in-place)
I0216 01:28:32.563443 32696 net.cpp:141] Setting up relu4_3
I0216 01:28:32.563451 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.563455 32696 net.cpp:156] Memory required for data: 209548832
I0216 01:28:32.563460 32696 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0216 01:28:32.563469 32696 net.cpp:91] Creating Layer conv4_3_relu4_3_0_split
I0216 01:28:32.563474 32696 net.cpp:425] conv4_3_relu4_3_0_split <- conv4_3
I0216 01:28:32.563484 32696 net.cpp:399] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0216 01:28:32.563495 32696 net.cpp:399] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0216 01:28:32.563549 32696 net.cpp:141] Setting up conv4_3_relu4_3_0_split
I0216 01:28:32.563558 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.563565 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.563570 32696 net.cpp:156] Memory required for data: 215385632
I0216 01:28:32.563575 32696 layer_factory.hpp:77] Creating layer pool4
I0216 01:28:32.563585 32696 net.cpp:91] Creating Layer pool4
I0216 01:28:32.563591 32696 net.cpp:425] pool4 <- conv4_3_relu4_3_0_split_0
I0216 01:28:32.563599 32696 net.cpp:399] pool4 -> pool4
I0216 01:28:32.563647 32696 net.cpp:141] Setting up pool4
I0216 01:28:32.563655 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.563660 32696 net.cpp:156] Memory required for data: 216163872
I0216 01:28:32.563693 32696 layer_factory.hpp:77] Creating layer conv5_1
I0216 01:28:32.563709 32696 net.cpp:91] Creating Layer conv5_1
I0216 01:28:32.563715 32696 net.cpp:425] conv5_1 <- pool4
I0216 01:28:32.563726 32696 net.cpp:399] conv5_1 -> conv5_1
I0216 01:28:32.582691 32696 net.cpp:141] Setting up conv5_1
I0216 01:28:32.582741 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.582744 32696 net.cpp:156] Memory required for data: 216942112
I0216 01:28:32.582759 32696 layer_factory.hpp:77] Creating layer relu5_1
I0216 01:28:32.582773 32696 net.cpp:91] Creating Layer relu5_1
I0216 01:28:32.582780 32696 net.cpp:425] relu5_1 <- conv5_1
I0216 01:28:32.582792 32696 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0216 01:28:32.582806 32696 net.cpp:141] Setting up relu5_1
I0216 01:28:32.582813 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.582818 32696 net.cpp:156] Memory required for data: 217720352
I0216 01:28:32.582821 32696 layer_factory.hpp:77] Creating layer conv5_2
I0216 01:28:32.582839 32696 net.cpp:91] Creating Layer conv5_2
I0216 01:28:32.582842 32696 net.cpp:425] conv5_2 <- conv5_1
I0216 01:28:32.582851 32696 net.cpp:399] conv5_2 -> conv5_2
I0216 01:28:32.602061 32696 net.cpp:141] Setting up conv5_2
I0216 01:28:32.602094 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.602098 32696 net.cpp:156] Memory required for data: 218498592
I0216 01:28:32.602111 32696 layer_factory.hpp:77] Creating layer relu5_2
I0216 01:28:32.602125 32696 net.cpp:91] Creating Layer relu5_2
I0216 01:28:32.602133 32696 net.cpp:425] relu5_2 <- conv5_2
I0216 01:28:32.602144 32696 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0216 01:28:32.602156 32696 net.cpp:141] Setting up relu5_2
I0216 01:28:32.602164 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.602169 32696 net.cpp:156] Memory required for data: 219276832
I0216 01:28:32.602174 32696 layer_factory.hpp:77] Creating layer conv5_3
I0216 01:28:32.602190 32696 net.cpp:91] Creating Layer conv5_3
I0216 01:28:32.602195 32696 net.cpp:425] conv5_3 <- conv5_2
I0216 01:28:32.602205 32696 net.cpp:399] conv5_3 -> conv5_3
I0216 01:28:32.621531 32696 net.cpp:141] Setting up conv5_3
I0216 01:28:32.621565 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.621570 32696 net.cpp:156] Memory required for data: 220055072
I0216 01:28:32.621587 32696 layer_factory.hpp:77] Creating layer relu5_3
I0216 01:28:32.621610 32696 net.cpp:91] Creating Layer relu5_3
I0216 01:28:32.621618 32696 net.cpp:425] relu5_3 <- conv5_3
I0216 01:28:32.621628 32696 net.cpp:386] relu5_3 -> conv5_3 (in-place)
I0216 01:28:32.621642 32696 net.cpp:141] Setting up relu5_3
I0216 01:28:32.621664 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.621667 32696 net.cpp:156] Memory required for data: 220833312
I0216 01:28:32.621672 32696 layer_factory.hpp:77] Creating layer pool5
I0216 01:28:32.621685 32696 net.cpp:91] Creating Layer pool5
I0216 01:28:32.621690 32696 net.cpp:425] pool5 <- conv5_3
I0216 01:28:32.621696 32696 net.cpp:399] pool5 -> pool5
I0216 01:28:32.621748 32696 net.cpp:141] Setting up pool5
I0216 01:28:32.621757 32696 net.cpp:148] Top shape: 1 512 10 38 (194560)
I0216 01:28:32.621762 32696 net.cpp:156] Memory required for data: 221611552
I0216 01:28:32.621767 32696 layer_factory.hpp:77] Creating layer fc6
I0216 01:28:32.621783 32696 net.cpp:91] Creating Layer fc6
I0216 01:28:32.621796 32696 net.cpp:425] fc6 <- pool5
I0216 01:28:32.621807 32696 net.cpp:399] fc6 -> fc6
I0216 01:28:32.660733 32696 net.cpp:141] Setting up fc6
I0216 01:28:32.660776 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.660782 32696 net.cpp:156] Memory required for data: 223168032
I0216 01:28:32.660796 32696 layer_factory.hpp:77] Creating layer relu6
I0216 01:28:32.660809 32696 net.cpp:91] Creating Layer relu6
I0216 01:28:32.660816 32696 net.cpp:425] relu6 <- fc6
I0216 01:28:32.660827 32696 net.cpp:386] relu6 -> fc6 (in-place)
I0216 01:28:32.660840 32696 net.cpp:141] Setting up relu6
I0216 01:28:32.660847 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.660903 32696 net.cpp:156] Memory required for data: 224724512
I0216 01:28:32.660909 32696 layer_factory.hpp:77] Creating layer fc7
I0216 01:28:32.660928 32696 net.cpp:91] Creating Layer fc7
I0216 01:28:32.660938 32696 net.cpp:425] fc7 <- fc6
I0216 01:28:32.660948 32696 net.cpp:399] fc7 -> fc7
I0216 01:28:32.670055 32696 net.cpp:141] Setting up fc7
I0216 01:28:32.670090 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.670095 32696 net.cpp:156] Memory required for data: 226280992
I0216 01:28:32.670109 32696 layer_factory.hpp:77] Creating layer relu7
I0216 01:28:32.670122 32696 net.cpp:91] Creating Layer relu7
I0216 01:28:32.670127 32696 net.cpp:425] relu7 <- fc7
I0216 01:28:32.670138 32696 net.cpp:386] relu7 -> fc7 (in-place)
I0216 01:28:32.670151 32696 net.cpp:141] Setting up relu7
I0216 01:28:32.670159 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.670163 32696 net.cpp:156] Memory required for data: 227837472
I0216 01:28:32.670168 32696 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0216 01:28:32.670179 32696 net.cpp:91] Creating Layer fc7_relu7_0_split
I0216 01:28:32.670186 32696 net.cpp:425] fc7_relu7_0_split <- fc7
I0216 01:28:32.670194 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0216 01:28:32.670207 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0216 01:28:32.670225 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0216 01:28:32.670254 32696 net.cpp:399] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0216 01:28:32.670327 32696 net.cpp:141] Setting up fc7_relu7_0_split
I0216 01:28:32.670336 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.670343 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.670351 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.670357 32696 net.cpp:148] Top shape: 1 1024 10 38 (389120)
I0216 01:28:32.670361 32696 net.cpp:156] Memory required for data: 234063392
I0216 01:28:32.670367 32696 layer_factory.hpp:77] Creating layer conv6_1
I0216 01:28:32.670384 32696 net.cpp:91] Creating Layer conv6_1
I0216 01:28:32.670397 32696 net.cpp:425] conv6_1 <- fc7_relu7_0_split_0
I0216 01:28:32.670408 32696 net.cpp:399] conv6_1 -> conv6_1
I0216 01:28:32.673921 32696 net.cpp:141] Setting up conv6_1
I0216 01:28:32.673940 32696 net.cpp:148] Top shape: 1 256 10 38 (97280)
I0216 01:28:32.673944 32696 net.cpp:156] Memory required for data: 234452512
I0216 01:28:32.673955 32696 layer_factory.hpp:77] Creating layer conv6_1_relu
I0216 01:28:32.673964 32696 net.cpp:91] Creating Layer conv6_1_relu
I0216 01:28:32.673970 32696 net.cpp:425] conv6_1_relu <- conv6_1
I0216 01:28:32.673979 32696 net.cpp:386] conv6_1_relu -> conv6_1 (in-place)
I0216 01:28:32.673990 32696 net.cpp:141] Setting up conv6_1_relu
I0216 01:28:32.673996 32696 net.cpp:148] Top shape: 1 256 10 38 (97280)
I0216 01:28:32.674001 32696 net.cpp:156] Memory required for data: 234841632
I0216 01:28:32.674006 32696 layer_factory.hpp:77] Creating layer conv6_2
I0216 01:28:32.674021 32696 net.cpp:91] Creating Layer conv6_2
I0216 01:28:32.674026 32696 net.cpp:425] conv6_2 <- conv6_1
I0216 01:28:32.674036 32696 net.cpp:399] conv6_2 -> conv6_2
I0216 01:28:32.684131 32696 net.cpp:141] Setting up conv6_2
I0216 01:28:32.684165 32696 net.cpp:148] Top shape: 1 512 5 19 (48640)
I0216 01:28:32.684170 32696 net.cpp:156] Memory required for data: 235036192
I0216 01:28:32.684195 32696 layer_factory.hpp:77] Creating layer conv6_2_relu
I0216 01:28:32.684208 32696 net.cpp:91] Creating Layer conv6_2_relu
I0216 01:28:32.684216 32696 net.cpp:425] conv6_2_relu <- conv6_2
I0216 01:28:32.684226 32696 net.cpp:386] conv6_2_relu -> conv6_2 (in-place)
I0216 01:28:32.684240 32696 net.cpp:141] Setting up conv6_2_relu
I0216 01:28:32.684247 32696 net.cpp:148] Top shape: 1 512 5 19 (48640)
I0216 01:28:32.684252 32696 net.cpp:156] Memory required for data: 235230752
I0216 01:28:32.684257 32696 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0216 01:28:32.684268 32696 net.cpp:91] Creating Layer conv6_2_conv6_2_relu_0_split
I0216 01:28:32.684299 32696 net.cpp:425] conv6_2_conv6_2_relu_0_split <- conv6_2
I0216 01:28:32.684309 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0216 01:28:32.684320 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0216 01:28:32.684332 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0216 01:28:32.684343 32696 net.cpp:399] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0216 01:28:32.684422 32696 net.cpp:141] Setting up conv6_2_conv6_2_relu_0_split
I0216 01:28:32.684429 32696 net.cpp:148] Top shape: 1 512 5 19 (48640)
I0216 01:28:32.684437 32696 net.cpp:148] Top shape: 1 512 5 19 (48640)
I0216 01:28:32.684443 32696 net.cpp:148] Top shape: 1 512 5 19 (48640)
I0216 01:28:32.684449 32696 net.cpp:148] Top shape: 1 512 5 19 (48640)
I0216 01:28:32.684454 32696 net.cpp:156] Memory required for data: 236008992
I0216 01:28:32.684460 32696 layer_factory.hpp:77] Creating layer conv7_1
I0216 01:28:32.684476 32696 net.cpp:91] Creating Layer conv7_1
I0216 01:28:32.684481 32696 net.cpp:425] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0216 01:28:32.684491 32696 net.cpp:399] conv7_1 -> conv7_1
I0216 01:28:32.685190 32696 net.cpp:141] Setting up conv7_1
I0216 01:28:32.685199 32696 net.cpp:148] Top shape: 1 128 5 19 (12160)
I0216 01:28:32.685204 32696 net.cpp:156] Memory required for data: 236057632
I0216 01:28:32.685211 32696 layer_factory.hpp:77] Creating layer conv7_1_relu
I0216 01:28:32.685221 32696 net.cpp:91] Creating Layer conv7_1_relu
I0216 01:28:32.685227 32696 net.cpp:425] conv7_1_relu <- conv7_1
I0216 01:28:32.685235 32696 net.cpp:386] conv7_1_relu -> conv7_1 (in-place)
I0216 01:28:32.685243 32696 net.cpp:141] Setting up conv7_1_relu
I0216 01:28:32.685252 32696 net.cpp:148] Top shape: 1 128 5 19 (12160)
I0216 01:28:32.685256 32696 net.cpp:156] Memory required for data: 236106272
I0216 01:28:32.685261 32696 layer_factory.hpp:77] Creating layer conv7_2
I0216 01:28:32.685271 32696 net.cpp:91] Creating Layer conv7_2
I0216 01:28:32.685277 32696 net.cpp:425] conv7_2 <- conv7_1
I0216 01:28:32.685286 32696 net.cpp:399] conv7_2 -> conv7_2
I0216 01:28:32.689021 32696 net.cpp:141] Setting up conv7_2
I0216 01:28:32.689044 32696 net.cpp:148] Top shape: 1 256 3 10 (7680)
I0216 01:28:32.689050 32696 net.cpp:156] Memory required for data: 236136992
I0216 01:28:32.689060 32696 layer_factory.hpp:77] Creating layer conv7_2_relu
I0216 01:28:32.689071 32696 net.cpp:91] Creating Layer conv7_2_relu
I0216 01:28:32.689079 32696 net.cpp:425] conv7_2_relu <- conv7_2
I0216 01:28:32.689088 32696 net.cpp:386] conv7_2_relu -> conv7_2 (in-place)
I0216 01:28:32.689100 32696 net.cpp:141] Setting up conv7_2_relu
I0216 01:28:32.689107 32696 net.cpp:148] Top shape: 1 256 3 10 (7680)
I0216 01:28:32.689112 32696 net.cpp:156] Memory required for data: 236167712
I0216 01:28:32.689118 32696 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0216 01:28:32.689128 32696 net.cpp:91] Creating Layer conv7_2_conv7_2_relu_0_split
I0216 01:28:32.689133 32696 net.cpp:425] conv7_2_conv7_2_relu_0_split <- conv7_2
I0216 01:28:32.689142 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0216 01:28:32.689155 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0216 01:28:32.689167 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0216 01:28:32.689177 32696 net.cpp:399] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0216 01:28:32.689250 32696 net.cpp:141] Setting up conv7_2_conv7_2_relu_0_split
I0216 01:28:32.689260 32696 net.cpp:148] Top shape: 1 256 3 10 (7680)
I0216 01:28:32.689265 32696 net.cpp:148] Top shape: 1 256 3 10 (7680)
I0216 01:28:32.689270 32696 net.cpp:148] Top shape: 1 256 3 10 (7680)
I0216 01:28:32.689277 32696 net.cpp:148] Top shape: 1 256 3 10 (7680)
I0216 01:28:32.689283 32696 net.cpp:156] Memory required for data: 236290592
I0216 01:28:32.689288 32696 layer_factory.hpp:77] Creating layer conv8_1
I0216 01:28:32.689306 32696 net.cpp:91] Creating Layer conv8_1
I0216 01:28:32.689324 32696 net.cpp:425] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0216 01:28:32.689337 32696 net.cpp:399] conv8_1 -> conv8_1
I0216 01:28:32.689808 32696 net.cpp:141] Setting up conv8_1
I0216 01:28:32.689817 32696 net.cpp:148] Top shape: 1 128 3 10 (3840)
I0216 01:28:32.689821 32696 net.cpp:156] Memory required for data: 236305952
I0216 01:28:32.689831 32696 layer_factory.hpp:77] Creating layer conv8_1_relu
I0216 01:28:32.689841 32696 net.cpp:91] Creating Layer conv8_1_relu
I0216 01:28:32.689846 32696 net.cpp:425] conv8_1_relu <- conv8_1
I0216 01:28:32.689853 32696 net.cpp:386] conv8_1_relu -> conv8_1 (in-place)
I0216 01:28:32.689863 32696 net.cpp:141] Setting up conv8_1_relu
I0216 01:28:32.689872 32696 net.cpp:148] Top shape: 1 128 3 10 (3840)
I0216 01:28:32.689877 32696 net.cpp:156] Memory required for data: 236321312
I0216 01:28:32.689882 32696 layer_factory.hpp:77] Creating layer conv8_2
I0216 01:28:32.689893 32696 net.cpp:91] Creating Layer conv8_2
I0216 01:28:32.689898 32696 net.cpp:425] conv8_2 <- conv8_1
I0216 01:28:32.689906 32696 net.cpp:399] conv8_2 -> conv8_2
I0216 01:28:32.693682 32696 net.cpp:141] Setting up conv8_2
I0216 01:28:32.693708 32696 net.cpp:148] Top shape: 1 256 2 5 (2560)
I0216 01:28:32.693712 32696 net.cpp:156] Memory required for data: 236331552
I0216 01:28:32.693723 32696 layer_factory.hpp:77] Creating layer conv8_2_relu
I0216 01:28:32.693733 32696 net.cpp:91] Creating Layer conv8_2_relu
I0216 01:28:32.693739 32696 net.cpp:425] conv8_2_relu <- conv8_2
I0216 01:28:32.693748 32696 net.cpp:386] conv8_2_relu -> conv8_2 (in-place)
I0216 01:28:32.693771 32696 net.cpp:141] Setting up conv8_2_relu
I0216 01:28:32.693778 32696 net.cpp:148] Top shape: 1 256 2 5 (2560)
I0216 01:28:32.693785 32696 net.cpp:156] Memory required for data: 236341792
I0216 01:28:32.693789 32696 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0216 01:28:32.693799 32696 net.cpp:91] Creating Layer conv8_2_conv8_2_relu_0_split
I0216 01:28:32.693805 32696 net.cpp:425] conv8_2_conv8_2_relu_0_split <- conv8_2
I0216 01:28:32.693815 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0216 01:28:32.693827 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0216 01:28:32.693838 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0216 01:28:32.693850 32696 net.cpp:399] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0216 01:28:32.693925 32696 net.cpp:141] Setting up conv8_2_conv8_2_relu_0_split
I0216 01:28:32.693933 32696 net.cpp:148] Top shape: 1 256 2 5 (2560)
I0216 01:28:32.693939 32696 net.cpp:148] Top shape: 1 256 2 5 (2560)
I0216 01:28:32.693944 32696 net.cpp:148] Top shape: 1 256 2 5 (2560)
I0216 01:28:32.693953 32696 net.cpp:148] Top shape: 1 256 2 5 (2560)
I0216 01:28:32.693956 32696 net.cpp:156] Memory required for data: 236382752
I0216 01:28:32.693961 32696 layer_factory.hpp:77] Creating layer pool6
I0216 01:28:32.693972 32696 net.cpp:91] Creating Layer pool6
I0216 01:28:32.693979 32696 net.cpp:425] pool6 <- conv8_2_conv8_2_relu_0_split_0
I0216 01:28:32.693987 32696 net.cpp:399] pool6 -> pool6
I0216 01:28:32.694018 32696 net.cpp:141] Setting up pool6
I0216 01:28:32.694025 32696 net.cpp:148] Top shape: 1 256 1 1 (256)
I0216 01:28:32.694031 32696 net.cpp:156] Memory required for data: 236383776
I0216 01:28:32.694034 32696 layer_factory.hpp:77] Creating layer pool6_pool6_0_split
I0216 01:28:32.694043 32696 net.cpp:91] Creating Layer pool6_pool6_0_split
I0216 01:28:32.694049 32696 net.cpp:425] pool6_pool6_0_split <- pool6
I0216 01:28:32.694058 32696 net.cpp:399] pool6_pool6_0_split -> pool6_pool6_0_split_0
I0216 01:28:32.694069 32696 net.cpp:399] pool6_pool6_0_split -> pool6_pool6_0_split_1
I0216 01:28:32.694079 32696 net.cpp:399] pool6_pool6_0_split -> pool6_pool6_0_split_2
I0216 01:28:32.694131 32696 net.cpp:141] Setting up pool6_pool6_0_split
I0216 01:28:32.694139 32696 net.cpp:148] Top shape: 1 256 1 1 (256)
I0216 01:28:32.694144 32696 net.cpp:148] Top shape: 1 256 1 1 (256)
I0216 01:28:32.694165 32696 net.cpp:148] Top shape: 1 256 1 1 (256)
I0216 01:28:32.694169 32696 net.cpp:156] Memory required for data: 236386848
I0216 01:28:32.694175 32696 layer_factory.hpp:77] Creating layer conv4_3_norm
I0216 01:28:32.694186 32696 net.cpp:91] Creating Layer conv4_3_norm
I0216 01:28:32.694191 32696 net.cpp:425] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0216 01:28:32.694200 32696 net.cpp:399] conv4_3_norm -> conv4_3_norm
I0216 01:28:32.694376 32696 net.cpp:141] Setting up conv4_3_norm
I0216 01:28:32.694385 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.694388 32696 net.cpp:156] Memory required for data: 239305248
I0216 01:28:32.694396 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0216 01:28:32.694406 32696 net.cpp:91] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0216 01:28:32.694412 32696 net.cpp:425] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0216 01:28:32.694420 32696 net.cpp:399] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0216 01:28:32.694432 32696 net.cpp:399] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0216 01:28:32.694442 32696 net.cpp:399] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0216 01:28:32.694497 32696 net.cpp:141] Setting up conv4_3_norm_conv4_3_norm_0_split
I0216 01:28:32.694504 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.694510 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.694519 32696 net.cpp:148] Top shape: 1 512 19 75 (729600)
I0216 01:28:32.694522 32696 net.cpp:156] Memory required for data: 248060448
I0216 01:28:32.694527 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0216 01:28:32.694540 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_loc
I0216 01:28:32.694546 32696 net.cpp:425] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0216 01:28:32.694555 32696 net.cpp:399] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0216 01:28:32.695191 32696 net.cpp:141] Setting up conv4_3_norm_mbox_loc
I0216 01:28:32.695201 32696 net.cpp:148] Top shape: 1 12 19 75 (17100)
I0216 01:28:32.695206 32696 net.cpp:156] Memory required for data: 248128848
I0216 01:28:32.695214 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0216 01:28:32.695226 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_loc_perm
I0216 01:28:32.695232 32696 net.cpp:425] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0216 01:28:32.695242 32696 net.cpp:399] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0216 01:28:32.695351 32696 net.cpp:141] Setting up conv4_3_norm_mbox_loc_perm
I0216 01:28:32.695359 32696 net.cpp:148] Top shape: 1 19 75 12 (17100)
I0216 01:28:32.695363 32696 net.cpp:156] Memory required for data: 248197248
I0216 01:28:32.695369 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0216 01:28:32.695379 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_loc_flat
I0216 01:28:32.695384 32696 net.cpp:425] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0216 01:28:32.695394 32696 net.cpp:399] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0216 01:28:32.695425 32696 net.cpp:141] Setting up conv4_3_norm_mbox_loc_flat
I0216 01:28:32.695431 32696 net.cpp:148] Top shape: 1 17100 (17100)
I0216 01:28:32.695436 32696 net.cpp:156] Memory required for data: 248265648
I0216 01:28:32.695439 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0216 01:28:32.695454 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_conf
I0216 01:28:32.695459 32696 net.cpp:425] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0216 01:28:32.695471 32696 net.cpp:399] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0216 01:28:32.696096 32696 net.cpp:141] Setting up conv4_3_norm_mbox_conf
I0216 01:28:32.696107 32696 net.cpp:148] Top shape: 1 12 19 75 (17100)
I0216 01:28:32.696112 32696 net.cpp:156] Memory required for data: 248334048
I0216 01:28:32.696121 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0216 01:28:32.696141 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_conf_perm
I0216 01:28:32.696149 32696 net.cpp:425] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0216 01:28:32.696158 32696 net.cpp:399] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0216 01:28:32.696267 32696 net.cpp:141] Setting up conv4_3_norm_mbox_conf_perm
I0216 01:28:32.696275 32696 net.cpp:148] Top shape: 1 19 75 12 (17100)
I0216 01:28:32.696282 32696 net.cpp:156] Memory required for data: 248402448
I0216 01:28:32.696286 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0216 01:28:32.696295 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_conf_flat
I0216 01:28:32.696301 32696 net.cpp:425] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0216 01:28:32.696311 32696 net.cpp:399] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0216 01:28:32.696341 32696 net.cpp:141] Setting up conv4_3_norm_mbox_conf_flat
I0216 01:28:32.696347 32696 net.cpp:148] Top shape: 1 17100 (17100)
I0216 01:28:32.696352 32696 net.cpp:156] Memory required for data: 248470848
I0216 01:28:32.696357 32696 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0216 01:28:32.696378 32696 net.cpp:91] Creating Layer conv4_3_norm_mbox_priorbox
I0216 01:28:32.696383 32696 net.cpp:425] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0216 01:28:32.696390 32696 net.cpp:425] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0216 01:28:32.696400 32696 net.cpp:399] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0216 01:28:32.696434 32696 net.cpp:141] Setting up conv4_3_norm_mbox_priorbox
I0216 01:28:32.696441 32696 net.cpp:148] Top shape: 1 2 17100 (34200)
I0216 01:28:32.696445 32696 net.cpp:156] Memory required for data: 248607648
I0216 01:28:32.696451 32696 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0216 01:28:32.696465 32696 net.cpp:91] Creating Layer fc7_mbox_loc
I0216 01:28:32.696471 32696 net.cpp:425] fc7_mbox_loc <- fc7_relu7_0_split_1
I0216 01:28:32.696480 32696 net.cpp:399] fc7_mbox_loc -> fc7_mbox_loc
I0216 01:28:32.698096 32696 net.cpp:141] Setting up fc7_mbox_loc
I0216 01:28:32.698104 32696 net.cpp:148] Top shape: 1 24 10 38 (9120)
I0216 01:28:32.698109 32696 net.cpp:156] Memory required for data: 248644128
I0216 01:28:32.698117 32696 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0216 01:28:32.698127 32696 net.cpp:91] Creating Layer fc7_mbox_loc_perm
I0216 01:28:32.698130 32696 net.cpp:425] fc7_mbox_loc_perm <- fc7_mbox_loc
I0216 01:28:32.698139 32696 net.cpp:399] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0216 01:28:32.698242 32696 net.cpp:141] Setting up fc7_mbox_loc_perm
I0216 01:28:32.698248 32696 net.cpp:148] Top shape: 1 10 38 24 (9120)
I0216 01:28:32.698251 32696 net.cpp:156] Memory required for data: 248680608
I0216 01:28:32.698253 32696 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0216 01:28:32.698259 32696 net.cpp:91] Creating Layer fc7_mbox_loc_flat
I0216 01:28:32.698263 32696 net.cpp:425] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0216 01:28:32.698268 32696 net.cpp:399] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0216 01:28:32.698290 32696 net.cpp:141] Setting up fc7_mbox_loc_flat
I0216 01:28:32.698294 32696 net.cpp:148] Top shape: 1 9120 (9120)
I0216 01:28:32.698298 32696 net.cpp:156] Memory required for data: 248717088
I0216 01:28:32.698300 32696 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0216 01:28:32.698309 32696 net.cpp:91] Creating Layer fc7_mbox_conf
I0216 01:28:32.698312 32696 net.cpp:425] fc7_mbox_conf <- fc7_relu7_0_split_2
I0216 01:28:32.698319 32696 net.cpp:399] fc7_mbox_conf -> fc7_mbox_conf
I0216 01:28:32.700024 32696 net.cpp:141] Setting up fc7_mbox_conf
I0216 01:28:32.700034 32696 net.cpp:148] Top shape: 1 24 10 38 (9120)
I0216 01:28:32.700038 32696 net.cpp:156] Memory required for data: 248753568
I0216 01:28:32.700048 32696 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0216 01:28:32.700060 32696 net.cpp:91] Creating Layer fc7_mbox_conf_perm
I0216 01:28:32.700067 32696 net.cpp:425] fc7_mbox_conf_perm <- fc7_mbox_conf
I0216 01:28:32.700088 32696 net.cpp:399] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0216 01:28:32.700207 32696 net.cpp:141] Setting up fc7_mbox_conf_perm
I0216 01:28:32.700217 32696 net.cpp:148] Top shape: 1 10 38 24 (9120)
I0216 01:28:32.700220 32696 net.cpp:156] Memory required for data: 248790048
I0216 01:28:32.700225 32696 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0216 01:28:32.700234 32696 net.cpp:91] Creating Layer fc7_mbox_conf_flat
I0216 01:28:32.700239 32696 net.cpp:425] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0216 01:28:32.700248 32696 net.cpp:399] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0216 01:28:32.700284 32696 net.cpp:141] Setting up fc7_mbox_conf_flat
I0216 01:28:32.700291 32696 net.cpp:148] Top shape: 1 9120 (9120)
I0216 01:28:32.700295 32696 net.cpp:156] Memory required for data: 248826528
I0216 01:28:32.700300 32696 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0216 01:28:32.700309 32696 net.cpp:91] Creating Layer fc7_mbox_priorbox
I0216 01:28:32.700315 32696 net.cpp:425] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0216 01:28:32.700322 32696 net.cpp:425] fc7_mbox_priorbox <- data_data_0_split_2
I0216 01:28:32.700331 32696 net.cpp:399] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0216 01:28:32.700367 32696 net.cpp:141] Setting up fc7_mbox_priorbox
I0216 01:28:32.700376 32696 net.cpp:148] Top shape: 1 2 9120 (18240)
I0216 01:28:32.700381 32696 net.cpp:156] Memory required for data: 248899488
I0216 01:28:32.700386 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0216 01:28:32.700399 32696 net.cpp:91] Creating Layer conv6_2_mbox_loc
I0216 01:28:32.700407 32696 net.cpp:425] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0216 01:28:32.700417 32696 net.cpp:399] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0216 01:28:32.701397 32696 net.cpp:141] Setting up conv6_2_mbox_loc
I0216 01:28:32.701406 32696 net.cpp:148] Top shape: 1 24 5 19 (2280)
I0216 01:28:32.701411 32696 net.cpp:156] Memory required for data: 248908608
I0216 01:28:32.701419 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0216 01:28:32.701431 32696 net.cpp:91] Creating Layer conv6_2_mbox_loc_perm
I0216 01:28:32.701437 32696 net.cpp:425] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0216 01:28:32.701447 32696 net.cpp:399] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0216 01:28:32.701561 32696 net.cpp:141] Setting up conv6_2_mbox_loc_perm
I0216 01:28:32.701570 32696 net.cpp:148] Top shape: 1 5 19 24 (2280)
I0216 01:28:32.701573 32696 net.cpp:156] Memory required for data: 248917728
I0216 01:28:32.701580 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0216 01:28:32.701587 32696 net.cpp:91] Creating Layer conv6_2_mbox_loc_flat
I0216 01:28:32.701592 32696 net.cpp:425] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0216 01:28:32.701601 32696 net.cpp:399] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0216 01:28:32.701632 32696 net.cpp:141] Setting up conv6_2_mbox_loc_flat
I0216 01:28:32.701638 32696 net.cpp:148] Top shape: 1 2280 (2280)
I0216 01:28:32.701642 32696 net.cpp:156] Memory required for data: 248926848
I0216 01:28:32.701647 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0216 01:28:32.701661 32696 net.cpp:91] Creating Layer conv6_2_mbox_conf
I0216 01:28:32.701666 32696 net.cpp:425] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0216 01:28:32.701676 32696 net.cpp:399] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0216 01:28:32.702656 32696 net.cpp:141] Setting up conv6_2_mbox_conf
I0216 01:28:32.702666 32696 net.cpp:148] Top shape: 1 24 5 19 (2280)
I0216 01:28:32.702671 32696 net.cpp:156] Memory required for data: 248935968
I0216 01:28:32.702679 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0216 01:28:32.702697 32696 net.cpp:91] Creating Layer conv6_2_mbox_conf_perm
I0216 01:28:32.702704 32696 net.cpp:425] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0216 01:28:32.702713 32696 net.cpp:399] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0216 01:28:32.702824 32696 net.cpp:141] Setting up conv6_2_mbox_conf_perm
I0216 01:28:32.702841 32696 net.cpp:148] Top shape: 1 5 19 24 (2280)
I0216 01:28:32.702848 32696 net.cpp:156] Memory required for data: 248945088
I0216 01:28:32.702853 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0216 01:28:32.702862 32696 net.cpp:91] Creating Layer conv6_2_mbox_conf_flat
I0216 01:28:32.702867 32696 net.cpp:425] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0216 01:28:32.702877 32696 net.cpp:399] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0216 01:28:32.702908 32696 net.cpp:141] Setting up conv6_2_mbox_conf_flat
I0216 01:28:32.702914 32696 net.cpp:148] Top shape: 1 2280 (2280)
I0216 01:28:32.702917 32696 net.cpp:156] Memory required for data: 248954208
I0216 01:28:32.702924 32696 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0216 01:28:32.702934 32696 net.cpp:91] Creating Layer conv6_2_mbox_priorbox
I0216 01:28:32.702939 32696 net.cpp:425] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0216 01:28:32.702945 32696 net.cpp:425] conv6_2_mbox_priorbox <- data_data_0_split_3
I0216 01:28:32.702957 32696 net.cpp:399] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0216 01:28:32.702988 32696 net.cpp:141] Setting up conv6_2_mbox_priorbox
I0216 01:28:32.702996 32696 net.cpp:148] Top shape: 1 2 2280 (4560)
I0216 01:28:32.703001 32696 net.cpp:156] Memory required for data: 248972448
I0216 01:28:32.703006 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0216 01:28:32.703018 32696 net.cpp:91] Creating Layer conv7_2_mbox_loc
I0216 01:28:32.703023 32696 net.cpp:425] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0216 01:28:32.703033 32696 net.cpp:399] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0216 01:28:32.703657 32696 net.cpp:141] Setting up conv7_2_mbox_loc
I0216 01:28:32.703666 32696 net.cpp:148] Top shape: 1 24 3 10 (720)
I0216 01:28:32.703670 32696 net.cpp:156] Memory required for data: 248975328
I0216 01:28:32.703678 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0216 01:28:32.703691 32696 net.cpp:91] Creating Layer conv7_2_mbox_loc_perm
I0216 01:28:32.703696 32696 net.cpp:425] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0216 01:28:32.703704 32696 net.cpp:399] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0216 01:28:32.703814 32696 net.cpp:141] Setting up conv7_2_mbox_loc_perm
I0216 01:28:32.703822 32696 net.cpp:148] Top shape: 1 3 10 24 (720)
I0216 01:28:32.703826 32696 net.cpp:156] Memory required for data: 248978208
I0216 01:28:32.703830 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0216 01:28:32.703838 32696 net.cpp:91] Creating Layer conv7_2_mbox_loc_flat
I0216 01:28:32.703845 32696 net.cpp:425] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0216 01:28:32.703855 32696 net.cpp:399] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0216 01:28:32.703884 32696 net.cpp:141] Setting up conv7_2_mbox_loc_flat
I0216 01:28:32.703891 32696 net.cpp:148] Top shape: 1 720 (720)
I0216 01:28:32.703896 32696 net.cpp:156] Memory required for data: 248981088
I0216 01:28:32.703900 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0216 01:28:32.703912 32696 net.cpp:91] Creating Layer conv7_2_mbox_conf
I0216 01:28:32.703917 32696 net.cpp:425] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0216 01:28:32.703929 32696 net.cpp:399] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0216 01:28:32.704546 32696 net.cpp:141] Setting up conv7_2_mbox_conf
I0216 01:28:32.704555 32696 net.cpp:148] Top shape: 1 24 3 10 (720)
I0216 01:28:32.704560 32696 net.cpp:156] Memory required for data: 248983968
I0216 01:28:32.704568 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0216 01:28:32.704579 32696 net.cpp:91] Creating Layer conv7_2_mbox_conf_perm
I0216 01:28:32.704586 32696 net.cpp:425] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0216 01:28:32.704594 32696 net.cpp:399] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0216 01:28:32.704704 32696 net.cpp:141] Setting up conv7_2_mbox_conf_perm
I0216 01:28:32.704711 32696 net.cpp:148] Top shape: 1 3 10 24 (720)
I0216 01:28:32.704715 32696 net.cpp:156] Memory required for data: 248986848
I0216 01:28:32.704730 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0216 01:28:32.704741 32696 net.cpp:91] Creating Layer conv7_2_mbox_conf_flat
I0216 01:28:32.704746 32696 net.cpp:425] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0216 01:28:32.704756 32696 net.cpp:399] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0216 01:28:32.704788 32696 net.cpp:141] Setting up conv7_2_mbox_conf_flat
I0216 01:28:32.704797 32696 net.cpp:148] Top shape: 1 720 (720)
I0216 01:28:32.704800 32696 net.cpp:156] Memory required for data: 248989728
I0216 01:28:32.704805 32696 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0216 01:28:32.704815 32696 net.cpp:91] Creating Layer conv7_2_mbox_priorbox
I0216 01:28:32.704821 32696 net.cpp:425] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0216 01:28:32.704828 32696 net.cpp:425] conv7_2_mbox_priorbox <- data_data_0_split_4
I0216 01:28:32.704838 32696 net.cpp:399] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0216 01:28:32.704874 32696 net.cpp:141] Setting up conv7_2_mbox_priorbox
I0216 01:28:32.704880 32696 net.cpp:148] Top shape: 1 2 720 (1440)
I0216 01:28:32.704885 32696 net.cpp:156] Memory required for data: 248995488
I0216 01:28:32.704888 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0216 01:28:32.704902 32696 net.cpp:91] Creating Layer conv8_2_mbox_loc
I0216 01:28:32.704908 32696 net.cpp:425] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0216 01:28:32.704919 32696 net.cpp:399] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0216 01:28:32.706933 32696 net.cpp:141] Setting up conv8_2_mbox_loc
I0216 01:28:32.706953 32696 net.cpp:148] Top shape: 1 24 2 5 (240)
I0216 01:28:32.706956 32696 net.cpp:156] Memory required for data: 248996448
I0216 01:28:32.706966 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0216 01:28:32.706979 32696 net.cpp:91] Creating Layer conv8_2_mbox_loc_perm
I0216 01:28:32.706986 32696 net.cpp:425] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0216 01:28:32.707000 32696 net.cpp:399] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0216 01:28:32.707115 32696 net.cpp:141] Setting up conv8_2_mbox_loc_perm
I0216 01:28:32.707123 32696 net.cpp:148] Top shape: 1 2 5 24 (240)
I0216 01:28:32.707128 32696 net.cpp:156] Memory required for data: 248997408
I0216 01:28:32.707132 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0216 01:28:32.707141 32696 net.cpp:91] Creating Layer conv8_2_mbox_loc_flat
I0216 01:28:32.707147 32696 net.cpp:425] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0216 01:28:32.707156 32696 net.cpp:399] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0216 01:28:32.707188 32696 net.cpp:141] Setting up conv8_2_mbox_loc_flat
I0216 01:28:32.707195 32696 net.cpp:148] Top shape: 1 240 (240)
I0216 01:28:32.707198 32696 net.cpp:156] Memory required for data: 248998368
I0216 01:28:32.707203 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0216 01:28:32.707218 32696 net.cpp:91] Creating Layer conv8_2_mbox_conf
I0216 01:28:32.707223 32696 net.cpp:425] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0216 01:28:32.707234 32696 net.cpp:399] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0216 01:28:32.707837 32696 net.cpp:141] Setting up conv8_2_mbox_conf
I0216 01:28:32.707849 32696 net.cpp:148] Top shape: 1 24 2 5 (240)
I0216 01:28:32.707851 32696 net.cpp:156] Memory required for data: 248999328
I0216 01:28:32.707860 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0216 01:28:32.707871 32696 net.cpp:91] Creating Layer conv8_2_mbox_conf_perm
I0216 01:28:32.707878 32696 net.cpp:425] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0216 01:28:32.707887 32696 net.cpp:399] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0216 01:28:32.707996 32696 net.cpp:141] Setting up conv8_2_mbox_conf_perm
I0216 01:28:32.708004 32696 net.cpp:148] Top shape: 1 2 5 24 (240)
I0216 01:28:32.708009 32696 net.cpp:156] Memory required for data: 249000288
I0216 01:28:32.708014 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0216 01:28:32.708021 32696 net.cpp:91] Creating Layer conv8_2_mbox_conf_flat
I0216 01:28:32.708045 32696 net.cpp:425] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0216 01:28:32.708055 32696 net.cpp:399] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0216 01:28:32.708087 32696 net.cpp:141] Setting up conv8_2_mbox_conf_flat
I0216 01:28:32.708093 32696 net.cpp:148] Top shape: 1 240 (240)
I0216 01:28:32.708097 32696 net.cpp:156] Memory required for data: 249001248
I0216 01:28:32.708103 32696 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0216 01:28:32.708115 32696 net.cpp:91] Creating Layer conv8_2_mbox_priorbox
I0216 01:28:32.708122 32696 net.cpp:425] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0216 01:28:32.708127 32696 net.cpp:425] conv8_2_mbox_priorbox <- data_data_0_split_5
I0216 01:28:32.708139 32696 net.cpp:399] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0216 01:28:32.708173 32696 net.cpp:141] Setting up conv8_2_mbox_priorbox
I0216 01:28:32.708179 32696 net.cpp:148] Top shape: 1 2 240 (480)
I0216 01:28:32.708184 32696 net.cpp:156] Memory required for data: 249003168
I0216 01:28:32.708189 32696 layer_factory.hpp:77] Creating layer pool6_mbox_loc
I0216 01:28:32.708201 32696 net.cpp:91] Creating Layer pool6_mbox_loc
I0216 01:28:32.708207 32696 net.cpp:425] pool6_mbox_loc <- pool6_pool6_0_split_0
I0216 01:28:32.708217 32696 net.cpp:399] pool6_mbox_loc -> pool6_mbox_loc
I0216 01:28:32.708832 32696 net.cpp:141] Setting up pool6_mbox_loc
I0216 01:28:32.708839 32696 net.cpp:148] Top shape: 1 24 1 1 (24)
I0216 01:28:32.708843 32696 net.cpp:156] Memory required for data: 249003264
I0216 01:28:32.708863 32696 layer_factory.hpp:77] Creating layer pool6_mbox_loc_perm
I0216 01:28:32.708874 32696 net.cpp:91] Creating Layer pool6_mbox_loc_perm
I0216 01:28:32.708880 32696 net.cpp:425] pool6_mbox_loc_perm <- pool6_mbox_loc
I0216 01:28:32.708889 32696 net.cpp:399] pool6_mbox_loc_perm -> pool6_mbox_loc_perm
I0216 01:28:32.708997 32696 net.cpp:141] Setting up pool6_mbox_loc_perm
I0216 01:28:32.709004 32696 net.cpp:148] Top shape: 1 1 1 24 (24)
I0216 01:28:32.709008 32696 net.cpp:156] Memory required for data: 249003360
I0216 01:28:32.709012 32696 layer_factory.hpp:77] Creating layer pool6_mbox_loc_flat
I0216 01:28:32.709022 32696 net.cpp:91] Creating Layer pool6_mbox_loc_flat
I0216 01:28:32.709029 32696 net.cpp:425] pool6_mbox_loc_flat <- pool6_mbox_loc_perm
I0216 01:28:32.709038 32696 net.cpp:399] pool6_mbox_loc_flat -> pool6_mbox_loc_flat
I0216 01:28:32.709067 32696 net.cpp:141] Setting up pool6_mbox_loc_flat
I0216 01:28:32.709074 32696 net.cpp:148] Top shape: 1 24 (24)
I0216 01:28:32.709079 32696 net.cpp:156] Memory required for data: 249003456
I0216 01:28:32.709084 32696 layer_factory.hpp:77] Creating layer pool6_mbox_conf
I0216 01:28:32.709095 32696 net.cpp:91] Creating Layer pool6_mbox_conf
I0216 01:28:32.709100 32696 net.cpp:425] pool6_mbox_conf <- pool6_pool6_0_split_1
I0216 01:28:32.709110 32696 net.cpp:399] pool6_mbox_conf -> pool6_mbox_conf
I0216 01:28:32.709733 32696 net.cpp:141] Setting up pool6_mbox_conf
I0216 01:28:32.709741 32696 net.cpp:148] Top shape: 1 24 1 1 (24)
I0216 01:28:32.709745 32696 net.cpp:156] Memory required for data: 249003552
I0216 01:28:32.709755 32696 layer_factory.hpp:77] Creating layer pool6_mbox_conf_perm
I0216 01:28:32.709771 32696 net.cpp:91] Creating Layer pool6_mbox_conf_perm
I0216 01:28:32.709777 32696 net.cpp:425] pool6_mbox_conf_perm <- pool6_mbox_conf
I0216 01:28:32.709785 32696 net.cpp:399] pool6_mbox_conf_perm -> pool6_mbox_conf_perm
I0216 01:28:32.709893 32696 net.cpp:141] Setting up pool6_mbox_conf_perm
I0216 01:28:32.709900 32696 net.cpp:148] Top shape: 1 1 1 24 (24)
I0216 01:28:32.709904 32696 net.cpp:156] Memory required for data: 249003648
I0216 01:28:32.709908 32696 layer_factory.hpp:77] Creating layer pool6_mbox_conf_flat
I0216 01:28:32.709918 32696 net.cpp:91] Creating Layer pool6_mbox_conf_flat
I0216 01:28:32.709923 32696 net.cpp:425] pool6_mbox_conf_flat <- pool6_mbox_conf_perm
I0216 01:28:32.709931 32696 net.cpp:399] pool6_mbox_conf_flat -> pool6_mbox_conf_flat
I0216 01:28:32.709972 32696 net.cpp:141] Setting up pool6_mbox_conf_flat
I0216 01:28:32.709980 32696 net.cpp:148] Top shape: 1 24 (24)
I0216 01:28:32.709983 32696 net.cpp:156] Memory required for data: 249003744
I0216 01:28:32.709988 32696 layer_factory.hpp:77] Creating layer pool6_mbox_priorbox
I0216 01:28:32.709997 32696 net.cpp:91] Creating Layer pool6_mbox_priorbox
I0216 01:28:32.710005 32696 net.cpp:425] pool6_mbox_priorbox <- pool6_pool6_0_split_2
I0216 01:28:32.710011 32696 net.cpp:425] pool6_mbox_priorbox <- data_data_0_split_6
I0216 01:28:32.710019 32696 net.cpp:399] pool6_mbox_priorbox -> pool6_mbox_priorbox
I0216 01:28:32.710050 32696 net.cpp:141] Setting up pool6_mbox_priorbox
I0216 01:28:32.710058 32696 net.cpp:148] Top shape: 1 2 24 (48)
I0216 01:28:32.710062 32696 net.cpp:156] Memory required for data: 249003936
I0216 01:28:32.710067 32696 layer_factory.hpp:77] Creating layer mbox_loc
I0216 01:28:32.710078 32696 net.cpp:91] Creating Layer mbox_loc
I0216 01:28:32.710084 32696 net.cpp:425] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0216 01:28:32.710091 32696 net.cpp:425] mbox_loc <- fc7_mbox_loc_flat
I0216 01:28:32.710099 32696 net.cpp:425] mbox_loc <- conv6_2_mbox_loc_flat
I0216 01:28:32.710108 32696 net.cpp:425] mbox_loc <- conv7_2_mbox_loc_flat
I0216 01:28:32.710115 32696 net.cpp:425] mbox_loc <- conv8_2_mbox_loc_flat
I0216 01:28:32.710121 32696 net.cpp:425] mbox_loc <- pool6_mbox_loc_flat
I0216 01:28:32.710130 32696 net.cpp:399] mbox_loc -> mbox_loc
I0216 01:28:32.710163 32696 net.cpp:141] Setting up mbox_loc
I0216 01:28:32.710171 32696 net.cpp:148] Top shape: 1 29484 (29484)
I0216 01:28:32.710175 32696 net.cpp:156] Memory required for data: 249121872
I0216 01:28:32.710180 32696 layer_factory.hpp:77] Creating layer mbox_conf
I0216 01:28:32.710188 32696 net.cpp:91] Creating Layer mbox_conf
I0216 01:28:32.710196 32696 net.cpp:425] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0216 01:28:32.710202 32696 net.cpp:425] mbox_conf <- fc7_mbox_conf_flat
I0216 01:28:32.710209 32696 net.cpp:425] mbox_conf <- conv6_2_mbox_conf_flat
I0216 01:28:32.710217 32696 net.cpp:425] mbox_conf <- conv7_2_mbox_conf_flat
I0216 01:28:32.710224 32696 net.cpp:425] mbox_conf <- conv8_2_mbox_conf_flat
I0216 01:28:32.710229 32696 net.cpp:425] mbox_conf <- pool6_mbox_conf_flat
I0216 01:28:32.710238 32696 net.cpp:399] mbox_conf -> mbox_conf
I0216 01:28:32.710268 32696 net.cpp:141] Setting up mbox_conf
I0216 01:28:32.710274 32696 net.cpp:148] Top shape: 1 29484 (29484)
I0216 01:28:32.710278 32696 net.cpp:156] Memory required for data: 249239808
I0216 01:28:32.710283 32696 layer_factory.hpp:77] Creating layer mbox_priorbox
I0216 01:28:32.710290 32696 net.cpp:91] Creating Layer mbox_priorbox
I0216 01:28:32.710297 32696 net.cpp:425] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0216 01:28:32.710304 32696 net.cpp:425] mbox_priorbox <- fc7_mbox_priorbox
I0216 01:28:32.710310 32696 net.cpp:425] mbox_priorbox <- conv6_2_mbox_priorbox
I0216 01:28:32.710316 32696 net.cpp:425] mbox_priorbox <- conv7_2_mbox_priorbox
I0216 01:28:32.710324 32696 net.cpp:425] mbox_priorbox <- conv8_2_mbox_priorbox
I0216 01:28:32.710328 32696 net.cpp:425] mbox_priorbox <- pool6_mbox_priorbox
I0216 01:28:32.710336 32696 net.cpp:399] mbox_priorbox -> mbox_priorbox
I0216 01:28:32.710366 32696 net.cpp:141] Setting up mbox_priorbox
I0216 01:28:32.710373 32696 net.cpp:148] Top shape: 1 2 29484 (58968)
I0216 01:28:32.710377 32696 net.cpp:156] Memory required for data: 249475680
I0216 01:28:32.710381 32696 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0216 01:28:32.710392 32696 net.cpp:91] Creating Layer mbox_conf_reshape
I0216 01:28:32.710398 32696 net.cpp:425] mbox_conf_reshape <- mbox_conf
I0216 01:28:32.710407 32696 net.cpp:399] mbox_conf_reshape -> mbox_conf_reshape
I0216 01:28:32.710448 32696 net.cpp:141] Setting up mbox_conf_reshape
I0216 01:28:32.710455 32696 net.cpp:148] Top shape: 1 7371 4 (29484)
I0216 01:28:32.710461 32696 net.cpp:156] Memory required for data: 249593616
I0216 01:28:32.710465 32696 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0216 01:28:32.710485 32696 net.cpp:91] Creating Layer mbox_conf_softmax
I0216 01:28:32.710490 32696 net.cpp:425] mbox_conf_softmax <- mbox_conf_reshape
I0216 01:28:32.710500 32696 net.cpp:399] mbox_conf_softmax -> mbox_conf_softmax
I0216 01:28:32.710573 32696 net.cpp:141] Setting up mbox_conf_softmax
I0216 01:28:32.710582 32696 net.cpp:148] Top shape: 1 7371 4 (29484)
I0216 01:28:32.710585 32696 net.cpp:156] Memory required for data: 249711552
I0216 01:28:32.710592 32696 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0216 01:28:32.710600 32696 net.cpp:91] Creating Layer mbox_conf_flatten
I0216 01:28:32.710607 32696 net.cpp:425] mbox_conf_flatten <- mbox_conf_softmax
I0216 01:28:32.710614 32696 net.cpp:399] mbox_conf_flatten -> mbox_conf_flatten
I0216 01:28:32.710655 32696 net.cpp:141] Setting up mbox_conf_flatten
I0216 01:28:32.710664 32696 net.cpp:148] Top shape: 1 29484 (29484)
I0216 01:28:32.710666 32696 net.cpp:156] Memory required for data: 249829488
I0216 01:28:32.710671 32696 layer_factory.hpp:77] Creating layer detection_out
I0216 01:28:32.710690 32696 net.cpp:91] Creating Layer detection_out
I0216 01:28:32.710695 32696 net.cpp:425] detection_out <- mbox_loc
I0216 01:28:32.710701 32696 net.cpp:425] detection_out <- mbox_conf_flatten
I0216 01:28:32.710706 32696 net.cpp:425] detection_out <- mbox_priorbox
I0216 01:28:32.710718 32696 net.cpp:399] detection_out -> detection_out
I0216 01:28:32.723644 32696 net.cpp:141] Setting up detection_out
I0216 01:28:32.723690 32696 net.cpp:148] Top shape: 1 1 1 7 (7)
I0216 01:28:32.723695 32696 net.cpp:156] Memory required for data: 249829516
I0216 01:28:32.723711 32696 layer_factory.hpp:77] Creating layer detection_eval
I0216 01:28:32.723742 32696 net.cpp:91] Creating Layer detection_eval
I0216 01:28:32.723752 32696 net.cpp:425] detection_eval <- detection_out
I0216 01:28:32.723763 32696 net.cpp:425] detection_eval <- label
I0216 01:28:32.723778 32696 net.cpp:399] detection_eval -> detection_eval
I0216 01:28:32.727552 32696 net.cpp:141] Setting up detection_eval
I0216 01:28:32.727568 32696 net.cpp:148] Top shape: 1 1 4 5 (20)
I0216 01:28:32.727591 32696 net.cpp:156] Memory required for data: 249829596
I0216 01:28:32.727598 32696 net.cpp:219] detection_eval does not need backward computation.
I0216 01:28:32.727608 32696 net.cpp:219] detection_out does not need backward computation.
I0216 01:28:32.727635 32696 net.cpp:219] mbox_conf_flatten does not need backward computation.
I0216 01:28:32.727643 32696 net.cpp:219] mbox_conf_softmax does not need backward computation.
I0216 01:28:32.727669 32696 net.cpp:219] mbox_conf_reshape does not need backward computation.
I0216 01:28:32.727677 32696 net.cpp:219] mbox_priorbox does not need backward computation.
I0216 01:28:32.727689 32696 net.cpp:219] mbox_conf does not need backward computation.
I0216 01:28:32.727718 32696 net.cpp:219] mbox_loc does not need backward computation.
I0216 01:28:32.727751 32696 net.cpp:219] pool6_mbox_priorbox does not need backward computation.
I0216 01:28:32.727761 32696 net.cpp:219] pool6_mbox_conf_flat does not need backward computation.
I0216 01:28:32.727769 32696 net.cpp:219] pool6_mbox_conf_perm does not need backward computation.
I0216 01:28:32.727795 32696 net.cpp:219] pool6_mbox_conf does not need backward computation.
I0216 01:28:32.727804 32696 net.cpp:219] pool6_mbox_loc_flat does not need backward computation.
I0216 01:28:32.727812 32696 net.cpp:219] pool6_mbox_loc_perm does not need backward computation.
I0216 01:28:32.727836 32696 net.cpp:219] pool6_mbox_loc does not need backward computation.
I0216 01:28:32.727843 32696 net.cpp:219] conv8_2_mbox_priorbox does not need backward computation.
I0216 01:28:32.727854 32696 net.cpp:219] conv8_2_mbox_conf_flat does not need backward computation.
I0216 01:28:32.727895 32696 net.cpp:219] conv8_2_mbox_conf_perm does not need backward computation.
I0216 01:28:32.727921 32696 net.cpp:219] conv8_2_mbox_conf does not need backward computation.
I0216 01:28:32.727928 32696 net.cpp:219] conv8_2_mbox_loc_flat does not need backward computation.
I0216 01:28:32.728003 32696 net.cpp:219] conv8_2_mbox_loc_perm does not need backward computation.
I0216 01:28:32.728011 32696 net.cpp:219] conv8_2_mbox_loc does not need backward computation.
I0216 01:28:32.728034 32696 net.cpp:219] conv7_2_mbox_priorbox does not need backward computation.
I0216 01:28:32.728044 32696 net.cpp:219] conv7_2_mbox_conf_flat does not need backward computation.
I0216 01:28:32.728054 32696 net.cpp:219] conv7_2_mbox_conf_perm does not need backward computation.
I0216 01:28:32.728060 32696 net.cpp:219] conv7_2_mbox_conf does not need backward computation.
I0216 01:28:32.728068 32696 net.cpp:219] conv7_2_mbox_loc_flat does not need backward computation.
I0216 01:28:32.728075 32696 net.cpp:219] conv7_2_mbox_loc_perm does not need backward computation.
I0216 01:28:32.728085 32696 net.cpp:219] conv7_2_mbox_loc does not need backward computation.
I0216 01:28:32.728091 32696 net.cpp:219] conv6_2_mbox_priorbox does not need backward computation.
I0216 01:28:32.728101 32696 net.cpp:219] conv6_2_mbox_conf_flat does not need backward computation.
I0216 01:28:32.728108 32696 net.cpp:219] conv6_2_mbox_conf_perm does not need backward computation.
I0216 01:28:32.728118 32696 net.cpp:219] conv6_2_mbox_conf does not need backward computation.
I0216 01:28:32.728124 32696 net.cpp:219] conv6_2_mbox_loc_flat does not need backward computation.
I0216 01:28:32.728132 32696 net.cpp:219] conv6_2_mbox_loc_perm does not need backward computation.
I0216 01:28:32.728139 32696 net.cpp:219] conv6_2_mbox_loc does not need backward computation.
I0216 01:28:32.728149 32696 net.cpp:219] fc7_mbox_priorbox does not need backward computation.
I0216 01:28:32.728158 32696 net.cpp:219] fc7_mbox_conf_flat does not need backward computation.
I0216 01:28:32.728166 32696 net.cpp:219] fc7_mbox_conf_perm does not need backward computation.
I0216 01:28:32.728173 32696 net.cpp:219] fc7_mbox_conf does not need backward computation.
I0216 01:28:32.728183 32696 net.cpp:219] fc7_mbox_loc_flat does not need backward computation.
I0216 01:28:32.728190 32696 net.cpp:219] fc7_mbox_loc_perm does not need backward computation.
I0216 01:28:32.728199 32696 net.cpp:219] fc7_mbox_loc does not need backward computation.
I0216 01:28:32.728205 32696 net.cpp:219] conv4_3_norm_mbox_priorbox does not need backward computation.
I0216 01:28:32.728215 32696 net.cpp:219] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0216 01:28:32.728224 32696 net.cpp:219] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0216 01:28:32.728231 32696 net.cpp:219] conv4_3_norm_mbox_conf does not need backward computation.
I0216 01:28:32.728240 32696 net.cpp:219] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0216 01:28:32.728248 32696 net.cpp:219] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0216 01:28:32.728256 32696 net.cpp:219] conv4_3_norm_mbox_loc does not need backward computation.
I0216 01:28:32.728272 32696 net.cpp:219] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0216 01:28:32.728281 32696 net.cpp:219] conv4_3_norm does not need backward computation.
I0216 01:28:32.728288 32696 net.cpp:219] pool6_pool6_0_split does not need backward computation.
I0216 01:28:32.728313 32696 net.cpp:219] pool6 does not need backward computation.
I0216 01:28:32.728322 32696 net.cpp:219] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0216 01:28:32.728329 32696 net.cpp:219] conv8_2_relu does not need backward computation.
I0216 01:28:32.728356 32696 net.cpp:219] conv8_2 does not need backward computation.
I0216 01:28:32.728363 32696 net.cpp:219] conv8_1_relu does not need backward computation.
I0216 01:28:32.728369 32696 net.cpp:219] conv8_1 does not need backward computation.
I0216 01:28:32.728392 32696 net.cpp:219] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0216 01:28:32.728402 32696 net.cpp:219] conv7_2_relu does not need backward computation.
I0216 01:28:32.728407 32696 net.cpp:219] conv7_2 does not need backward computation.
I0216 01:28:32.728415 32696 net.cpp:219] conv7_1_relu does not need backward computation.
I0216 01:28:32.728448 32696 net.cpp:219] conv7_1 does not need backward computation.
I0216 01:28:32.728472 32696 net.cpp:219] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0216 01:28:32.728487 32696 net.cpp:219] conv6_2_relu does not need backward computation.
I0216 01:28:32.728493 32696 net.cpp:219] conv6_2 does not need backward computation.
I0216 01:28:32.728516 32696 net.cpp:219] conv6_1_relu does not need backward computation.
I0216 01:28:32.728523 32696 net.cpp:219] conv6_1 does not need backward computation.
I0216 01:28:32.728533 32696 net.cpp:219] fc7_relu7_0_split does not need backward computation.
I0216 01:28:32.728554 32696 net.cpp:219] relu7 does not need backward computation.
I0216 01:28:32.728561 32696 net.cpp:219] fc7 does not need backward computation.
I0216 01:28:32.728570 32696 net.cpp:219] relu6 does not need backward computation.
I0216 01:28:32.728577 32696 net.cpp:219] fc6 does not need backward computation.
I0216 01:28:32.728603 32696 net.cpp:219] pool5 does not need backward computation.
I0216 01:28:32.728610 32696 net.cpp:219] relu5_3 does not need backward computation.
I0216 01:28:32.728619 32696 net.cpp:219] conv5_3 does not need backward computation.
I0216 01:28:32.728641 32696 net.cpp:219] relu5_2 does not need backward computation.
I0216 01:28:32.728647 32696 net.cpp:219] conv5_2 does not need backward computation.
I0216 01:28:32.728654 32696 net.cpp:219] relu5_1 does not need backward computation.
I0216 01:28:32.728682 32696 net.cpp:219] conv5_1 does not need backward computation.
I0216 01:28:32.728688 32696 net.cpp:219] pool4 does not need backward computation.
I0216 01:28:32.728698 32696 net.cpp:219] conv4_3_relu4_3_0_split does not need backward computation.
I0216 01:28:32.728754 32696 net.cpp:219] relu4_3 does not need backward computation.
I0216 01:28:32.728765 32696 net.cpp:219] conv4_3 does not need backward computation.
I0216 01:28:32.728770 32696 net.cpp:219] relu4_2 does not need backward computation.
I0216 01:28:32.728776 32696 net.cpp:219] conv4_2 does not need backward computation.
I0216 01:28:32.728783 32696 net.cpp:219] relu4_1 does not need backward computation.
I0216 01:28:32.728803 32696 net.cpp:219] conv4_1 does not need backward computation.
I0216 01:28:32.728809 32696 net.cpp:219] pool3 does not need backward computation.
I0216 01:28:32.728814 32696 net.cpp:219] relu3_3 does not need backward computation.
I0216 01:28:32.728821 32696 net.cpp:219] conv3_3 does not need backward computation.
I0216 01:28:32.728844 32696 net.cpp:219] relu3_2 does not need backward computation.
I0216 01:28:32.728849 32696 net.cpp:219] conv3_2 does not need backward computation.
I0216 01:28:32.728857 32696 net.cpp:219] relu3_1 does not need backward computation.
I0216 01:28:32.728862 32696 net.cpp:219] conv3_1 does not need backward computation.
I0216 01:28:32.728884 32696 net.cpp:219] pool2 does not need backward computation.
I0216 01:28:32.728890 32696 net.cpp:219] relu2_2 does not need backward computation.
I0216 01:28:32.728898 32696 net.cpp:219] conv2_2 does not need backward computation.
I0216 01:28:32.728904 32696 net.cpp:219] relu2_1 does not need backward computation.
I0216 01:28:32.728926 32696 net.cpp:219] conv2_1 does not need backward computation.
I0216 01:28:32.728931 32696 net.cpp:219] pool1 does not need backward computation.
I0216 01:28:32.728938 32696 net.cpp:219] relu1_2 does not need backward computation.
I0216 01:28:32.728943 32696 net.cpp:219] conv1_2 does not need backward computation.
I0216 01:28:32.728965 32696 net.cpp:219] relu1_1 does not need backward computation.
I0216 01:28:32.728971 32696 net.cpp:219] conv1_1 does not need backward computation.
I0216 01:28:32.728978 32696 net.cpp:219] data_data_0_split does not need backward computation.
I0216 01:28:32.728996 32696 net.cpp:219] data does not need backward computation.
I0216 01:28:32.729007 32696 net.cpp:261] This network produces output detection_eval
I0216 01:28:32.729290 32696 net.cpp:274] Network initialization done.
I0216 01:28:32.730288 32696 solver.cpp:63] Solver scaffolding done.
I0216 01:28:32.736994 32696 caffe.cpp:209] Resuming from /home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/VGG_KITTI_SSD_600x150_iter_56231.solverstate
I0216 01:28:32.938262 32696 sgd_solver.cpp:318] SGDSolver: restoring history
I0216 01:28:33.089155 32696 parallel.cpp:392] GPUs pairs 0:1, 2:3, 0:2
I0216 01:28:33.683850 32696 annotated_data_layer.cpp:52] output data size: 8,3,150,600
I0216 01:28:34.772392 32696 annotated_data_layer.cpp:52] output data size: 8,3,150,600
I0216 01:28:35.386239 32696 parallel.cpp:234] GPU 2 does not have p2p access to GPU 0
I0216 01:28:36.075129 32696 annotated_data_layer.cpp:52] output data size: 8,3,150,600
I0216 01:28:36.785956 32696 parallel.cpp:425] Starting Optimization
I0216 01:28:36.786139 32696 solver.cpp:282] Solving VGG_KITTI_SSD_600x150_train
I0216 01:28:36.786168 32696 solver.cpp:283] Learning Rate Policy: step
I0216 01:28:46.433224 32696 solver.cpp:231] Iteration 56240, loss = 0.887874
I0216 01:28:46.433280 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.715376 (* 1 = 0.715376 loss)
I0216 01:28:46.876869 32696 sgd_solver.cpp:106] Iteration 56240, lr = 0.0001
I0216 01:28:56.758824 32696 solver.cpp:231] Iteration 56250, loss = 0.867359
I0216 01:28:56.758894 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.966461 (* 1 = 0.966461 loss)
I0216 01:28:56.758949 32696 sgd_solver.cpp:106] Iteration 56250, lr = 0.0001
I0216 01:29:05.621069 32696 solver.cpp:231] Iteration 56260, loss = 1.03059
I0216 01:29:05.621224 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.898622 (* 1 = 0.898622 loss)
I0216 01:29:05.857036 32696 sgd_solver.cpp:106] Iteration 56260, lr = 0.0001
I0216 01:29:16.623237 32696 solver.cpp:231] Iteration 56270, loss = 1.15477
I0216 01:29:16.623288 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.17249 (* 1 = 1.17249 loss)
I0216 01:29:16.623332 32696 sgd_solver.cpp:106] Iteration 56270, lr = 0.0001
I0216 01:29:26.404404 32696 solver.cpp:231] Iteration 56280, loss = 0.960398
I0216 01:29:26.404469 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.592745 (* 1 = 0.592745 loss)
I0216 01:29:27.006685 32696 sgd_solver.cpp:106] Iteration 56280, lr = 0.0001
I0216 01:29:35.853114 32696 solver.cpp:231] Iteration 56290, loss = 1.10556
I0216 01:29:35.853343 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.685983 (* 1 = 0.685983 loss)
I0216 01:29:36.293797 32696 sgd_solver.cpp:106] Iteration 56290, lr = 0.0001
I0216 01:29:44.795855 32696 solver.cpp:231] Iteration 56300, loss = 1.00896
I0216 01:29:44.795922 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.786617 (* 1 = 0.786617 loss)
I0216 01:29:45.427436 32696 sgd_solver.cpp:106] Iteration 56300, lr = 0.0001
I0216 01:29:55.024297 32696 solver.cpp:231] Iteration 56310, loss = 0.844182
I0216 01:29:55.024358 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.759129 (* 1 = 0.759129 loss)
I0216 01:29:55.556623 32696 sgd_solver.cpp:106] Iteration 56310, lr = 0.0001
I0216 01:30:04.692876 32696 solver.cpp:231] Iteration 56320, loss = 0.915772
I0216 01:30:04.692920 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.06642 (* 1 = 1.06642 loss)
I0216 01:30:04.692972 32696 sgd_solver.cpp:106] Iteration 56320, lr = 0.0001
I0216 01:30:13.761579 32696 solver.cpp:231] Iteration 56330, loss = 0.911317
I0216 01:30:13.761868 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.446688 (* 1 = 0.446688 loss)
I0216 01:30:14.188776 32696 sgd_solver.cpp:106] Iteration 56330, lr = 0.0001
I0216 01:30:23.362854 32696 solver.cpp:231] Iteration 56340, loss = 0.982072
I0216 01:30:23.362900 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.29196 (* 1 = 1.29196 loss)
I0216 01:30:23.391780 32696 sgd_solver.cpp:106] Iteration 56340, lr = 0.0001
I0216 01:30:32.722928 32696 solver.cpp:231] Iteration 56350, loss = 0.960251
I0216 01:30:32.722986 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.923851 (* 1 = 0.923851 loss)
I0216 01:30:33.094491 32696 sgd_solver.cpp:106] Iteration 56350, lr = 0.0001
I0216 01:30:43.297763 32696 solver.cpp:231] Iteration 56360, loss = 1.00885
I0216 01:30:43.297827 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.710738 (* 1 = 0.710738 loss)
I0216 01:30:43.297850 32696 sgd_solver.cpp:106] Iteration 56360, lr = 0.0001
I0216 01:30:52.274741 32696 solver.cpp:231] Iteration 56370, loss = 0.871103
I0216 01:30:52.274996 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.712821 (* 1 = 0.712821 loss)
I0216 01:30:52.275053 32696 sgd_solver.cpp:106] Iteration 56370, lr = 0.0001
I0216 01:31:00.786211 32696 solver.cpp:231] Iteration 56380, loss = 0.915508
I0216 01:31:00.786273 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.771539 (* 1 = 0.771539 loss)
I0216 01:31:01.534412 32696 sgd_solver.cpp:106] Iteration 56380, lr = 0.0001
I0216 01:31:10.499148 32696 solver.cpp:231] Iteration 56390, loss = 0.770691
I0216 01:31:10.499218 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.20739 (* 1 = 1.20739 loss)
I0216 01:31:10.557107 32696 sgd_solver.cpp:106] Iteration 56390, lr = 0.0001
I0216 01:31:19.778053 32696 solver.cpp:231] Iteration 56400, loss = 1.36076
I0216 01:31:19.778111 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.780052 (* 1 = 0.780052 loss)
I0216 01:31:20.149085 32696 sgd_solver.cpp:106] Iteration 56400, lr = 0.0001
I0216 01:31:29.539295 32696 solver.cpp:231] Iteration 56410, loss = 0.975456
I0216 01:31:29.539577 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.965576 (* 1 = 0.965576 loss)
I0216 01:31:29.539717 32696 sgd_solver.cpp:106] Iteration 56410, lr = 0.0001
I0216 01:31:39.572243 32696 solver.cpp:231] Iteration 56420, loss = 0.994197
I0216 01:31:39.572305 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.916911 (* 1 = 0.916911 loss)
I0216 01:31:39.572377 32696 sgd_solver.cpp:106] Iteration 56420, lr = 0.0001
I0216 01:31:49.186342 32696 solver.cpp:231] Iteration 56430, loss = 0.994458
I0216 01:31:49.186389 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.709945 (* 1 = 0.709945 loss)
I0216 01:31:49.621230 32696 sgd_solver.cpp:106] Iteration 56430, lr = 0.0001
I0216 01:31:57.421216 32696 solver.cpp:231] Iteration 56440, loss = 1.11191
I0216 01:31:57.421267 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.05445 (* 1 = 1.05445 loss)
I0216 01:31:58.147943 32696 sgd_solver.cpp:106] Iteration 56440, lr = 0.0001
I0216 01:32:07.286370 32696 solver.cpp:231] Iteration 56450, loss = 1.06269
I0216 01:32:07.286557 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.81997 (* 1 = 0.81997 loss)
I0216 01:32:07.613855 32696 sgd_solver.cpp:106] Iteration 56450, lr = 0.0001
I0216 01:32:16.343515 32696 solver.cpp:231] Iteration 56460, loss = 1.06941
I0216 01:32:16.343574 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.93252 (* 1 = 0.93252 loss)
I0216 01:32:16.774153 32696 sgd_solver.cpp:106] Iteration 56460, lr = 0.0001
I0216 01:32:26.425312 32696 solver.cpp:231] Iteration 56470, loss = 0.837687
I0216 01:32:26.425370 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.659721 (* 1 = 0.659721 loss)
I0216 01:32:26.425395 32696 sgd_solver.cpp:106] Iteration 56470, lr = 0.0001
I0216 01:32:34.767467 32696 solver.cpp:231] Iteration 56480, loss = 0.952098
I0216 01:32:34.767515 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.802367 (* 1 = 0.802367 loss)
I0216 01:32:35.327800 32696 sgd_solver.cpp:106] Iteration 56480, lr = 0.0001
I0216 01:32:45.262226 32696 solver.cpp:231] Iteration 56490, loss = 1.05878
I0216 01:32:45.262441 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.01338 (* 1 = 1.01338 loss)
I0216 01:32:45.262517 32696 sgd_solver.cpp:106] Iteration 56490, lr = 0.0001
I0216 01:32:54.963513 32696 solver.cpp:231] Iteration 56500, loss = 1.13492
I0216 01:32:54.963565 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.11748 (* 1 = 1.11748 loss)
I0216 01:32:54.963588 32696 sgd_solver.cpp:106] Iteration 56500, lr = 0.0001
I0216 01:33:04.203583 32696 solver.cpp:231] Iteration 56510, loss = 1.07675
I0216 01:33:04.203649 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.957806 (* 1 = 0.957806 loss)
I0216 01:33:04.634374 32696 sgd_solver.cpp:106] Iteration 56510, lr = 0.0001
I0216 01:33:14.263526 32696 solver.cpp:231] Iteration 56520, loss = 0.856443
I0216 01:33:14.263571 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.725546 (* 1 = 0.725546 loss)
I0216 01:33:14.647905 32696 sgd_solver.cpp:106] Iteration 56520, lr = 0.0001
I0216 01:33:24.335338 32696 solver.cpp:231] Iteration 56530, loss = 1.17889
I0216 01:33:24.335703 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.926051 (* 1 = 0.926051 loss)
I0216 01:33:24.748615 32696 sgd_solver.cpp:106] Iteration 56530, lr = 0.0001
I0216 01:33:33.625593 32696 solver.cpp:231] Iteration 56540, loss = 0.805797
I0216 01:33:33.625650 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.708473 (* 1 = 0.708473 loss)
I0216 01:33:34.090947 32696 sgd_solver.cpp:106] Iteration 56540, lr = 0.0001
I0216 01:33:43.224416 32696 solver.cpp:231] Iteration 56550, loss = 0.996467
I0216 01:33:43.224469 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.767107 (* 1 = 0.767107 loss)
I0216 01:33:43.224504 32696 sgd_solver.cpp:106] Iteration 56550, lr = 0.0001
I0216 01:33:54.480245 32696 solver.cpp:231] Iteration 56560, loss = 1.10613
I0216 01:33:54.480468 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.767981 (* 1 = 0.767981 loss)
I0216 01:33:54.480540 32696 sgd_solver.cpp:106] Iteration 56560, lr = 0.0001
I0216 01:34:03.601312 32696 solver.cpp:231] Iteration 56570, loss = 0.896725
I0216 01:34:03.601373 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.97219 (* 1 = 0.97219 loss)
I0216 01:34:03.793618 32696 sgd_solver.cpp:106] Iteration 56570, lr = 0.0001
I0216 01:34:13.443115 32696 solver.cpp:231] Iteration 56580, loss = 1.11812
I0216 01:34:13.443166 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.05866 (* 1 = 1.05866 loss)
I0216 01:34:13.883375 32696 sgd_solver.cpp:106] Iteration 56580, lr = 0.0001
I0216 01:34:22.380656 32696 solver.cpp:231] Iteration 56590, loss = 0.926543
I0216 01:34:22.380710 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.737613 (* 1 = 0.737613 loss)
I0216 01:34:22.783408 32696 sgd_solver.cpp:106] Iteration 56590, lr = 0.0001
I0216 01:34:32.543118 32696 solver.cpp:231] Iteration 56600, loss = 1.12298
I0216 01:34:32.543303 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.708728 (* 1 = 0.708728 loss)
I0216 01:34:33.135732 32696 sgd_solver.cpp:106] Iteration 56600, lr = 0.0001
I0216 01:34:41.736615 32696 solver.cpp:231] Iteration 56610, loss = 0.83236
I0216 01:34:41.736671 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.01831 (* 1 = 1.01831 loss)
I0216 01:34:42.124301 32696 sgd_solver.cpp:106] Iteration 56610, lr = 0.0001
I0216 01:34:52.144678 32696 solver.cpp:231] Iteration 56620, loss = 0.827495
I0216 01:34:52.144727 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.03592 (* 1 = 1.03592 loss)
I0216 01:34:52.144773 32696 sgd_solver.cpp:106] Iteration 56620, lr = 0.0001
I0216 01:35:01.628907 32696 solver.cpp:231] Iteration 56630, loss = 0.86776
I0216 01:35:01.628971 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.855055 (* 1 = 0.855055 loss)
I0216 01:35:02.022543 32696 sgd_solver.cpp:106] Iteration 56630, lr = 0.0001
I0216 01:35:11.763579 32696 solver.cpp:231] Iteration 56640, loss = 0.898039
I0216 01:35:11.763769 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.00453 (* 1 = 1.00453 loss)
I0216 01:35:11.763804 32696 sgd_solver.cpp:106] Iteration 56640, lr = 0.0001
I0216 01:35:22.138631 32696 solver.cpp:231] Iteration 56650, loss = 1.12864
I0216 01:35:22.138679 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.30646 (* 1 = 1.30646 loss)
I0216 01:35:22.484108 32696 sgd_solver.cpp:106] Iteration 56650, lr = 0.0001
I0216 01:35:31.881902 32696 solver.cpp:231] Iteration 56660, loss = 0.954359
I0216 01:35:31.881953 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.1976 (* 1 = 1.1976 loss)
I0216 01:35:32.541378 32696 sgd_solver.cpp:106] Iteration 56660, lr = 0.0001
I0216 01:35:42.961887 32696 solver.cpp:231] Iteration 56670, loss = 0.967265
I0216 01:35:42.962146 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.951449 (* 1 = 0.951449 loss)
I0216 01:35:43.392030 32696 sgd_solver.cpp:106] Iteration 56670, lr = 0.0001
I0216 01:35:52.627432 32696 solver.cpp:231] Iteration 56680, loss = 0.919612
I0216 01:35:52.627480 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.667874 (* 1 = 0.667874 loss)
I0216 01:35:53.307034 32696 sgd_solver.cpp:106] Iteration 56680, lr = 0.0001
I0216 01:36:03.590561 32696 solver.cpp:231] Iteration 56690, loss = 1.00715
I0216 01:36:03.590607 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.15711 (* 1 = 1.15711 loss)
I0216 01:36:03.590649 32696 sgd_solver.cpp:106] Iteration 56690, lr = 0.0001
I0216 01:36:12.895594 32696 solver.cpp:231] Iteration 56700, loss = 1.03693
I0216 01:36:12.895638 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.48258 (* 1 = 1.48258 loss)
I0216 01:36:12.895675 32696 sgd_solver.cpp:106] Iteration 56700, lr = 0.0001
I0216 01:36:22.664808 32696 solver.cpp:231] Iteration 56710, loss = 0.9758
I0216 01:36:22.664983 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.939611 (* 1 = 0.939611 loss)
I0216 01:36:22.665012 32696 sgd_solver.cpp:106] Iteration 56710, lr = 0.0001
I0216 01:36:32.059720 32696 solver.cpp:231] Iteration 56720, loss = 0.927551
I0216 01:36:32.059770 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.994483 (* 1 = 0.994483 loss)
I0216 01:36:32.793830 32696 sgd_solver.cpp:106] Iteration 56720, lr = 0.0001
I0216 01:36:43.389122 32696 solver.cpp:231] Iteration 56730, loss = 0.949818
I0216 01:36:43.389181 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.755467 (* 1 = 0.755467 loss)
I0216 01:36:43.389202 32696 sgd_solver.cpp:106] Iteration 56730, lr = 0.0001
I0216 01:36:52.762249 32696 solver.cpp:231] Iteration 56740, loss = 0.898518
I0216 01:36:52.762410 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.35498 (* 1 = 1.35498 loss)
I0216 01:36:53.066052 32696 sgd_solver.cpp:106] Iteration 56740, lr = 0.0001
I0216 01:37:02.561740 32696 solver.cpp:231] Iteration 56750, loss = 0.930487
I0216 01:37:02.561805 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.575748 (* 1 = 0.575748 loss)
I0216 01:37:02.967028 32696 sgd_solver.cpp:106] Iteration 56750, lr = 0.0001
I0216 01:37:13.113868 32696 solver.cpp:231] Iteration 56760, loss = 1.11944
I0216 01:37:13.113914 32696 solver.cpp:247]     Train net output #0: mbox_loss = 2.35385 (* 1 = 2.35385 loss)
I0216 01:37:13.113943 32696 sgd_solver.cpp:106] Iteration 56760, lr = 0.0001
I0216 01:37:22.360637 32696 solver.cpp:231] Iteration 56770, loss = 0.967864
I0216 01:37:22.360694 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.620064 (* 1 = 0.620064 loss)
I0216 01:37:22.797441 32696 sgd_solver.cpp:106] Iteration 56770, lr = 0.0001
I0216 01:37:31.609082 32696 solver.cpp:231] Iteration 56780, loss = 0.945226
I0216 01:37:31.609134 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.766692 (* 1 = 0.766692 loss)
I0216 01:37:32.123805 32696 sgd_solver.cpp:106] Iteration 56780, lr = 0.0001
I0216 01:37:41.211352 32696 solver.cpp:231] Iteration 56790, loss = 1.09474
I0216 01:37:41.211414 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.39563 (* 1 = 1.39563 loss)
I0216 01:37:41.503270 32696 sgd_solver.cpp:106] Iteration 56790, lr = 0.0001
I0216 01:37:50.709568 32696 solver.cpp:231] Iteration 56800, loss = 1.00015
I0216 01:37:50.709619 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.781403 (* 1 = 0.781403 loss)
I0216 01:37:50.709668 32696 sgd_solver.cpp:106] Iteration 56800, lr = 0.0001
I0216 01:37:59.717876 32696 solver.cpp:231] Iteration 56810, loss = 0.958377
I0216 01:37:59.718122 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.861265 (* 1 = 0.861265 loss)
I0216 01:38:00.201328 32696 sgd_solver.cpp:106] Iteration 56810, lr = 0.0001
I0216 01:38:09.888253 32696 solver.cpp:231] Iteration 56820, loss = 0.86027
I0216 01:38:09.888309 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.845664 (* 1 = 0.845664 loss)
I0216 01:38:10.303431 32696 sgd_solver.cpp:106] Iteration 56820, lr = 0.0001
I0216 01:38:18.882760 32696 solver.cpp:231] Iteration 56830, loss = 0.932518
I0216 01:38:18.882820 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.632119 (* 1 = 0.632119 loss)
I0216 01:38:19.349865 32696 sgd_solver.cpp:106] Iteration 56830, lr = 0.0001
I0216 01:38:27.707631 32696 solver.cpp:231] Iteration 56840, loss = 0.912599
I0216 01:38:27.707684 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.864405 (* 1 = 0.864405 loss)
I0216 01:38:28.485358 32696 sgd_solver.cpp:106] Iteration 56840, lr = 0.0001
I0216 01:38:37.606518 32696 solver.cpp:231] Iteration 56850, loss = 0.921122
I0216 01:38:37.606766 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.811533 (* 1 = 0.811533 loss)
I0216 01:38:37.606796 32696 sgd_solver.cpp:106] Iteration 56850, lr = 0.0001
I0216 01:38:47.203253 32696 solver.cpp:231] Iteration 56860, loss = 1.01655
I0216 01:38:47.203313 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.10872 (* 1 = 1.10872 loss)
I0216 01:38:47.203341 32696 sgd_solver.cpp:106] Iteration 56860, lr = 0.0001
I0216 01:38:56.671949 32696 solver.cpp:231] Iteration 56870, loss = 0.998102
I0216 01:38:56.672011 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.867201 (* 1 = 0.867201 loss)
I0216 01:38:57.024565 32696 sgd_solver.cpp:106] Iteration 56870, lr = 0.0001
I0216 01:39:06.348099 32696 solver.cpp:231] Iteration 56880, loss = 1.20011
I0216 01:39:06.348171 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.07578 (* 1 = 1.07578 loss)
I0216 01:39:06.757231 32696 sgd_solver.cpp:106] Iteration 56880, lr = 0.0001
I0216 01:39:16.398319 32696 solver.cpp:231] Iteration 56890, loss = 0.874779
I0216 01:39:16.398561 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.879394 (* 1 = 0.879394 loss)
I0216 01:39:16.627050 32696 sgd_solver.cpp:106] Iteration 56890, lr = 0.0001
I0216 01:39:25.684865 32696 solver.cpp:231] Iteration 56900, loss = 1.12998
I0216 01:39:25.684931 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.671941 (* 1 = 0.671941 loss)
I0216 01:39:26.089444 32696 sgd_solver.cpp:106] Iteration 56900, lr = 0.0001
I0216 01:39:35.660404 32696 solver.cpp:231] Iteration 56910, loss = 1.06542
I0216 01:39:35.660462 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.875961 (* 1 = 0.875961 loss)
I0216 01:39:35.660516 32696 sgd_solver.cpp:106] Iteration 56910, lr = 0.0001
I0216 01:39:45.354375 32696 solver.cpp:231] Iteration 56920, loss = 1.0109
I0216 01:39:45.354425 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.922367 (* 1 = 0.922367 loss)
I0216 01:39:45.703254 32696 sgd_solver.cpp:106] Iteration 56920, lr = 0.0001
I0216 01:39:55.098574 32696 solver.cpp:231] Iteration 56930, loss = 0.887618
I0216 01:39:55.098767 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.638092 (* 1 = 0.638092 loss)
I0216 01:39:55.792774 32696 sgd_solver.cpp:106] Iteration 56930, lr = 0.0001
I0216 01:40:05.167934 32696 solver.cpp:231] Iteration 56940, loss = 1.06371
I0216 01:40:05.167989 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.25456 (* 1 = 1.25456 loss)
I0216 01:40:05.660241 32696 sgd_solver.cpp:106] Iteration 56940, lr = 0.0001
I0216 01:40:16.127274 32696 solver.cpp:231] Iteration 56950, loss = 0.866147
I0216 01:40:16.127316 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.715852 (* 1 = 0.715852 loss)
I0216 01:40:16.127355 32696 sgd_solver.cpp:106] Iteration 56950, lr = 0.0001
I0216 01:40:25.379153 32696 solver.cpp:231] Iteration 56960, loss = 1.29456
I0216 01:40:25.379325 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.77058 (* 1 = 1.77058 loss)
I0216 01:40:25.719002 32696 sgd_solver.cpp:106] Iteration 56960, lr = 0.0001
I0216 01:40:35.197744 32696 solver.cpp:231] Iteration 56970, loss = 0.816774
I0216 01:40:35.197800 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.10114 (* 1 = 1.10114 loss)
I0216 01:40:35.461580 32696 sgd_solver.cpp:106] Iteration 56970, lr = 0.0001
I0216 01:40:45.040649 32696 solver.cpp:231] Iteration 56980, loss = 0.926153
I0216 01:40:45.040711 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.51638 (* 1 = 1.51638 loss)
I0216 01:40:45.537554 32696 sgd_solver.cpp:106] Iteration 56980, lr = 0.0001
I0216 01:40:54.732817 32696 solver.cpp:231] Iteration 56990, loss = 0.951326
I0216 01:40:54.732882 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.951477 (* 1 = 0.951477 loss)
I0216 01:40:54.732933 32696 sgd_solver.cpp:106] Iteration 56990, lr = 0.0001
I0216 01:41:03.883352 32696 solver.cpp:231] Iteration 57000, loss = 0.912717
I0216 01:41:03.883682 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.898987 (* 1 = 0.898987 loss)
I0216 01:41:04.557600 32696 sgd_solver.cpp:106] Iteration 57000, lr = 0.0001
I0216 01:41:15.083973 32696 solver.cpp:231] Iteration 57010, loss = 1.06287
I0216 01:41:15.084033 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.887036 (* 1 = 0.887036 loss)
I0216 01:41:15.084120 32696 sgd_solver.cpp:106] Iteration 57010, lr = 0.0001
I0216 01:41:25.879767 32696 solver.cpp:231] Iteration 57020, loss = 0.987256
I0216 01:41:25.879811 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.764747 (* 1 = 0.764747 loss)
I0216 01:41:25.879871 32696 sgd_solver.cpp:106] Iteration 57020, lr = 0.0001
I0216 01:41:35.594285 32696 solver.cpp:231] Iteration 57030, loss = 0.895372
I0216 01:41:35.594530 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.18006 (* 1 = 1.18006 loss)
I0216 01:41:35.594672 32696 sgd_solver.cpp:106] Iteration 57030, lr = 0.0001
I0216 01:41:44.957118 32696 solver.cpp:231] Iteration 57040, loss = 1.01376
I0216 01:41:44.957183 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.599458 (* 1 = 0.599458 loss)
I0216 01:41:45.729260 32696 sgd_solver.cpp:106] Iteration 57040, lr = 0.0001
I0216 01:41:54.052513 32696 solver.cpp:231] Iteration 57050, loss = 1.05591
I0216 01:41:54.052563 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.46006 (* 1 = 1.46006 loss)
I0216 01:41:54.481856 32696 sgd_solver.cpp:106] Iteration 57050, lr = 0.0001
I0216 01:42:04.165052 32696 solver.cpp:231] Iteration 57060, loss = 1.17571
I0216 01:42:04.165102 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.795854 (* 1 = 0.795854 loss)
I0216 01:42:04.165150 32696 sgd_solver.cpp:106] Iteration 57060, lr = 0.0001
I0216 01:42:13.534936 32696 solver.cpp:231] Iteration 57070, loss = 1.25671
I0216 01:42:13.535133 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.587573 (* 1 = 0.587573 loss)
I0216 01:42:13.535164 32696 sgd_solver.cpp:106] Iteration 57070, lr = 0.0001
I0216 01:42:23.270185 32696 solver.cpp:231] Iteration 57080, loss = 0.871778
I0216 01:42:23.270233 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.888515 (* 1 = 0.888515 loss)
I0216 01:42:24.012457 32696 sgd_solver.cpp:106] Iteration 57080, lr = 0.0001
I0216 01:42:33.590550 32696 solver.cpp:231] Iteration 57090, loss = 0.893874
I0216 01:42:33.590585 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.576019 (* 1 = 0.576019 loss)
I0216 01:42:33.590606 32696 sgd_solver.cpp:106] Iteration 57090, lr = 0.0001
I0216 01:42:43.007864 32696 solver.cpp:231] Iteration 57100, loss = 0.926376
I0216 01:42:43.007920 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.16212 (* 1 = 1.16212 loss)
I0216 01:42:43.007951 32696 sgd_solver.cpp:106] Iteration 57100, lr = 0.0001
I0216 01:42:52.783852 32696 solver.cpp:231] Iteration 57110, loss = 0.908106
I0216 01:42:52.784008 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.529028 (* 1 = 0.529028 loss)
I0216 01:42:53.579633 32696 sgd_solver.cpp:106] Iteration 57110, lr = 0.0001
I0216 01:43:02.536583 32696 solver.cpp:231] Iteration 57120, loss = 1.00198
I0216 01:43:02.536643 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.975895 (* 1 = 0.975895 loss)
I0216 01:43:02.733266 32696 sgd_solver.cpp:106] Iteration 57120, lr = 0.0001
I0216 01:43:12.701311 32696 solver.cpp:231] Iteration 57130, loss = 1.08799
I0216 01:43:12.701375 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.10574 (* 1 = 1.10574 loss)
I0216 01:43:12.701396 32696 sgd_solver.cpp:106] Iteration 57130, lr = 0.0001
I0216 01:43:21.310760 32696 solver.cpp:231] Iteration 57140, loss = 1.06454
I0216 01:43:21.310813 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.610586 (* 1 = 0.610586 loss)
I0216 01:43:22.050706 32696 sgd_solver.cpp:106] Iteration 57140, lr = 0.0001
I0216 01:43:30.970204 32696 solver.cpp:231] Iteration 57150, loss = 0.909906
I0216 01:43:30.970382 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.23192 (* 1 = 1.23192 loss)
I0216 01:43:31.333751 32696 sgd_solver.cpp:106] Iteration 57150, lr = 0.0001
I0216 01:43:40.890832 32696 solver.cpp:231] Iteration 57160, loss = 1.09754
I0216 01:43:40.890909 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.594107 (* 1 = 0.594107 loss)
I0216 01:43:41.348572 32696 sgd_solver.cpp:106] Iteration 57160, lr = 0.0001
I0216 01:43:51.265702 32696 solver.cpp:231] Iteration 57170, loss = 0.942667
I0216 01:43:51.265751 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.15006 (* 1 = 1.15006 loss)
I0216 01:43:51.648972 32696 sgd_solver.cpp:106] Iteration 57170, lr = 0.0001
I0216 01:44:00.797175 32696 solver.cpp:231] Iteration 57180, loss = 0.982151
I0216 01:44:00.797232 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.86323 (* 1 = 1.86323 loss)
I0216 01:44:01.375499 32696 sgd_solver.cpp:106] Iteration 57180, lr = 0.0001
I0216 01:44:10.125049 32696 solver.cpp:231] Iteration 57190, loss = 0.942259
I0216 01:44:10.125113 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.790453 (* 1 = 0.790453 loss)
I0216 01:44:10.463943 32696 sgd_solver.cpp:106] Iteration 57190, lr = 0.0001
I0216 01:44:19.481768 32696 solver.cpp:231] Iteration 57200, loss = 1.14852
I0216 01:44:19.481825 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.32447 (* 1 = 1.32447 loss)
I0216 01:44:19.894177 32696 sgd_solver.cpp:106] Iteration 57200, lr = 0.0001
I0216 01:44:28.477574 32696 solver.cpp:231] Iteration 57210, loss = 0.936227
I0216 01:44:28.477619 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.04317 (* 1 = 1.04317 loss)
I0216 01:44:28.709632 32696 sgd_solver.cpp:106] Iteration 57210, lr = 0.0001
I0216 01:44:38.257341 32696 solver.cpp:231] Iteration 57220, loss = 1.31468
I0216 01:44:38.257573 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.18111 (* 1 = 1.18111 loss)
I0216 01:44:38.458154 32696 sgd_solver.cpp:106] Iteration 57220, lr = 0.0001
I0216 01:44:48.299713 32696 solver.cpp:231] Iteration 57230, loss = 0.933387
I0216 01:44:48.299769 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.11261 (* 1 = 1.11261 loss)
I0216 01:44:48.299796 32696 sgd_solver.cpp:106] Iteration 57230, lr = 0.0001
I0216 01:44:57.194138 32696 solver.cpp:231] Iteration 57240, loss = 0.954878
I0216 01:44:57.194197 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.59745 (* 1 = 1.59745 loss)
I0216 01:44:57.600463 32696 sgd_solver.cpp:106] Iteration 57240, lr = 0.0001
I0216 01:45:07.414068 32696 solver.cpp:231] Iteration 57250, loss = 0.823997
I0216 01:45:07.414124 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.1089 (* 1 = 1.1089 loss)
I0216 01:45:07.414187 32696 sgd_solver.cpp:106] Iteration 57250, lr = 0.0001
I0216 01:45:17.580437 32696 solver.cpp:231] Iteration 57260, loss = 1.06001
I0216 01:45:17.580667 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.9961 (* 1 = 0.9961 loss)
I0216 01:45:17.983222 32696 sgd_solver.cpp:106] Iteration 57260, lr = 0.0001
I0216 01:45:27.117333 32696 solver.cpp:231] Iteration 57270, loss = 0.902967
I0216 01:45:27.117385 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.77654 (* 1 = 0.77654 loss)
I0216 01:45:27.534955 32696 sgd_solver.cpp:106] Iteration 57270, lr = 0.0001
I0216 01:45:37.607455 32696 solver.cpp:231] Iteration 57280, loss = 1.08725
I0216 01:45:37.607511 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.926782 (* 1 = 0.926782 loss)
I0216 01:45:37.886449 32696 sgd_solver.cpp:106] Iteration 57280, lr = 0.0001
I0216 01:45:47.205866 32696 solver.cpp:231] Iteration 57290, loss = 1.07146
I0216 01:45:47.205919 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.25547 (* 1 = 1.25547 loss)
I0216 01:45:47.562355 32696 sgd_solver.cpp:106] Iteration 57290, lr = 0.0001
I0216 01:45:57.295720 32696 solver.cpp:231] Iteration 57300, loss = 0.887885
I0216 01:45:57.295958 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.92784 (* 1 = 0.92784 loss)
I0216 01:45:57.786710 32696 sgd_solver.cpp:106] Iteration 57300, lr = 0.0001
I0216 01:46:07.226922 32696 solver.cpp:231] Iteration 57310, loss = 0.946644
I0216 01:46:07.227005 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.5507 (* 1 = 1.5507 loss)
I0216 01:46:07.227030 32696 sgd_solver.cpp:106] Iteration 57310, lr = 0.0001
I0216 01:46:16.886540 32696 solver.cpp:231] Iteration 57320, loss = 1.06479
I0216 01:46:16.886613 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.566105 (* 1 = 0.566105 loss)
I0216 01:46:17.322893 32696 sgd_solver.cpp:106] Iteration 57320, lr = 0.0001
I0216 01:46:27.314131 32696 solver.cpp:231] Iteration 57330, loss = 0.97808
I0216 01:46:27.314306 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.852783 (* 1 = 0.852783 loss)
I0216 01:46:27.314337 32696 sgd_solver.cpp:106] Iteration 57330, lr = 0.0001
I0216 01:46:37.860052 32696 solver.cpp:231] Iteration 57340, loss = 1.03466
I0216 01:46:37.860116 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.856126 (* 1 = 0.856126 loss)
I0216 01:46:38.054232 32696 sgd_solver.cpp:106] Iteration 57340, lr = 0.0001
I0216 01:46:48.104921 32696 solver.cpp:231] Iteration 57350, loss = 0.869448
I0216 01:46:48.104979 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.06637 (* 1 = 1.06637 loss)
I0216 01:46:48.105002 32696 sgd_solver.cpp:106] Iteration 57350, lr = 0.0001
I0216 01:46:58.661103 32696 solver.cpp:231] Iteration 57360, loss = 1.07865
I0216 01:46:58.661329 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.12153 (* 1 = 1.12153 loss)
I0216 01:46:58.661442 32696 sgd_solver.cpp:106] Iteration 57360, lr = 0.0001
I0216 01:47:08.195400 32696 solver.cpp:231] Iteration 57370, loss = 1.31574
I0216 01:47:08.195462 32696 solver.cpp:247]     Train net output #0: mbox_loss = 2.40657 (* 1 = 2.40657 loss)
I0216 01:47:08.596230 32696 sgd_solver.cpp:106] Iteration 57370, lr = 0.0001
I0216 01:47:17.526130 32696 solver.cpp:231] Iteration 57380, loss = 0.850531
I0216 01:47:17.526201 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.788421 (* 1 = 0.788421 loss)
I0216 01:47:18.199705 32696 sgd_solver.cpp:106] Iteration 57380, lr = 0.0001
I0216 01:47:27.469727 32696 solver.cpp:231] Iteration 57390, loss = 1.08779
I0216 01:47:27.469771 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.16963 (* 1 = 1.16963 loss)
I0216 01:47:27.469795 32696 sgd_solver.cpp:106] Iteration 57390, lr = 0.0001
I0216 01:47:36.764569 32696 solver.cpp:231] Iteration 57400, loss = 1.15628
I0216 01:47:36.764787 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.15348 (* 1 = 1.15348 loss)
I0216 01:47:37.242136 32696 sgd_solver.cpp:106] Iteration 57400, lr = 0.0001
I0216 01:47:47.606031 32696 solver.cpp:231] Iteration 57410, loss = 0.908913
I0216 01:47:47.606072 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.365442 (* 1 = 0.365442 loss)
I0216 01:47:47.606101 32696 sgd_solver.cpp:106] Iteration 57410, lr = 0.0001
I0216 01:47:57.312258 32696 solver.cpp:231] Iteration 57420, loss = 0.951205
I0216 01:47:57.312324 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.16308 (* 1 = 1.16308 loss)
I0216 01:47:57.312366 32696 sgd_solver.cpp:106] Iteration 57420, lr = 0.0001
I0216 01:48:06.444859 32696 solver.cpp:231] Iteration 57430, loss = 1.18889
I0216 01:48:06.444913 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.44298 (* 1 = 1.44298 loss)
I0216 01:48:06.660962 32696 sgd_solver.cpp:106] Iteration 57430, lr = 0.0001
I0216 01:48:16.024960 32696 solver.cpp:231] Iteration 57440, loss = 1.11826
I0216 01:48:16.025244 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.676758 (* 1 = 0.676758 loss)
I0216 01:48:16.233912 32696 sgd_solver.cpp:106] Iteration 57440, lr = 0.0001
I0216 01:48:25.374719 32696 solver.cpp:231] Iteration 57450, loss = 0.983129
I0216 01:48:25.374779 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.683971 (* 1 = 0.683971 loss)
I0216 01:48:25.899577 32696 sgd_solver.cpp:106] Iteration 57450, lr = 0.0001
I0216 01:48:34.885675 32696 solver.cpp:231] Iteration 57460, loss = 0.926075
I0216 01:48:34.885737 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.791071 (* 1 = 0.791071 loss)
I0216 01:48:35.835650 32696 sgd_solver.cpp:106] Iteration 57460, lr = 0.0001
I0216 01:48:44.877812 32696 solver.cpp:231] Iteration 57470, loss = 0.98502
I0216 01:48:44.877882 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.907275 (* 1 = 0.907275 loss)
I0216 01:48:45.249130 32696 sgd_solver.cpp:106] Iteration 57470, lr = 0.0001
I0216 01:48:53.882084 32696 solver.cpp:231] Iteration 57480, loss = 0.933196
I0216 01:48:53.882189 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.20129 (* 1 = 1.20129 loss)
I0216 01:48:54.237540 32696 sgd_solver.cpp:106] Iteration 57480, lr = 0.0001
I0216 01:49:02.830085 32696 solver.cpp:231] Iteration 57490, loss = 1.06807
I0216 01:49:02.830149 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.62701 (* 1 = 1.62701 loss)
I0216 01:49:03.171825 32696 sgd_solver.cpp:106] Iteration 57490, lr = 0.0001
I0216 01:49:12.511587 32696 solver.cpp:231] Iteration 57500, loss = 1.09338
I0216 01:49:12.511646 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.852904 (* 1 = 0.852904 loss)
I0216 01:49:12.511690 32696 sgd_solver.cpp:106] Iteration 57500, lr = 0.0001
I0216 01:49:21.576822 32696 solver.cpp:231] Iteration 57510, loss = 1.01192
I0216 01:49:21.576861 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.475179 (* 1 = 0.475179 loss)
I0216 01:49:21.576900 32696 sgd_solver.cpp:106] Iteration 57510, lr = 0.0001
I0216 01:49:30.728859 32696 solver.cpp:231] Iteration 57520, loss = 1.11429
I0216 01:49:30.729074 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.34934 (* 1 = 1.34934 loss)
I0216 01:49:31.072235 32696 sgd_solver.cpp:106] Iteration 57520, lr = 0.0001
I0216 01:49:40.729499 32696 solver.cpp:231] Iteration 57530, loss = 0.913695
I0216 01:49:40.729558 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.562288 (* 1 = 0.562288 loss)
I0216 01:49:40.729586 32696 sgd_solver.cpp:106] Iteration 57530, lr = 0.0001
I0216 01:49:49.557934 32696 solver.cpp:231] Iteration 57540, loss = 1.16674
I0216 01:49:49.558004 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.47373 (* 1 = 1.47373 loss)
I0216 01:49:50.154548 32696 sgd_solver.cpp:106] Iteration 57540, lr = 0.0001
I0216 01:50:00.196393 32696 solver.cpp:231] Iteration 57550, loss = 0.864437
I0216 01:50:00.196446 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.985883 (* 1 = 0.985883 loss)
I0216 01:50:00.196492 32696 sgd_solver.cpp:106] Iteration 57550, lr = 0.0001
I0216 01:50:10.395535 32696 solver.cpp:231] Iteration 57560, loss = 0.927723
I0216 01:50:10.395759 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.790154 (* 1 = 0.790154 loss)
I0216 01:50:10.808231 32696 sgd_solver.cpp:106] Iteration 57560, lr = 0.0001
I0216 01:50:19.656994 32696 solver.cpp:231] Iteration 57570, loss = 0.834719
I0216 01:50:19.657043 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.963744 (* 1 = 0.963744 loss)
I0216 01:50:20.063390 32696 sgd_solver.cpp:106] Iteration 57570, lr = 0.0001
I0216 01:50:29.284765 32696 solver.cpp:231] Iteration 57580, loss = 0.887039
I0216 01:50:29.284827 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.05969 (* 1 = 1.05969 loss)
I0216 01:50:29.686818 32696 sgd_solver.cpp:106] Iteration 57580, lr = 0.0001
I0216 01:50:39.491147 32696 solver.cpp:231] Iteration 57590, loss = 1.06516
I0216 01:50:39.491205 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.04615 (* 1 = 1.04615 loss)
I0216 01:50:39.491225 32696 sgd_solver.cpp:106] Iteration 57590, lr = 0.0001
I0216 01:50:48.924829 32696 solver.cpp:231] Iteration 57600, loss = 0.916924
I0216 01:50:48.925052 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.715981 (* 1 = 0.715981 loss)
I0216 01:50:49.576791 32696 sgd_solver.cpp:106] Iteration 57600, lr = 0.0001
I0216 01:50:58.929555 32696 solver.cpp:231] Iteration 57610, loss = 0.982727
I0216 01:50:58.929617 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.0206 (* 1 = 1.0206 loss)
I0216 01:50:58.929657 32696 sgd_solver.cpp:106] Iteration 57610, lr = 0.0001
I0216 01:51:07.741657 32696 solver.cpp:231] Iteration 57620, loss = 0.863077
I0216 01:51:07.741703 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.494523 (* 1 = 0.494523 loss)
I0216 01:51:07.741727 32696 sgd_solver.cpp:106] Iteration 57620, lr = 0.0001
I0216 01:51:17.588804 32696 solver.cpp:231] Iteration 57630, loss = 1.01584
I0216 01:51:17.588891 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.958922 (* 1 = 0.958922 loss)
I0216 01:51:17.756340 32696 sgd_solver.cpp:106] Iteration 57630, lr = 0.0001
I0216 01:51:27.886186 32696 solver.cpp:231] Iteration 57640, loss = 1.1492
I0216 01:51:27.886337 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.85284 (* 1 = 1.85284 loss)
I0216 01:51:27.886392 32696 sgd_solver.cpp:106] Iteration 57640, lr = 0.0001
I0216 01:51:37.453454 32696 solver.cpp:231] Iteration 57650, loss = 0.76135
I0216 01:51:37.453516 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.563375 (* 1 = 0.563375 loss)
I0216 01:51:37.868945 32696 sgd_solver.cpp:106] Iteration 57650, lr = 0.0001
I0216 01:51:47.432574 32696 solver.cpp:231] Iteration 57660, loss = 0.886443
I0216 01:51:47.432620 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.782003 (* 1 = 0.782003 loss)
I0216 01:51:47.432660 32696 sgd_solver.cpp:106] Iteration 57660, lr = 0.0001
I0216 01:51:56.692574 32696 solver.cpp:231] Iteration 57670, loss = 0.984185
I0216 01:51:56.692622 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.98721 (* 1 = 0.98721 loss)
I0216 01:51:57.061020 32696 sgd_solver.cpp:106] Iteration 57670, lr = 0.0001
I0216 01:52:06.544317 32696 solver.cpp:231] Iteration 57680, loss = 0.961757
I0216 01:52:06.544524 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.451199 (* 1 = 0.451199 loss)
I0216 01:52:06.906654 32696 sgd_solver.cpp:106] Iteration 57680, lr = 0.0001
I0216 01:52:16.871266 32696 solver.cpp:231] Iteration 57690, loss = 0.95463
I0216 01:52:16.871326 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.599179 (* 1 = 0.599179 loss)
I0216 01:52:16.871369 32696 sgd_solver.cpp:106] Iteration 57690, lr = 0.0001
I0216 01:52:26.068266 32696 solver.cpp:231] Iteration 57700, loss = 1.05515
I0216 01:52:26.068316 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.00678 (* 1 = 1.00678 loss)
I0216 01:52:26.521975 32696 sgd_solver.cpp:106] Iteration 57700, lr = 0.0001
I0216 01:52:35.938007 32696 solver.cpp:231] Iteration 57710, loss = 0.964928
I0216 01:52:35.938057 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.09534 (* 1 = 1.09534 loss)
I0216 01:52:35.938094 32696 sgd_solver.cpp:106] Iteration 57710, lr = 0.0001
I0216 01:52:45.219588 32696 solver.cpp:231] Iteration 57720, loss = 0.960953
I0216 01:52:45.219787 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.00027 (* 1 = 1.00027 loss)
I0216 01:52:45.443588 32696 sgd_solver.cpp:106] Iteration 57720, lr = 0.0001
I0216 01:52:54.817874 32696 solver.cpp:231] Iteration 57730, loss = 0.957732
I0216 01:52:54.817922 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.540031 (* 1 = 0.540031 loss)
I0216 01:52:55.522902 32696 sgd_solver.cpp:106] Iteration 57730, lr = 0.0001
I0216 01:53:05.012456 32696 solver.cpp:231] Iteration 57740, loss = 1.01396
I0216 01:53:05.012501 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.811241 (* 1 = 0.811241 loss)
I0216 01:53:05.012568 32696 sgd_solver.cpp:106] Iteration 57740, lr = 0.0001
I0216 01:53:14.488239 32696 solver.cpp:231] Iteration 57750, loss = 1.18093
I0216 01:53:14.488281 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.05635 (* 1 = 1.05635 loss)
I0216 01:53:14.488315 32696 sgd_solver.cpp:106] Iteration 57750, lr = 0.0001
I0216 01:53:23.892246 32696 solver.cpp:231] Iteration 57760, loss = 1.17203
I0216 01:53:23.892405 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.20443 (* 1 = 1.20443 loss)
I0216 01:53:24.181926 32696 sgd_solver.cpp:106] Iteration 57760, lr = 0.0001
I0216 01:53:33.363085 32696 solver.cpp:231] Iteration 57770, loss = 0.986508
I0216 01:53:33.363148 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.661443 (* 1 = 0.661443 loss)
I0216 01:53:33.765750 32696 sgd_solver.cpp:106] Iteration 57770, lr = 0.0001
I0216 01:53:43.813875 32696 solver.cpp:231] Iteration 57780, loss = 1.00633
I0216 01:53:43.813920 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.18671 (* 1 = 1.18671 loss)
I0216 01:53:43.813941 32696 sgd_solver.cpp:106] Iteration 57780, lr = 0.0001
I0216 01:53:52.256925 32696 solver.cpp:231] Iteration 57790, loss = 1.02883
I0216 01:53:52.256969 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.864795 (* 1 = 0.864795 loss)
I0216 01:53:52.452052 32696 sgd_solver.cpp:106] Iteration 57790, lr = 0.0001
I0216 01:54:01.532709 32696 solver.cpp:231] Iteration 57800, loss = 1.12304
I0216 01:54:01.532953 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.78263 (* 1 = 1.78263 loss)
I0216 01:54:01.955441 32696 sgd_solver.cpp:106] Iteration 57800, lr = 0.0001
I0216 01:54:11.317394 32696 solver.cpp:231] Iteration 57810, loss = 0.990348
I0216 01:54:11.317442 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.00923 (* 1 = 1.00923 loss)
I0216 01:54:11.889008 32696 sgd_solver.cpp:106] Iteration 57810, lr = 0.0001
I0216 01:54:21.463325 32696 solver.cpp:231] Iteration 57820, loss = 0.847383
I0216 01:54:21.463385 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.752682 (* 1 = 0.752682 loss)
I0216 01:54:21.463415 32696 sgd_solver.cpp:106] Iteration 57820, lr = 0.0001
I0216 01:54:31.449208 32696 solver.cpp:231] Iteration 57830, loss = 0.852354
I0216 01:54:31.449250 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.825082 (* 1 = 0.825082 loss)
I0216 01:54:31.449287 32696 sgd_solver.cpp:106] Iteration 57830, lr = 0.0001
I0216 01:54:41.756703 32696 solver.cpp:231] Iteration 57840, loss = 1.02337
I0216 01:54:41.756929 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.774618 (* 1 = 0.774618 loss)
I0216 01:54:42.212391 32696 sgd_solver.cpp:106] Iteration 57840, lr = 0.0001
I0216 01:54:51.936092 32696 solver.cpp:231] Iteration 57850, loss = 0.952747
I0216 01:54:51.936138 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.22282 (* 1 = 1.22282 loss)
I0216 01:54:51.936177 32696 sgd_solver.cpp:106] Iteration 57850, lr = 0.0001
I0216 01:55:01.476131 32696 solver.cpp:231] Iteration 57860, loss = 1.07391
I0216 01:55:01.476174 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.12328 (* 1 = 1.12328 loss)
I0216 01:55:01.476212 32696 sgd_solver.cpp:106] Iteration 57860, lr = 0.0001
I0216 01:55:10.849367 32696 solver.cpp:231] Iteration 57870, loss = 1.14326
I0216 01:55:10.849433 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.36619 (* 1 = 1.36619 loss)
I0216 01:55:11.546880 32696 sgd_solver.cpp:106] Iteration 57870, lr = 0.0001
I0216 01:55:20.224413 32696 solver.cpp:231] Iteration 57880, loss = 0.93648
I0216 01:55:20.224557 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.07398 (* 1 = 1.07398 loss)
I0216 01:55:20.622500 32696 sgd_solver.cpp:106] Iteration 57880, lr = 0.0001
I0216 01:55:29.278615 32696 solver.cpp:231] Iteration 57890, loss = 0.875702
I0216 01:55:29.278683 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.14211 (* 1 = 1.14211 loss)
I0216 01:55:29.479470 32696 sgd_solver.cpp:106] Iteration 57890, lr = 0.0001
I0216 01:55:39.363745 32696 solver.cpp:231] Iteration 57900, loss = 1.08081
I0216 01:55:39.363801 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.09367 (* 1 = 1.09367 loss)
I0216 01:55:39.701109 32696 sgd_solver.cpp:106] Iteration 57900, lr = 0.0001
I0216 01:55:49.372252 32696 solver.cpp:231] Iteration 57910, loss = 1.19454
I0216 01:55:49.372310 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.747745 (* 1 = 0.747745 loss)
I0216 01:55:49.372335 32696 sgd_solver.cpp:106] Iteration 57910, lr = 0.0001
I0216 01:55:58.523906 32696 solver.cpp:231] Iteration 57920, loss = 0.801318
I0216 01:55:58.524184 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.10272 (* 1 = 1.10272 loss)
I0216 01:55:59.133386 32696 sgd_solver.cpp:106] Iteration 57920, lr = 0.0001
I0216 01:56:09.084568 32696 solver.cpp:231] Iteration 57930, loss = 0.931309
I0216 01:56:09.084630 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.21582 (* 1 = 1.21582 loss)
I0216 01:56:09.084656 32696 sgd_solver.cpp:106] Iteration 57930, lr = 0.0001
I0216 01:56:18.516067 32696 solver.cpp:231] Iteration 57940, loss = 1.1883
I0216 01:56:18.516121 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.728516 (* 1 = 0.728516 loss)
I0216 01:56:18.516162 32696 sgd_solver.cpp:106] Iteration 57940, lr = 0.0001
I0216 01:56:27.009639 32696 solver.cpp:231] Iteration 57950, loss = 0.893144
I0216 01:56:27.009685 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.750742 (* 1 = 0.750742 loss)
I0216 01:56:27.434025 32696 sgd_solver.cpp:106] Iteration 57950, lr = 0.0001
I0216 01:56:36.193140 32696 solver.cpp:231] Iteration 57960, loss = 1.1274
I0216 01:56:36.193297 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.3757 (* 1 = 1.3757 loss)
I0216 01:56:36.597898 32696 sgd_solver.cpp:106] Iteration 57960, lr = 0.0001
I0216 01:56:46.071831 32696 solver.cpp:231] Iteration 57970, loss = 1.10538
I0216 01:56:46.071900 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.40952 (* 1 = 1.40952 loss)
I0216 01:56:46.494038 32696 sgd_solver.cpp:106] Iteration 57970, lr = 0.0001
I0216 01:56:55.172386 32696 solver.cpp:231] Iteration 57980, loss = 1.14666
I0216 01:56:55.172453 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.01116 (* 1 = 1.01116 loss)
I0216 01:56:55.574671 32696 sgd_solver.cpp:106] Iteration 57980, lr = 0.0001
I0216 01:57:05.697618 32696 solver.cpp:231] Iteration 57990, loss = 1.07385
I0216 01:57:05.697669 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.980139 (* 1 = 0.980139 loss)
I0216 01:57:05.697692 32696 sgd_solver.cpp:106] Iteration 57990, lr = 0.0001
I0216 01:57:14.697621 32696 solver.cpp:231] Iteration 58000, loss = 1.16936
I0216 01:57:14.697790 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.14553 (* 1 = 1.14553 loss)
I0216 01:57:14.697854 32696 sgd_solver.cpp:106] Iteration 58000, lr = 0.0001
I0216 01:57:23.939076 32696 solver.cpp:231] Iteration 58010, loss = 0.909344
I0216 01:57:23.939121 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.840184 (* 1 = 0.840184 loss)
I0216 01:57:24.301434 32696 sgd_solver.cpp:106] Iteration 58010, lr = 0.0001
I0216 01:57:33.693619 32696 solver.cpp:231] Iteration 58020, loss = 0.975658
I0216 01:57:33.693670 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.54951 (* 1 = 1.54951 loss)
I0216 01:57:34.141708 32696 sgd_solver.cpp:106] Iteration 58020, lr = 0.0001
I0216 01:57:43.590597 32696 solver.cpp:231] Iteration 58030, loss = 0.889565
I0216 01:57:43.590654 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.72639 (* 1 = 0.72639 loss)
I0216 01:57:43.590692 32696 sgd_solver.cpp:106] Iteration 58030, lr = 0.0001
I0216 01:57:53.158802 32696 solver.cpp:231] Iteration 58040, loss = 1.06989
I0216 01:57:53.159015 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.732506 (* 1 = 0.732506 loss)
I0216 01:57:53.507766 32696 sgd_solver.cpp:106] Iteration 58040, lr = 0.0001
I0216 01:58:03.612267 32696 solver.cpp:231] Iteration 58050, loss = 0.94053
I0216 01:58:03.612330 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.20336 (* 1 = 1.20336 loss)
I0216 01:58:03.612354 32696 sgd_solver.cpp:106] Iteration 58050, lr = 0.0001
I0216 01:58:13.256541 32696 solver.cpp:231] Iteration 58060, loss = 0.920179
I0216 01:58:13.256603 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.968925 (* 1 = 0.968925 loss)
I0216 01:58:13.617561 32696 sgd_solver.cpp:106] Iteration 58060, lr = 0.0001
I0216 01:58:23.454808 32696 solver.cpp:231] Iteration 58070, loss = 0.889258
I0216 01:58:23.455093 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.635016 (* 1 = 0.635016 loss)
I0216 01:58:24.223811 32696 sgd_solver.cpp:106] Iteration 58070, lr = 0.0001
I0216 01:58:33.818734 32696 solver.cpp:231] Iteration 58080, loss = 0.865149
I0216 01:58:33.818780 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.641069 (* 1 = 0.641069 loss)
I0216 01:58:33.818819 32696 sgd_solver.cpp:106] Iteration 58080, lr = 0.0001
I0216 01:58:43.646108 32696 solver.cpp:231] Iteration 58090, loss = 0.917187
I0216 01:58:43.646162 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.836653 (* 1 = 0.836653 loss)
I0216 01:58:43.646189 32696 sgd_solver.cpp:106] Iteration 58090, lr = 0.0001
I0216 01:58:53.161604 32696 solver.cpp:231] Iteration 58100, loss = 0.951535
I0216 01:58:53.161656 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.905046 (* 1 = 0.905046 loss)
I0216 01:58:53.481484 32696 sgd_solver.cpp:106] Iteration 58100, lr = 0.0001
I0216 01:59:02.600771 32696 solver.cpp:231] Iteration 58110, loss = 1.15134
I0216 01:59:02.600821 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.879746 (* 1 = 0.879746 loss)
I0216 01:59:03.188252 32696 sgd_solver.cpp:106] Iteration 58110, lr = 0.0001
I0216 01:59:12.865769 32696 solver.cpp:231] Iteration 58120, loss = 0.911153
I0216 01:59:12.865830 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.797519 (* 1 = 0.797519 loss)
I0216 01:59:12.865869 32696 sgd_solver.cpp:106] Iteration 58120, lr = 0.0001
I0216 01:59:22.904734 32696 solver.cpp:231] Iteration 58130, loss = 0.968827
I0216 01:59:22.904793 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.580906 (* 1 = 0.580906 loss)
I0216 01:59:23.317392 32696 sgd_solver.cpp:106] Iteration 58130, lr = 0.0001
I0216 01:59:32.508952 32696 solver.cpp:231] Iteration 58140, loss = 1.07448
I0216 01:59:32.509114 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.535782 (* 1 = 0.535782 loss)
I0216 01:59:32.509141 32696 sgd_solver.cpp:106] Iteration 58140, lr = 0.0001
I0216 01:59:42.180074 32696 solver.cpp:231] Iteration 58150, loss = 0.976876
I0216 01:59:42.180126 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.909111 (* 1 = 0.909111 loss)
I0216 01:59:42.615829 32696 sgd_solver.cpp:106] Iteration 58150, lr = 0.0001
I0216 01:59:52.438516 32696 solver.cpp:231] Iteration 58160, loss = 1.02129
I0216 01:59:52.438580 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.979947 (* 1 = 0.979947 loss)
I0216 01:59:53.142139 32696 sgd_solver.cpp:106] Iteration 58160, lr = 0.0001
I0216 02:00:01.309877 32696 solver.cpp:231] Iteration 58170, loss = 1.06007
I0216 02:00:01.309939 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.17714 (* 1 = 1.17714 loss)
I0216 02:00:01.733249 32696 sgd_solver.cpp:106] Iteration 58170, lr = 0.0001
I0216 02:00:11.295089 32696 solver.cpp:231] Iteration 58180, loss = 0.949935
I0216 02:00:11.295301 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.777337 (* 1 = 0.777337 loss)
I0216 02:00:11.599761 32696 sgd_solver.cpp:106] Iteration 58180, lr = 0.0001
I0216 02:00:21.528486 32696 solver.cpp:231] Iteration 58190, loss = 0.846834
I0216 02:00:21.528553 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.791199 (* 1 = 0.791199 loss)
I0216 02:00:21.915890 32696 sgd_solver.cpp:106] Iteration 58190, lr = 0.0001
I0216 02:00:30.687417 32696 solver.cpp:231] Iteration 58200, loss = 1.20945
I0216 02:00:30.687470 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.54449 (* 1 = 1.54449 loss)
I0216 02:00:31.067107 32696 sgd_solver.cpp:106] Iteration 58200, lr = 0.0001
I0216 02:00:40.288507 32696 solver.cpp:231] Iteration 58210, loss = 1.00703
I0216 02:00:40.288574 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.824469 (* 1 = 0.824469 loss)
I0216 02:00:40.683300 32696 sgd_solver.cpp:106] Iteration 58210, lr = 0.0001
I0216 02:00:50.550637 32696 solver.cpp:231] Iteration 58220, loss = 0.942984
I0216 02:00:50.550873 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.01557 (* 1 = 1.01557 loss)
I0216 02:00:50.550950 32696 sgd_solver.cpp:106] Iteration 58220, lr = 0.0001
I0216 02:01:00.043803 32696 solver.cpp:231] Iteration 58230, loss = 0.895794
I0216 02:01:00.043872 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.947906 (* 1 = 0.947906 loss)
I0216 02:01:00.523250 32696 sgd_solver.cpp:106] Iteration 58230, lr = 0.0001
I0216 02:01:09.566256 32696 solver.cpp:231] Iteration 58240, loss = 1.1165
I0216 02:01:09.566311 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.04456 (* 1 = 1.04456 loss)
I0216 02:01:09.932536 32696 sgd_solver.cpp:106] Iteration 58240, lr = 0.0001
I0216 02:01:20.206852 32696 solver.cpp:231] Iteration 58250, loss = 1.15853
I0216 02:01:20.206908 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.25497 (* 1 = 1.25497 loss)
I0216 02:01:20.403028 32696 sgd_solver.cpp:106] Iteration 58250, lr = 0.0001
I0216 02:01:30.416424 32696 solver.cpp:231] Iteration 58260, loss = 1.03538
I0216 02:01:30.416667 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.07406 (* 1 = 1.07406 loss)
I0216 02:01:30.731220 32696 sgd_solver.cpp:106] Iteration 58260, lr = 0.0001
I0216 02:01:39.275369 32696 solver.cpp:231] Iteration 58270, loss = 1.02794
I0216 02:01:39.275434 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.33303 (* 1 = 1.33303 loss)
I0216 02:01:39.663004 32696 sgd_solver.cpp:106] Iteration 58270, lr = 0.0001
I0216 02:01:48.396910 32696 solver.cpp:231] Iteration 58280, loss = 0.906658
I0216 02:01:48.396973 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.953553 (* 1 = 0.953553 loss)
I0216 02:01:48.397037 32696 sgd_solver.cpp:106] Iteration 58280, lr = 0.0001
I0216 02:01:58.519702 32696 solver.cpp:231] Iteration 58290, loss = 0.992605
I0216 02:01:58.519753 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.983097 (* 1 = 0.983097 loss)
I0216 02:01:58.712119 32696 sgd_solver.cpp:106] Iteration 58290, lr = 0.0001
I0216 02:02:08.541421 32696 solver.cpp:231] Iteration 58300, loss = 0.928312
I0216 02:02:08.541693 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.639604 (* 1 = 0.639604 loss)
I0216 02:02:08.854231 32696 sgd_solver.cpp:106] Iteration 58300, lr = 0.0001
I0216 02:02:17.963665 32696 solver.cpp:231] Iteration 58310, loss = 1.03344
I0216 02:02:17.963726 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.07997 (* 1 = 1.07997 loss)
I0216 02:02:17.963748 32696 sgd_solver.cpp:106] Iteration 58310, lr = 0.0001
I0216 02:02:27.606166 32696 solver.cpp:231] Iteration 58320, loss = 1.03335
I0216 02:02:27.606216 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.45208 (* 1 = 1.45208 loss)
I0216 02:02:27.606245 32696 sgd_solver.cpp:106] Iteration 58320, lr = 0.0001
I0216 02:02:37.605304 32696 solver.cpp:231] Iteration 58330, loss = 0.809262
I0216 02:02:37.605345 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.934886 (* 1 = 0.934886 loss)
I0216 02:02:37.905351 32696 sgd_solver.cpp:106] Iteration 58330, lr = 0.0001
I0216 02:02:47.976940 32696 solver.cpp:231] Iteration 58340, loss = 0.917096
I0216 02:02:47.977195 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.748085 (* 1 = 0.748085 loss)
I0216 02:02:47.977311 32696 sgd_solver.cpp:106] Iteration 58340, lr = 0.0001
I0216 02:02:56.744216 32696 solver.cpp:231] Iteration 58350, loss = 1.02542
I0216 02:02:56.744271 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.842741 (* 1 = 0.842741 loss)
I0216 02:02:57.060693 32696 sgd_solver.cpp:106] Iteration 58350, lr = 0.0001
I0216 02:03:06.030791 32696 solver.cpp:231] Iteration 58360, loss = 1.00767
I0216 02:03:06.030848 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.964105 (* 1 = 0.964105 loss)
I0216 02:03:06.373800 32696 sgd_solver.cpp:106] Iteration 58360, lr = 0.0001
I0216 02:03:15.494329 32696 solver.cpp:231] Iteration 58370, loss = 1.14548
I0216 02:03:15.494392 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.92924 (* 1 = 0.92924 loss)
I0216 02:03:15.494416 32696 sgd_solver.cpp:106] Iteration 58370, lr = 0.0001
I0216 02:03:24.477608 32696 solver.cpp:231] Iteration 58380, loss = 1.01527
I0216 02:03:24.477826 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.716465 (* 1 = 0.716465 loss)
I0216 02:03:24.927014 32696 sgd_solver.cpp:106] Iteration 58380, lr = 0.0001
I0216 02:03:35.351124 32696 solver.cpp:231] Iteration 58390, loss = 1.01117
I0216 02:03:35.351166 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.852687 (* 1 = 0.852687 loss)
I0216 02:03:35.351205 32696 sgd_solver.cpp:106] Iteration 58390, lr = 0.0001
I0216 02:03:45.953987 32696 solver.cpp:231] Iteration 58400, loss = 0.97157
I0216 02:03:45.954051 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.606458 (* 1 = 0.606458 loss)
I0216 02:03:46.403077 32696 sgd_solver.cpp:106] Iteration 58400, lr = 0.0001
I0216 02:03:55.643990 32696 solver.cpp:231] Iteration 58410, loss = 1.02648
I0216 02:03:55.644249 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.11229 (* 1 = 1.11229 loss)
I0216 02:03:55.644361 32696 sgd_solver.cpp:106] Iteration 58410, lr = 0.0001
I0216 02:04:05.391288 32696 solver.cpp:231] Iteration 58420, loss = 1.13518
I0216 02:04:05.391346 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.781373 (* 1 = 0.781373 loss)
I0216 02:04:06.238960 32696 sgd_solver.cpp:106] Iteration 58420, lr = 0.0001
I0216 02:04:15.465518 32696 solver.cpp:231] Iteration 58430, loss = 1.1479
I0216 02:04:15.465636 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.72545 (* 1 = 1.72545 loss)
I0216 02:04:15.465688 32696 sgd_solver.cpp:106] Iteration 58430, lr = 0.0001
I0216 02:04:25.031982 32696 solver.cpp:231] Iteration 58440, loss = 1.00633
I0216 02:04:25.032033 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.67822 (* 1 = 1.67822 loss)
I0216 02:04:25.915984 32696 sgd_solver.cpp:106] Iteration 58440, lr = 0.0001
I0216 02:04:35.712662 32696 solver.cpp:231] Iteration 58450, loss = 1.13323
I0216 02:04:35.712708 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.64007 (* 1 = 1.64007 loss)
I0216 02:04:35.712745 32696 sgd_solver.cpp:106] Iteration 58450, lr = 0.0001
I0216 02:04:45.093338 32696 solver.cpp:231] Iteration 58460, loss = 0.931339
I0216 02:04:45.093399 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.536195 (* 1 = 0.536195 loss)
I0216 02:04:45.093451 32696 sgd_solver.cpp:106] Iteration 58460, lr = 0.0001
I0216 02:04:54.090097 32696 solver.cpp:231] Iteration 58470, loss = 0.931819
I0216 02:04:54.090165 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.632146 (* 1 = 0.632146 loss)
I0216 02:04:54.561528 32696 sgd_solver.cpp:106] Iteration 58470, lr = 0.0001
I0216 02:05:04.159565 32696 solver.cpp:231] Iteration 58480, loss = 0.84655
I0216 02:05:04.159744 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.696297 (* 1 = 0.696297 loss)
I0216 02:05:04.612009 32696 sgd_solver.cpp:106] Iteration 58480, lr = 0.0001
I0216 02:05:12.559731 32696 solver.cpp:231] Iteration 58490, loss = 0.793467
I0216 02:05:12.559811 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.746228 (* 1 = 0.746228 loss)
I0216 02:05:12.970645 32696 sgd_solver.cpp:106] Iteration 58490, lr = 0.0001
I0216 02:05:22.385207 32696 solver.cpp:231] Iteration 58500, loss = 0.950619
I0216 02:05:22.385262 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.576774 (* 1 = 0.576774 loss)
I0216 02:05:22.606560 32696 sgd_solver.cpp:106] Iteration 58500, lr = 0.0001
I0216 02:05:33.009367 32696 solver.cpp:231] Iteration 58510, loss = 1.0601
I0216 02:05:33.009431 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.20499 (* 1 = 1.20499 loss)
I0216 02:05:33.587966 32696 sgd_solver.cpp:106] Iteration 58510, lr = 0.0001
I0216 02:05:42.416728 32696 solver.cpp:231] Iteration 58520, loss = 0.867509
I0216 02:05:42.416999 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.97362 (* 1 = 0.97362 loss)
I0216 02:05:42.417110 32696 sgd_solver.cpp:106] Iteration 58520, lr = 0.0001
I0216 02:05:51.991356 32696 solver.cpp:231] Iteration 58530, loss = 0.95882
I0216 02:05:51.991412 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.18816 (* 1 = 1.18816 loss)
I0216 02:05:52.385401 32696 sgd_solver.cpp:106] Iteration 58530, lr = 0.0001
I0216 02:06:02.023988 32696 solver.cpp:231] Iteration 58540, loss = 1.08417
I0216 02:06:02.024058 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.53717 (* 1 = 0.53717 loss)
I0216 02:06:02.816052 32696 sgd_solver.cpp:106] Iteration 58540, lr = 0.0001
I0216 02:06:13.190174 32696 solver.cpp:231] Iteration 58550, loss = 0.926142
I0216 02:06:13.190364 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.616152 (* 1 = 0.616152 loss)
I0216 02:06:13.190392 32696 sgd_solver.cpp:106] Iteration 58550, lr = 0.0001
I0216 02:06:22.022483 32696 solver.cpp:231] Iteration 58560, loss = 0.9084
I0216 02:06:22.022539 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.966581 (* 1 = 0.966581 loss)
I0216 02:06:22.404877 32696 sgd_solver.cpp:106] Iteration 58560, lr = 0.0001
I0216 02:06:32.577565 32696 solver.cpp:231] Iteration 58570, loss = 1.08254
I0216 02:06:32.577630 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.672897 (* 1 = 0.672897 loss)
I0216 02:06:32.577703 32696 sgd_solver.cpp:106] Iteration 58570, lr = 0.0001
I0216 02:06:42.042451 32696 solver.cpp:231] Iteration 58580, loss = 0.867521
I0216 02:06:42.042505 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.742967 (* 1 = 0.742967 loss)
I0216 02:06:42.494765 32696 sgd_solver.cpp:106] Iteration 58580, lr = 0.0001
I0216 02:06:51.364462 32696 solver.cpp:231] Iteration 58590, loss = 1.29997
I0216 02:06:51.364719 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.729127 (* 1 = 0.729127 loss)
I0216 02:06:51.722445 32696 sgd_solver.cpp:106] Iteration 58590, lr = 0.0001
I0216 02:07:00.625744 32696 solver.cpp:231] Iteration 58600, loss = 1.12911
I0216 02:07:00.625810 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.20173 (* 1 = 1.20173 loss)
I0216 02:07:00.952769 32696 sgd_solver.cpp:106] Iteration 58600, lr = 0.0001
I0216 02:07:10.108327 32696 solver.cpp:231] Iteration 58610, loss = 0.935666
I0216 02:07:10.108374 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.634296 (* 1 = 0.634296 loss)
I0216 02:07:10.469132 32696 sgd_solver.cpp:106] Iteration 58610, lr = 0.0001
I0216 02:07:18.671316 32696 solver.cpp:231] Iteration 58620, loss = 0.825925
I0216 02:07:18.671380 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.65689 (* 1 = 0.65689 loss)
I0216 02:07:19.292285 32696 sgd_solver.cpp:106] Iteration 58620, lr = 0.0001
I0216 02:07:27.897418 32696 solver.cpp:231] Iteration 58630, loss = 1.08204
I0216 02:07:27.897620 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.71646 (* 1 = 1.71646 loss)
I0216 02:07:28.558137 32696 sgd_solver.cpp:106] Iteration 58630, lr = 0.0001
I0216 02:07:37.734304 32696 solver.cpp:231] Iteration 58640, loss = 0.833527
I0216 02:07:37.734359 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.718262 (* 1 = 0.718262 loss)
I0216 02:07:38.466394 32696 sgd_solver.cpp:106] Iteration 58640, lr = 0.0001
I0216 02:07:47.964488 32696 solver.cpp:231] Iteration 58650, loss = 1.07253
I0216 02:07:47.964556 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.935132 (* 1 = 0.935132 loss)
I0216 02:07:48.681696 32696 sgd_solver.cpp:106] Iteration 58650, lr = 0.0001
I0216 02:07:57.407294 32696 solver.cpp:231] Iteration 58660, loss = 1.15778
I0216 02:07:57.407358 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.52017 (* 1 = 1.52017 loss)
I0216 02:07:57.787628 32696 sgd_solver.cpp:106] Iteration 58660, lr = 0.0001
I0216 02:08:07.295033 32696 solver.cpp:231] Iteration 58670, loss = 0.789459
I0216 02:08:07.295294 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.559149 (* 1 = 0.559149 loss)
I0216 02:08:07.724148 32696 sgd_solver.cpp:106] Iteration 58670, lr = 0.0001
I0216 02:08:16.557929 32696 solver.cpp:231] Iteration 58680, loss = 1.06049
I0216 02:08:16.557982 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.69961 (* 1 = 1.69961 loss)
I0216 02:08:17.329795 32696 sgd_solver.cpp:106] Iteration 58680, lr = 0.0001
I0216 02:08:26.248782 32696 solver.cpp:231] Iteration 58690, loss = 1.04817
I0216 02:08:26.248841 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.614426 (* 1 = 0.614426 loss)
I0216 02:08:26.585717 32696 sgd_solver.cpp:106] Iteration 58690, lr = 0.0001
I0216 02:08:35.799679 32696 solver.cpp:231] Iteration 58700, loss = 1.00053
I0216 02:08:35.799742 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.57435 (* 1 = 0.57435 loss)
I0216 02:08:36.050257 32696 sgd_solver.cpp:106] Iteration 58700, lr = 0.0001
I0216 02:08:44.630882 32696 solver.cpp:231] Iteration 58710, loss = 0.955202
I0216 02:08:44.631191 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.706489 (* 1 = 0.706489 loss)
I0216 02:08:45.043377 32696 sgd_solver.cpp:106] Iteration 58710, lr = 0.0001
I0216 02:08:54.395238 32696 solver.cpp:231] Iteration 58720, loss = 0.915743
I0216 02:08:54.395287 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.22527 (* 1 = 1.22527 loss)
I0216 02:08:54.395311 32696 sgd_solver.cpp:106] Iteration 58720, lr = 0.0001
I0216 02:09:04.417554 32696 solver.cpp:231] Iteration 58730, loss = 1.16573
I0216 02:09:04.417609 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.68649 (* 1 = 1.68649 loss)
I0216 02:09:04.417650 32696 sgd_solver.cpp:106] Iteration 58730, lr = 0.0001
I0216 02:09:13.444128 32696 solver.cpp:231] Iteration 58740, loss = 1.11079
I0216 02:09:13.444203 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.712244 (* 1 = 0.712244 loss)
I0216 02:09:13.444278 32696 sgd_solver.cpp:106] Iteration 58740, lr = 0.0001
I0216 02:09:22.830708 32696 solver.cpp:231] Iteration 58750, loss = 0.900359
I0216 02:09:22.830919 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.657943 (* 1 = 0.657943 loss)
I0216 02:09:23.485750 32696 sgd_solver.cpp:106] Iteration 58750, lr = 0.0001
I0216 02:09:32.386396 32696 solver.cpp:231] Iteration 58760, loss = 1.22038
I0216 02:09:32.386462 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.702923 (* 1 = 0.702923 loss)
I0216 02:09:32.807972 32696 sgd_solver.cpp:106] Iteration 58760, lr = 0.0001
I0216 02:09:42.243568 32696 solver.cpp:231] Iteration 58770, loss = 0.776742
I0216 02:09:42.243607 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.389683 (* 1 = 0.389683 loss)
I0216 02:09:42.682433 32696 sgd_solver.cpp:106] Iteration 58770, lr = 0.0001
I0216 02:09:52.079248 32696 solver.cpp:231] Iteration 58780, loss = 1.08326
I0216 02:09:52.079316 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.918093 (* 1 = 0.918093 loss)
I0216 02:09:52.809958 32696 sgd_solver.cpp:106] Iteration 58780, lr = 0.0001
I0216 02:10:02.269412 32696 solver.cpp:231] Iteration 58790, loss = 0.895881
I0216 02:10:02.269690 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.975145 (* 1 = 0.975145 loss)
I0216 02:10:02.269790 32696 sgd_solver.cpp:106] Iteration 58790, lr = 0.0001
I0216 02:10:11.654944 32696 solver.cpp:231] Iteration 58800, loss = 0.961917
I0216 02:10:11.654989 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.0134 (* 1 = 1.0134 loss)
I0216 02:10:11.655010 32696 sgd_solver.cpp:106] Iteration 58800, lr = 0.0001
I0216 02:10:20.811991 32696 solver.cpp:231] Iteration 58810, loss = 1.09592
I0216 02:10:20.812052 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.00435 (* 1 = 1.00435 loss)
I0216 02:10:21.251794 32696 sgd_solver.cpp:106] Iteration 58810, lr = 0.0001
I0216 02:10:30.735685 32696 solver.cpp:231] Iteration 58820, loss = 0.95565
I0216 02:10:30.735745 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.19207 (* 1 = 1.19207 loss)
I0216 02:10:30.735796 32696 sgd_solver.cpp:106] Iteration 58820, lr = 0.0001
I0216 02:10:41.147893 32696 solver.cpp:231] Iteration 58830, loss = 0.933121
I0216 02:10:41.148157 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.12935 (* 1 = 1.12935 loss)
I0216 02:10:41.148195 32696 sgd_solver.cpp:106] Iteration 58830, lr = 0.0001
I0216 02:10:50.259022 32696 solver.cpp:231] Iteration 58840, loss = 1.03346
I0216 02:10:50.259095 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.806934 (* 1 = 0.806934 loss)
I0216 02:10:50.404072 32696 sgd_solver.cpp:106] Iteration 58840, lr = 0.0001
I0216 02:10:59.439586 32696 solver.cpp:231] Iteration 58850, loss = 1.09234
I0216 02:10:59.439653 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.993703 (* 1 = 0.993703 loss)
I0216 02:10:59.811812 32696 sgd_solver.cpp:106] Iteration 58850, lr = 0.0001
I0216 02:11:09.821998 32696 solver.cpp:231] Iteration 58860, loss = 1.10671
I0216 02:11:09.822047 32696 solver.cpp:247]     Train net output #0: mbox_loss = 2.32849 (* 1 = 2.32849 loss)
I0216 02:11:10.210145 32696 sgd_solver.cpp:106] Iteration 58860, lr = 0.0001
I0216 02:11:20.296912 32696 solver.cpp:231] Iteration 58870, loss = 0.996647
I0216 02:11:20.297129 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.654151 (* 1 = 0.654151 loss)
I0216 02:11:20.297163 32696 sgd_solver.cpp:106] Iteration 58870, lr = 0.0001
I0216 02:11:29.504273 32696 solver.cpp:231] Iteration 58880, loss = 0.936356
I0216 02:11:29.504335 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.06924 (* 1 = 1.06924 loss)
I0216 02:11:30.035343 32696 sgd_solver.cpp:106] Iteration 58880, lr = 0.0001
I0216 02:11:39.369650 32696 solver.cpp:231] Iteration 58890, loss = 0.907143
I0216 02:11:39.369707 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.819954 (* 1 = 0.819954 loss)
I0216 02:11:39.369738 32696 sgd_solver.cpp:106] Iteration 58890, lr = 0.0001
I0216 02:11:48.407927 32696 solver.cpp:231] Iteration 58900, loss = 0.990956
I0216 02:11:48.407975 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.23846 (* 1 = 1.23846 loss)
I0216 02:11:48.809247 32696 sgd_solver.cpp:106] Iteration 58900, lr = 0.0001
I0216 02:11:58.899868 32696 solver.cpp:231] Iteration 58910, loss = 0.966065
I0216 02:11:58.900002 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.06121 (* 1 = 1.06121 loss)
I0216 02:11:59.209427 32696 sgd_solver.cpp:106] Iteration 58910, lr = 0.0001
I0216 02:12:08.884932 32696 solver.cpp:231] Iteration 58920, loss = 0.862473
I0216 02:12:08.884987 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.26557 (* 1 = 1.26557 loss)
I0216 02:12:08.885028 32696 sgd_solver.cpp:106] Iteration 58920, lr = 0.0001
I0216 02:12:19.901800 32696 solver.cpp:231] Iteration 58930, loss = 0.992121
I0216 02:12:19.901859 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.84032 (* 1 = 1.84032 loss)
I0216 02:12:19.901890 32696 sgd_solver.cpp:106] Iteration 58930, lr = 0.0001
I0216 02:12:28.489732 32696 solver.cpp:231] Iteration 58940, loss = 1.08094
I0216 02:12:28.489791 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.657967 (* 1 = 0.657967 loss)
I0216 02:12:28.724869 32696 sgd_solver.cpp:106] Iteration 58940, lr = 0.0001
I0216 02:12:37.144186 32696 solver.cpp:231] Iteration 58950, loss = 1.14575
I0216 02:12:37.144438 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.1114 (* 1 = 1.1114 loss)
I0216 02:12:37.568918 32696 sgd_solver.cpp:106] Iteration 58950, lr = 0.0001
I0216 02:12:46.952811 32696 solver.cpp:231] Iteration 58960, loss = 1.11876
I0216 02:12:46.952885 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.864399 (* 1 = 0.864399 loss)
I0216 02:12:47.756197 32696 sgd_solver.cpp:106] Iteration 58960, lr = 0.0001
I0216 02:12:56.128137 32696 solver.cpp:231] Iteration 58970, loss = 1.03848
I0216 02:12:56.128206 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.900728 (* 1 = 0.900728 loss)
I0216 02:12:56.777273 32696 sgd_solver.cpp:106] Iteration 58970, lr = 0.0001
I0216 02:13:06.941462 32696 solver.cpp:231] Iteration 58980, loss = 1.04857
I0216 02:13:06.941534 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.861551 (* 1 = 0.861551 loss)
I0216 02:13:07.145839 32696 sgd_solver.cpp:106] Iteration 58980, lr = 0.0001
I0216 02:13:15.662395 32696 solver.cpp:231] Iteration 58990, loss = 0.856406
I0216 02:13:15.662448 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.829985 (* 1 = 0.829985 loss)
I0216 02:13:15.923916 32696 sgd_solver.cpp:106] Iteration 58990, lr = 0.0001
I0216 02:13:24.329574 32696 solver.cpp:231] Iteration 59000, loss = 1.08846
I0216 02:13:24.329643 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.23987 (* 1 = 1.23987 loss)
I0216 02:13:24.732915 32696 sgd_solver.cpp:106] Iteration 59000, lr = 0.0001
I0216 02:13:34.502658 32696 solver.cpp:231] Iteration 59010, loss = 0.974656
I0216 02:13:34.502720 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.986391 (* 1 = 0.986391 loss)
I0216 02:13:34.853771 32696 sgd_solver.cpp:106] Iteration 59010, lr = 0.0001
I0216 02:13:43.111100 32696 solver.cpp:231] Iteration 59020, loss = 0.88612
I0216 02:13:43.111326 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.527619 (* 1 = 0.527619 loss)
I0216 02:13:43.111409 32696 sgd_solver.cpp:106] Iteration 59020, lr = 0.0001
I0216 02:13:52.328902 32696 solver.cpp:231] Iteration 59030, loss = 1.13614
I0216 02:13:52.328948 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.921887 (* 1 = 0.921887 loss)
I0216 02:13:52.774744 32696 sgd_solver.cpp:106] Iteration 59030, lr = 0.0001
I0216 02:14:01.169258 32696 solver.cpp:231] Iteration 59040, loss = 0.970652
I0216 02:14:01.169312 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.94798 (* 1 = 1.94798 loss)
I0216 02:14:01.512011 32696 sgd_solver.cpp:106] Iteration 59040, lr = 0.0001
I0216 02:14:09.937060 32696 solver.cpp:231] Iteration 59050, loss = 0.944274
I0216 02:14:09.937131 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.903844 (* 1 = 0.903844 loss)
I0216 02:14:10.618836 32696 sgd_solver.cpp:106] Iteration 59050, lr = 0.0001
I0216 02:14:19.874721 32696 solver.cpp:231] Iteration 59060, loss = 0.868206
I0216 02:14:19.874913 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.548791 (* 1 = 0.548791 loss)
I0216 02:14:20.518050 32696 sgd_solver.cpp:106] Iteration 59060, lr = 0.0001
I0216 02:14:29.808734 32696 solver.cpp:231] Iteration 59070, loss = 1.03778
I0216 02:14:29.808784 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.966605 (* 1 = 0.966605 loss)
I0216 02:14:30.140451 32696 sgd_solver.cpp:106] Iteration 59070, lr = 0.0001
I0216 02:14:39.368489 32696 solver.cpp:231] Iteration 59080, loss = 1.04109
I0216 02:14:39.368551 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.16408 (* 1 = 1.16408 loss)
I0216 02:14:39.754129 32696 sgd_solver.cpp:106] Iteration 59080, lr = 0.0001
I0216 02:14:48.746289 32696 solver.cpp:231] Iteration 59090, loss = 1.03648
I0216 02:14:48.746350 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.28919 (* 1 = 1.28919 loss)
I0216 02:14:48.746372 32696 sgd_solver.cpp:106] Iteration 59090, lr = 0.0001
I0216 02:14:57.717924 32696 solver.cpp:231] Iteration 59100, loss = 0.948862
I0216 02:14:57.718112 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.0217 (* 1 = 1.0217 loss)
I0216 02:14:57.718158 32696 sgd_solver.cpp:106] Iteration 59100, lr = 0.0001
I0216 02:15:08.355803 32696 solver.cpp:231] Iteration 59110, loss = 1.01484
I0216 02:15:08.355865 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.61214 (* 1 = 0.61214 loss)
I0216 02:15:08.355886 32696 sgd_solver.cpp:106] Iteration 59110, lr = 0.0001
I0216 02:15:17.819283 32696 solver.cpp:231] Iteration 59120, loss = 0.846763
I0216 02:15:17.819352 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.5272 (* 1 = 0.5272 loss)
I0216 02:15:18.370437 32696 sgd_solver.cpp:106] Iteration 59120, lr = 0.0001
I0216 02:15:27.272186 32696 solver.cpp:231] Iteration 59130, loss = 1.00132
I0216 02:15:27.272249 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.12641 (* 1 = 1.12641 loss)
I0216 02:15:27.521980 32696 sgd_solver.cpp:106] Iteration 59130, lr = 0.0001
I0216 02:15:36.802577 32696 solver.cpp:231] Iteration 59140, loss = 1.00237
I0216 02:15:36.802908 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.904229 (* 1 = 0.904229 loss)
I0216 02:15:36.803014 32696 sgd_solver.cpp:106] Iteration 59140, lr = 0.0001
I0216 02:15:46.214254 32696 solver.cpp:231] Iteration 59150, loss = 1.09282
I0216 02:15:46.214318 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.769907 (* 1 = 0.769907 loss)
I0216 02:15:46.435035 32696 sgd_solver.cpp:106] Iteration 59150, lr = 0.0001
I0216 02:15:55.132076 32696 solver.cpp:231] Iteration 59160, loss = 0.842917
I0216 02:15:55.132124 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.11148 (* 1 = 1.11148 loss)
I0216 02:15:55.518429 32696 sgd_solver.cpp:106] Iteration 59160, lr = 0.0001
I0216 02:16:05.270669 32696 solver.cpp:231] Iteration 59170, loss = 0.889108
I0216 02:16:05.270740 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.978117 (* 1 = 0.978117 loss)
I0216 02:16:05.991794 32696 sgd_solver.cpp:106] Iteration 59170, lr = 0.0001
I0216 02:16:14.375805 32696 solver.cpp:231] Iteration 59180, loss = 0.921792
I0216 02:16:14.376070 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.64273 (* 1 = 1.64273 loss)
I0216 02:16:14.691329 32696 sgd_solver.cpp:106] Iteration 59180, lr = 0.0001
I0216 02:16:23.752943 32696 solver.cpp:231] Iteration 59190, loss = 0.837211
I0216 02:16:23.752992 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.843096 (* 1 = 0.843096 loss)
I0216 02:16:24.235416 32696 sgd_solver.cpp:106] Iteration 59190, lr = 0.0001
I0216 02:16:33.945128 32696 solver.cpp:231] Iteration 59200, loss = 0.823343
I0216 02:16:33.945200 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.6871 (* 1 = 0.6871 loss)
I0216 02:16:34.390952 32696 sgd_solver.cpp:106] Iteration 59200, lr = 0.0001
I0216 02:16:44.011204 32696 solver.cpp:231] Iteration 59210, loss = 1.13404
I0216 02:16:44.011251 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.25131 (* 1 = 1.25131 loss)
I0216 02:16:44.011301 32696 sgd_solver.cpp:106] Iteration 59210, lr = 0.0001
I0216 02:16:52.980217 32696 solver.cpp:231] Iteration 59220, loss = 0.839425
I0216 02:16:52.980413 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.923565 (* 1 = 0.923565 loss)
I0216 02:16:53.764899 32696 sgd_solver.cpp:106] Iteration 59220, lr = 0.0001
I0216 02:17:03.136083 32696 solver.cpp:231] Iteration 59230, loss = 1.16227
I0216 02:17:03.136152 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.00967 (* 1 = 1.00967 loss)
I0216 02:17:03.752718 32696 sgd_solver.cpp:106] Iteration 59230, lr = 0.0001
I0216 02:17:13.035656 32696 solver.cpp:231] Iteration 59240, loss = 1.12074
I0216 02:17:13.035724 32696 solver.cpp:247]     Train net output #0: mbox_loss = 2.14632 (* 1 = 2.14632 loss)
I0216 02:17:13.391801 32696 sgd_solver.cpp:106] Iteration 59240, lr = 0.0001
I0216 02:17:22.548012 32696 solver.cpp:231] Iteration 59250, loss = 1.00436
I0216 02:17:22.548064 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.0047 (* 1 = 1.0047 loss)
I0216 02:17:22.881796 32696 sgd_solver.cpp:106] Iteration 59250, lr = 0.0001
I0216 02:17:32.075728 32696 solver.cpp:231] Iteration 59260, loss = 0.998479
I0216 02:17:32.076091 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.651255 (* 1 = 0.651255 loss)
I0216 02:17:32.578182 32696 sgd_solver.cpp:106] Iteration 59260, lr = 0.0001
I0216 02:17:41.781471 32696 solver.cpp:231] Iteration 59270, loss = 0.988459
I0216 02:17:41.781520 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.13238 (* 1 = 1.13238 loss)
I0216 02:17:42.161182 32696 sgd_solver.cpp:106] Iteration 59270, lr = 0.0001
I0216 02:17:51.228548 32696 solver.cpp:231] Iteration 59280, loss = 0.809045
I0216 02:17:51.228618 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.600948 (* 1 = 0.600948 loss)
I0216 02:17:52.026064 32696 sgd_solver.cpp:106] Iteration 59280, lr = 0.0001
I0216 02:18:01.380070 32696 solver.cpp:231] Iteration 59290, loss = 0.883425
I0216 02:18:01.380123 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.15487 (* 1 = 1.15487 loss)
I0216 02:18:01.380161 32696 sgd_solver.cpp:106] Iteration 59290, lr = 0.0001
I0216 02:18:11.128684 32696 solver.cpp:231] Iteration 59300, loss = 1.02775
I0216 02:18:11.128954 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.69308 (* 1 = 1.69308 loss)
I0216 02:18:11.679633 32696 sgd_solver.cpp:106] Iteration 59300, lr = 0.0001
I0216 02:18:21.690836 32696 solver.cpp:231] Iteration 59310, loss = 1.17007
I0216 02:18:21.690907 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.930689 (* 1 = 0.930689 loss)
I0216 02:18:22.383862 32696 sgd_solver.cpp:106] Iteration 59310, lr = 0.0001
I0216 02:18:32.026173 32696 solver.cpp:231] Iteration 59320, loss = 1.0625
I0216 02:18:32.026237 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.14796 (* 1 = 1.14796 loss)
I0216 02:18:32.026262 32696 sgd_solver.cpp:106] Iteration 59320, lr = 0.0001
I0216 02:18:42.089015 32696 solver.cpp:231] Iteration 59330, loss = 0.874071
I0216 02:18:42.089215 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.456192 (* 1 = 0.456192 loss)
I0216 02:18:42.089295 32696 sgd_solver.cpp:106] Iteration 59330, lr = 0.0001
I0216 02:18:52.380570 32696 solver.cpp:231] Iteration 59340, loss = 0.996341
I0216 02:18:52.380645 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.09305 (* 1 = 1.09305 loss)
I0216 02:18:53.104941 32696 sgd_solver.cpp:106] Iteration 59340, lr = 0.0001
I0216 02:19:01.954780 32696 solver.cpp:231] Iteration 59350, loss = 1.03173
I0216 02:19:01.954849 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.32594 (* 1 = 1.32594 loss)
I0216 02:19:02.252986 32696 sgd_solver.cpp:106] Iteration 59350, lr = 0.0001
I0216 02:19:11.638912 32696 solver.cpp:231] Iteration 59360, loss = 1.00774
I0216 02:19:11.638984 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.750531 (* 1 = 0.750531 loss)
I0216 02:19:12.227195 32696 sgd_solver.cpp:106] Iteration 59360, lr = 0.0001
I0216 02:19:22.049340 32696 solver.cpp:231] Iteration 59370, loss = 1.11702
I0216 02:19:22.049383 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.24117 (* 1 = 1.24117 loss)
I0216 02:19:22.049427 32696 sgd_solver.cpp:106] Iteration 59370, lr = 0.0001
I0216 02:19:31.163355 32696 solver.cpp:231] Iteration 59380, loss = 0.947255
I0216 02:19:31.163413 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.623797 (* 1 = 0.623797 loss)
I0216 02:19:31.837827 32696 sgd_solver.cpp:106] Iteration 59380, lr = 0.0001
I0216 02:19:41.642732 32696 solver.cpp:231] Iteration 59390, loss = 1.05315
I0216 02:19:41.642789 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.982857 (* 1 = 0.982857 loss)
I0216 02:19:41.955361 32696 sgd_solver.cpp:106] Iteration 59390, lr = 0.0001
I0216 02:19:52.130051 32696 solver.cpp:231] Iteration 59400, loss = 1.32188
I0216 02:19:52.130286 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.01158 (* 1 = 1.01158 loss)
I0216 02:19:52.578042 32696 sgd_solver.cpp:106] Iteration 59400, lr = 0.0001
I0216 02:20:01.941452 32696 solver.cpp:231] Iteration 59410, loss = 0.872649
I0216 02:20:01.941514 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.947079 (* 1 = 0.947079 loss)
I0216 02:20:02.475602 32696 sgd_solver.cpp:106] Iteration 59410, lr = 0.0001
I0216 02:20:11.556658 32696 solver.cpp:231] Iteration 59420, loss = 1.04242
I0216 02:20:11.556715 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.619051 (* 1 = 0.619051 loss)
I0216 02:20:11.978560 32696 sgd_solver.cpp:106] Iteration 59420, lr = 0.0001
I0216 02:20:21.129295 32696 solver.cpp:231] Iteration 59430, loss = 1.07816
I0216 02:20:21.129364 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.45488 (* 1 = 1.45488 loss)
I0216 02:20:21.512045 32696 sgd_solver.cpp:106] Iteration 59430, lr = 0.0001
I0216 02:20:30.932889 32696 solver.cpp:231] Iteration 59440, loss = 0.889158
I0216 02:20:30.932972 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.00214 (* 1 = 1.00214 loss)
I0216 02:20:31.348472 32696 sgd_solver.cpp:106] Iteration 59440, lr = 0.0001
I0216 02:20:40.234268 32696 solver.cpp:231] Iteration 59450, loss = 1.10251
I0216 02:20:40.234335 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.765095 (* 1 = 0.765095 loss)
I0216 02:20:40.635972 32696 sgd_solver.cpp:106] Iteration 59450, lr = 0.0001
I0216 02:20:50.429929 32696 solver.cpp:231] Iteration 59460, loss = 1.09466
I0216 02:20:50.429980 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.16036 (* 1 = 1.16036 loss)
I0216 02:20:51.171264 32696 sgd_solver.cpp:106] Iteration 59460, lr = 0.0001
I0216 02:21:00.908201 32696 solver.cpp:231] Iteration 59470, loss = 1.13299
I0216 02:21:00.908252 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.596251 (* 1 = 0.596251 loss)
I0216 02:21:01.416071 32696 sgd_solver.cpp:106] Iteration 59470, lr = 0.0001
I0216 02:21:10.311082 32696 solver.cpp:231] Iteration 59480, loss = 0.878764
I0216 02:21:10.311120 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.28855 (* 1 = 1.28855 loss)
I0216 02:21:10.594126 32696 sgd_solver.cpp:106] Iteration 59480, lr = 0.0001
I0216 02:21:18.765739 32696 solver.cpp:231] Iteration 59490, loss = 0.87796
I0216 02:21:18.765799 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.739978 (* 1 = 0.739978 loss)
I0216 02:21:19.320176 32696 sgd_solver.cpp:106] Iteration 59490, lr = 0.0001
I0216 02:21:29.192953 32696 solver.cpp:231] Iteration 59500, loss = 1.0726
I0216 02:21:29.193012 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.38661 (* 1 = 1.38661 loss)
I0216 02:21:29.193048 32696 sgd_solver.cpp:106] Iteration 59500, lr = 0.0001
I0216 02:21:38.529634 32696 solver.cpp:231] Iteration 59510, loss = 0.886132
I0216 02:21:38.529881 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.10145 (* 1 = 1.10145 loss)
I0216 02:21:38.770558 32696 sgd_solver.cpp:106] Iteration 59510, lr = 0.0001
I0216 02:21:47.614130 32696 solver.cpp:231] Iteration 59520, loss = 0.967717
I0216 02:21:47.614168 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.11314 (* 1 = 1.11314 loss)
I0216 02:21:47.614228 32696 sgd_solver.cpp:106] Iteration 59520, lr = 0.0001
I0216 02:21:56.151871 32696 solver.cpp:231] Iteration 59530, loss = 1.05955
I0216 02:21:56.151935 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.35744 (* 1 = 1.35744 loss)
I0216 02:21:57.149749 32696 sgd_solver.cpp:106] Iteration 59530, lr = 0.0001
I0216 02:22:06.364534 32696 solver.cpp:231] Iteration 59540, loss = 0.990992
I0216 02:22:06.364585 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.41344 (* 1 = 1.41344 loss)
I0216 02:22:06.738678 32696 sgd_solver.cpp:106] Iteration 59540, lr = 0.0001
I0216 02:22:16.340205 32696 solver.cpp:231] Iteration 59550, loss = 0.999342
I0216 02:22:16.340453 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.28282 (* 1 = 1.28282 loss)
I0216 02:22:16.801688 32696 sgd_solver.cpp:106] Iteration 59550, lr = 0.0001
I0216 02:22:26.130511 32696 solver.cpp:231] Iteration 59560, loss = 1.04946
I0216 02:22:26.130568 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.695092 (* 1 = 0.695092 loss)
I0216 02:22:26.130589 32696 sgd_solver.cpp:106] Iteration 59560, lr = 0.0001
I0216 02:22:36.075081 32696 solver.cpp:231] Iteration 59570, loss = 0.934712
I0216 02:22:36.075155 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.09747 (* 1 = 1.09747 loss)
I0216 02:22:36.711755 32696 sgd_solver.cpp:106] Iteration 59570, lr = 0.0001
I0216 02:22:46.367473 32696 solver.cpp:231] Iteration 59580, loss = 0.942993
I0216 02:22:46.367683 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.19094 (* 1 = 1.19094 loss)
I0216 02:22:46.711149 32696 sgd_solver.cpp:106] Iteration 59580, lr = 0.0001
I0216 02:22:56.156244 32696 solver.cpp:231] Iteration 59590, loss = 0.940271
I0216 02:22:56.156312 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.970964 (* 1 = 0.970964 loss)
I0216 02:22:56.567035 32696 sgd_solver.cpp:106] Iteration 59590, lr = 0.0001
I0216 02:23:05.522720 32696 solver.cpp:231] Iteration 59600, loss = 0.941283
I0216 02:23:05.522771 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.12256 (* 1 = 1.12256 loss)
I0216 02:23:05.864552 32696 sgd_solver.cpp:106] Iteration 59600, lr = 0.0001
I0216 02:23:15.065764 32696 solver.cpp:231] Iteration 59610, loss = 1.18709
I0216 02:23:15.065824 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.38229 (* 1 = 1.38229 loss)
I0216 02:23:15.065846 32696 sgd_solver.cpp:106] Iteration 59610, lr = 0.0001
I0216 02:23:23.761657 32696 solver.cpp:231] Iteration 59620, loss = 0.951719
I0216 02:23:23.761906 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.921779 (* 1 = 0.921779 loss)
I0216 02:23:24.209991 32696 sgd_solver.cpp:106] Iteration 59620, lr = 0.0001
I0216 02:23:34.581728 32696 solver.cpp:231] Iteration 59630, loss = 1.18385
I0216 02:23:34.581789 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.94815 (* 1 = 0.94815 loss)
I0216 02:23:34.776625 32696 sgd_solver.cpp:106] Iteration 59630, lr = 0.0001
I0216 02:23:43.881696 32696 solver.cpp:231] Iteration 59640, loss = 0.924449
I0216 02:23:43.881753 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.546996 (* 1 = 0.546996 loss)
I0216 02:23:44.289572 32696 sgd_solver.cpp:106] Iteration 59640, lr = 0.0001
I0216 02:23:53.714779 32696 solver.cpp:231] Iteration 59650, loss = 0.999138
I0216 02:23:53.714834 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.684081 (* 1 = 0.684081 loss)
I0216 02:23:54.194491 32696 sgd_solver.cpp:106] Iteration 59650, lr = 0.0001
I0216 02:24:04.038960 32696 solver.cpp:231] Iteration 59660, loss = 1.2812
I0216 02:24:04.039026 32696 solver.cpp:247]     Train net output #0: mbox_loss = 2.04324 (* 1 = 2.04324 loss)
I0216 02:24:04.663918 32696 sgd_solver.cpp:106] Iteration 59660, lr = 0.0001
I0216 02:24:14.148351 32696 solver.cpp:231] Iteration 59670, loss = 1.15949
I0216 02:24:14.148408 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.808455 (* 1 = 0.808455 loss)
I0216 02:24:14.544191 32696 sgd_solver.cpp:106] Iteration 59670, lr = 0.0001
I0216 02:24:24.451103 32696 solver.cpp:231] Iteration 59680, loss = 1.06031
I0216 02:24:24.451261 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.898878 (* 1 = 0.898878 loss)
I0216 02:24:24.451292 32696 sgd_solver.cpp:106] Iteration 59680, lr = 0.0001
I0216 02:24:33.275534 32696 solver.cpp:231] Iteration 59690, loss = 1.06074
I0216 02:24:33.275585 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.30635 (* 1 = 1.30635 loss)
I0216 02:24:33.609014 32696 sgd_solver.cpp:106] Iteration 59690, lr = 0.0001
I0216 02:24:42.357529 32696 solver.cpp:231] Iteration 59700, loss = 0.950033
I0216 02:24:42.357591 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.636275 (* 1 = 0.636275 loss)
I0216 02:24:42.682700 32696 sgd_solver.cpp:106] Iteration 59700, lr = 0.0001
I0216 02:24:51.680747 32696 solver.cpp:231] Iteration 59710, loss = 0.914619
I0216 02:24:51.680814 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.643218 (* 1 = 0.643218 loss)
I0216 02:24:52.097683 32696 sgd_solver.cpp:106] Iteration 59710, lr = 0.0001
I0216 02:25:02.938694 32696 solver.cpp:231] Iteration 59720, loss = 1.04881
I0216 02:25:02.938885 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.01743 (* 1 = 1.01743 loss)
I0216 02:25:02.938918 32696 sgd_solver.cpp:106] Iteration 59720, lr = 0.0001
I0216 02:25:11.937183 32696 solver.cpp:231] Iteration 59730, loss = 0.949163
I0216 02:25:11.937232 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.05703 (* 1 = 1.05703 loss)
I0216 02:25:12.167049 32696 sgd_solver.cpp:106] Iteration 59730, lr = 0.0001
I0216 02:25:21.686609 32696 solver.cpp:231] Iteration 59740, loss = 0.905453
I0216 02:25:21.686672 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.995468 (* 1 = 0.995468 loss)
I0216 02:25:22.503759 32696 sgd_solver.cpp:106] Iteration 59740, lr = 0.0001
I0216 02:25:32.153903 32696 solver.cpp:231] Iteration 59750, loss = 0.88712
I0216 02:25:32.153967 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.768635 (* 1 = 0.768635 loss)
I0216 02:25:32.470556 32696 sgd_solver.cpp:106] Iteration 59750, lr = 0.0001
I0216 02:25:41.633839 32696 solver.cpp:231] Iteration 59760, loss = 1.03569
I0216 02:25:41.634284 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.820551 (* 1 = 0.820551 loss)
I0216 02:25:42.312950 32696 sgd_solver.cpp:106] Iteration 59760, lr = 0.0001
I0216 02:25:50.665143 32696 solver.cpp:231] Iteration 59770, loss = 0.977179
I0216 02:25:50.665216 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.07738 (* 1 = 1.07738 loss)
I0216 02:25:51.032208 32696 sgd_solver.cpp:106] Iteration 59770, lr = 0.0001
I0216 02:26:00.609410 32696 solver.cpp:231] Iteration 59780, loss = 1.2248
I0216 02:26:00.609473 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.52216 (* 1 = 1.52216 loss)
I0216 02:26:01.027014 32696 sgd_solver.cpp:106] Iteration 59780, lr = 0.0001
I0216 02:26:10.504653 32696 solver.cpp:231] Iteration 59790, loss = 0.844104
I0216 02:26:10.504724 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.775637 (* 1 = 0.775637 loss)
I0216 02:26:10.818608 32696 sgd_solver.cpp:106] Iteration 59790, lr = 0.0001
I0216 02:26:20.410131 32696 solver.cpp:231] Iteration 59800, loss = 0.962087
I0216 02:26:20.410382 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.640467 (* 1 = 0.640467 loss)
I0216 02:26:20.742038 32696 sgd_solver.cpp:106] Iteration 59800, lr = 0.0001
I0216 02:26:29.997520 32696 solver.cpp:231] Iteration 59810, loss = 1.08184
I0216 02:26:29.997580 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.75584 (* 1 = 0.75584 loss)
I0216 02:26:29.997611 32696 sgd_solver.cpp:106] Iteration 59810, lr = 0.0001
I0216 02:26:38.603401 32696 solver.cpp:231] Iteration 59820, loss = 0.939009
I0216 02:26:38.603452 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.596655 (* 1 = 0.596655 loss)
I0216 02:26:38.979095 32696 sgd_solver.cpp:106] Iteration 59820, lr = 0.0001
I0216 02:26:48.066026 32696 solver.cpp:231] Iteration 59830, loss = 0.982557
I0216 02:26:48.066085 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.71136 (* 1 = 0.71136 loss)
I0216 02:26:48.537243 32696 sgd_solver.cpp:106] Iteration 59830, lr = 0.0001
I0216 02:26:57.775166 32696 solver.cpp:231] Iteration 59840, loss = 1.10785
I0216 02:26:57.775372 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.554773 (* 1 = 0.554773 loss)
I0216 02:26:58.117112 32696 sgd_solver.cpp:106] Iteration 59840, lr = 0.0001
I0216 02:27:07.946974 32696 solver.cpp:231] Iteration 59850, loss = 0.868587
I0216 02:27:07.947111 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.599713 (* 1 = 0.599713 loss)
I0216 02:27:08.367081 32696 sgd_solver.cpp:106] Iteration 59850, lr = 0.0001
I0216 02:27:18.358969 32696 solver.cpp:231] Iteration 59860, loss = 1.1098
I0216 02:27:18.359035 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.62595 (* 1 = 1.62595 loss)
I0216 02:27:18.668418 32696 sgd_solver.cpp:106] Iteration 59860, lr = 0.0001
I0216 02:27:28.044884 32696 solver.cpp:231] Iteration 59870, loss = 1.06792
I0216 02:27:28.045094 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.803129 (* 1 = 0.803129 loss)
I0216 02:27:28.406709 32696 sgd_solver.cpp:106] Iteration 59870, lr = 0.0001
I0216 02:27:37.048787 32696 solver.cpp:231] Iteration 59880, loss = 0.965654
I0216 02:27:37.048838 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.613688 (* 1 = 0.613688 loss)
I0216 02:27:37.755596 32696 sgd_solver.cpp:106] Iteration 59880, lr = 0.0001
I0216 02:27:46.058071 32696 solver.cpp:231] Iteration 59890, loss = 0.988833
I0216 02:27:46.058132 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.904779 (* 1 = 0.904779 loss)
I0216 02:27:46.058190 32696 sgd_solver.cpp:106] Iteration 59890, lr = 0.0001
I0216 02:27:54.092814 32696 solver.cpp:231] Iteration 59900, loss = 1.04989
I0216 02:27:54.092854 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.33614 (* 1 = 1.33614 loss)
I0216 02:27:54.092874 32696 sgd_solver.cpp:106] Iteration 59900, lr = 0.0001
I0216 02:28:02.097249 32696 solver.cpp:231] Iteration 59910, loss = 0.987855
I0216 02:28:02.097481 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.92336 (* 1 = 0.92336 loss)
I0216 02:28:02.097579 32696 sgd_solver.cpp:106] Iteration 59910, lr = 0.0001
I0216 02:28:10.670781 32696 solver.cpp:231] Iteration 59920, loss = 0.743041
I0216 02:28:10.670836 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.691033 (* 1 = 0.691033 loss)
I0216 02:28:10.670868 32696 sgd_solver.cpp:106] Iteration 59920, lr = 0.0001
I0216 02:28:18.633581 32696 solver.cpp:231] Iteration 59930, loss = 0.893735
I0216 02:28:18.633657 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.892409 (* 1 = 0.892409 loss)
I0216 02:28:18.633754 32696 sgd_solver.cpp:106] Iteration 59930, lr = 0.0001
I0216 02:28:26.595252 32696 solver.cpp:231] Iteration 59940, loss = 0.945713
I0216 02:28:26.595309 32696 solver.cpp:247]     Train net output #0: mbox_loss = 1.13099 (* 1 = 1.13099 loss)
I0216 02:28:26.595348 32696 sgd_solver.cpp:106] Iteration 59940, lr = 0.0001
I0216 02:28:34.856403 32696 solver.cpp:231] Iteration 59950, loss = 1.17308
I0216 02:28:34.856662 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.945229 (* 1 = 0.945229 loss)
I0216 02:28:34.856729 32696 sgd_solver.cpp:106] Iteration 59950, lr = 0.0001
I0216 02:28:42.818673 32696 solver.cpp:231] Iteration 59960, loss = 1.01185
I0216 02:28:42.818742 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.924461 (* 1 = 0.924461 loss)
I0216 02:28:42.818819 32696 sgd_solver.cpp:106] Iteration 59960, lr = 0.0001
I0216 02:28:50.626816 32696 solver.cpp:231] Iteration 59970, loss = 1.03413
I0216 02:28:50.626859 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.775016 (* 1 = 0.775016 loss)
I0216 02:28:50.626919 32696 sgd_solver.cpp:106] Iteration 59970, lr = 0.0001
I0216 02:28:59.011845 32696 solver.cpp:231] Iteration 59980, loss = 0.92927
I0216 02:28:59.011914 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.785601 (* 1 = 0.785601 loss)
I0216 02:28:59.011957 32696 sgd_solver.cpp:106] Iteration 59980, lr = 0.0001
I0216 02:29:07.581151 32696 solver.cpp:231] Iteration 59990, loss = 0.974543
I0216 02:29:07.581401 32696 solver.cpp:247]     Train net output #0: mbox_loss = 0.681917 (* 1 = 0.681917 loss)
I0216 02:29:07.581477 32696 sgd_solver.cpp:106] Iteration 59990, lr = 0.0001
I0216 02:29:14.582067 32696 solver.cpp:576] Snapshotting to binary proto file /home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/VGG_KITTI_SSD_600x150_iter_60000.caffemodel
I0216 02:29:15.159126 32696 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/perception/KITTI_SSD//models/VGGNet/KITTI/SSD_600x150/VGG_KITTI_SSD_600x150_iter_60000.solverstate
I0216 02:29:15.631608 32696 solver.cpp:320] Iteration 60000, loss = 1.03914
I0216 02:29:15.631719 32696 solver.cpp:421] Iteration 60000, Testing net (#0)
I0216 02:29:15.661864 32696 net.cpp:684] Ignoring source layer mbox_loss
I0216 02:34:46.441015 32696 blocking_queue.cpp:50] Data layer prefetch queue empty
I0216 02:35:23.774775 32696 blocking_queue.cpp:50] Data layer prefetch queue empty
I0216 02:35:39.670061 32696 solver.cpp:526]     Test net output #0: detection_eval = 0.849508
I0216 02:35:39.670120 32696 solver.cpp:325] Optimization Done.
I0216 02:35:39.986567 32696 caffe.cpp:222] Optimization Done.
